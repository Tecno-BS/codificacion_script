# üöÄ Optimizaci√≥n de Costos y Rendimiento

## Problema Identificado

El sistema actual con LangGraph hace **3-4 llamadas separadas a GPT por cada batch**:
1. `nodo_validar` ‚Üí 1 llamada GPT
2. `nodo_evaluar_catalogo` ‚Üí 1 llamada GPT (o m√°s si hay categor√≠as)
3. `nodo_identificar_conceptos` ‚Üí 1 llamada GPT

**Impacto:**
- **3-4x m√°s costo** que el sistema anterior
- **3-4x m√°s latencia** (tiempo de procesamiento)
- **3-4x m√°s tokens** (cada prompt incluye contexto repetido)

## Soluci√≥n Implementada

### Nodo Combinado (`nodo_codificar_combinado`)

Se cre√≥ un nuevo nodo que combina las 3 tareas en **una sola llamada GPT**:
- ‚úÖ Validaci√≥n de respuestas
- ‚úÖ Evaluaci√≥n del cat√°logo hist√≥rico
- ‚úÖ Identificaci√≥n de conceptos nuevos

**Beneficios:**
- **Reducci√≥n de costo: ~70%** (de 3-4 llamadas a 1)
- **Reducci√≥n de latencia: ~70%** (de 3-4 llamadas secuenciales a 1)
- **Reducci√≥n de tokens: ~50%** (contexto compartido, sin repetici√≥n)

### C√≥mo Activar la Optimizaci√≥n

El nodo combinado est√° disponible pero **no activado por defecto** para mantener compatibilidad.

Para activarlo, modifica el grafo en `codificador_nuevo.py`:

```python
# ANTES (3 nodos separados):
workflow.add_node("validar", nodo_validar)
workflow.add_node("evaluar_catalogo", nodo_evaluar_catalogo)
workflow.add_node("identificar_conceptos", nodo_identificar_conceptos)

workflow.add_edge("preparar_batch", "validar")
workflow.add_edge("validar", "evaluar_catalogo")
workflow.add_edge("evaluar_catalogo", "identificar_conceptos")
workflow.add_edge("identificar_conceptos", "ensamblar")

# DESPU√âS (1 nodo combinado):
workflow.add_node("codificar_combinado", nodo_codificar_combinado)

workflow.add_edge("preparar_batch", "codificar_combinado")
workflow.add_edge("codificar_combinado", "ensamblar")
```

## Comparaci√≥n de Rendimiento

### Sistema Anterior (GptHibrido)
- **Llamadas GPT por batch:** 1
- **Costo estimado por 100 respuestas:** ~$0.05-0.10
- **Tiempo estimado:** ~5-10 segundos

### Sistema Actual (LangGraph - 3 nodos)
- **Llamadas GPT por batch:** 3-4
- **Costo estimado por 100 respuestas:** ~$0.15-0.40
- **Tiempo estimado:** ~15-40 segundos

### Sistema Optimizado (LangGraph - nodo combinado)
- **Llamadas GPT por batch:** 1
- **Costo estimado por 100 respuestas:** ~$0.05-0.10
- **Tiempo estimado:** ~5-10 segundos

## Otras Optimizaciones Recomendadas

1. **Cach√© m√°s agresivo:**
   - Cachear respuestas similares
   - Cachear evaluaciones de cat√°logo para respuestas id√©nticas

2. **Llamadas as√≠ncronas en paralelo:**
   - Si hay m√∫ltiples categor√≠as, procesarlas en paralelo

3. **Optimizaci√≥n de prompts:**
   - Reducir tokens redundantes
   - Usar prompts m√°s concisos

4. **Batch size din√°mico:**
   - Ajustar el tama√±o del batch seg√∫n el modelo usado
   - Modelos m√°s r√°pidos pueden usar batches m√°s grandes

## Notas

- El nodo combinado mantiene la misma calidad de resultados
- La estructura de LangGraph se mantiene para flexibilidad futura
- El formato de salida es compatible con el nodo `ensamblar` existente

