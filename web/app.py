import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import os
import sys
from pathlib import Path
from io import BytesIO
import asyncio
import streamlit.components.v1 as components


# Agregar directorio src
sys.path.append(str(Path(__file__).parent.parent / "src"))

from codificador_v05 import CodificadorHibridoV05
from evaluador import EvaluadorCodificacion
from config import USE_GPT_MOCK, OPENAI_MODEL
from contexto import ContextoProyecto
from extractor_contexto import ExtractorContexto

# Configuraci√≥n p√°gina
st.set_page_config(
    page_title="Codificaci√≥n H√≠brida v0.5 - BS",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)


def main():
    st.title("üöÄ Sistema de Codificaci√≥n H√≠brida v0.5")
    st.markdown("---")

    configuracion_sidebar()

    col1, col2 = st.columns([2, 1])

    with col1:
        st.header("üìÅ Cargar Archivos")
        archivos = cargar_archivos()

        if archivos: 
            # Capturar contexto del proyecto (opcional) - TEMPORALMENTE DESACTIVADO
            # contexto = capturar_contexto()
            contexto = ContextoProyecto()  # Contexto vac√≠o por ahora
            
            st.header("‚ñ∂Ô∏è Ejecutar Codificaci√≥n")
            if st.button("üöÄ Iniciar Codificaci√≥n", type="primary", use_container_width=True):
                # Limpiar resultados anteriores
                keys_to_clear = [
                    'resultados', 'ruta_resultados', 'ruta_codigos_nuevos', 
                    'codificador', 'codificacion_completada',
                    'excel_bytes_resultados', 'excel_bytes_codigos_nuevos'
                ]
                for key in keys_to_clear:
                    if key in st.session_state:
                        del st.session_state[key]
                ejecutar_codificacion(archivos, contexto)
            
    with col2:
        st.header("üìä Estado del Sistema")
        mostrar_estado()
    
    # MOSTRAR RESULTADOS SI EXISTEN EN SESSION_STATE
    if st.session_state.get('codificacion_completada', False):
        st.markdown("---")
        
        # Bot√≥n para limpiar resultados y empezar de nuevo
        col_limpiar1, col_limpiar2 = st.columns([3, 1])
        with col_limpiar2:
            if st.button("üîÑ Nueva Codificaci√≥n", use_container_width=True):
                keys_to_clear = [
                    'resultados', 'ruta_resultados', 'ruta_codigos_nuevos', 
                    'codificador', 'codificacion_completada',
                    'excel_bytes_resultados', 'excel_bytes_codigos_nuevos'
                ]
                for key in keys_to_clear:
                    if key in st.session_state:
                        del st.session_state[key]
                st.rerun()
        
        mostrar_resultados(
            st.session_state.resultados,
            st.session_state.ruta_resultados,
            st.session_state.ruta_codigos_nuevos,
            st.session_state.codificador
        )


def reproducir_sonido_notificacion():
    """Reproduce un sonido de notificaci√≥n cuando termina la codificaci√≥n"""
    # Verificar si el usuario quiere sonido
    if not st.session_state.get('notificacion_sonido', True):
        return
    
    # HTML con JavaScript para reproducir sonido
    html_code = """
    <script>
        // Crear contexto de audio
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        
        // Funci√≥n para crear un beep
        function playBeep(frequency, duration, volume) {
            const oscillator = audioContext.createOscillator();
            const gainNode = audioContext.createGain();
            
            oscillator.connect(gainNode);
            gainNode.connect(audioContext.destination);
            
            oscillator.frequency.value = frequency;
            oscillator.type = 'sine';
            
            gainNode.gain.setValueAtTime(volume, audioContext.currentTime);
            gainNode.gain.exponentialRampToValueAtTime(0.001, audioContext.currentTime + duration);
            
            oscillator.start(audioContext.currentTime);
            oscillator.stop(audioContext.currentTime + duration);
        }
        
        // Secuencia de notificaci√≥n: 3 beeps cortos
        playBeep(800, 0.15, 0.3);  // Primera nota
        setTimeout(() => playBeep(1000, 0.15, 0.3), 200);  // Segunda nota
        setTimeout(() => playBeep(1200, 0.25, 0.3), 400);  // Tercera nota (m√°s larga)
        
        console.log("üîî Notificaci√≥n sonora reproducida");
    </script>
    """
    components.html(html_code, height=0)


def configuracion_sidebar():
    """Configuraci√≥n en barra lateral"""
    st.sidebar.title("‚öôÔ∏è Configuraci√≥n")

    # Modo GPT
    st.sidebar.subheader("ü§ñ Modo de Operaci√≥n")
    if USE_GPT_MOCK:
        st.sidebar.success("‚úÖ Modo MOCK activado")
        st.sidebar.info("Sin costos - Ideal para desarrollo y pruebas")
    else:
        st.sidebar.warning("‚ö° Modo REAL activado")
        
        # Selector de modelo
        modelos_disponibles = [
            "gpt-4o-mini",
            "gpt-4.1",
            "gpt-5"
        ]
        
        # Obtener modelo por defecto
        modelo_default = OPENAI_MODEL if OPENAI_MODEL in modelos_disponibles else "gpt-4o-mini"
        default_index = modelos_disponibles.index(modelo_default)
        
        modelo_seleccionado = st.sidebar.selectbox(
            "üéØ Modelo GPT",
            modelos_disponibles,
            index=default_index,
            help="Selecciona el modelo seg√∫n tu necesidad de precisi√≥n vs. costo"
        )
        st.session_state.modelo_gpt = modelo_seleccionado
        
        # Mostrar info del modelo
        if "gpt-5" in modelo_seleccionado:
            st.sidebar.info("üíé **GPT-5**: M√°xima precisi√≥n y razonamiento avanzado")
            st.sidebar.warning("‚ö†Ô∏è Costo estimado: ~$5-15 por 1M tokens")
            st.sidebar.caption("üî∏ Temperature fija = 1 | max_completion_tokens = 8000")
        elif "gpt-4.1" in modelo_seleccionado:
            st.sidebar.info("üî∏ **GPT-4.1**: Equilibrio calidad-costo √≥ptimo")
            st.sidebar.info("‚ö° Costo estimado: ~$3-12 por 1M tokens")
            st.sidebar.caption("üî∏ Temperature = 0.1 | max_tokens = 4000")
        else:  # gpt-4o-mini
            st.sidebar.info("‚ö° **GPT-4o-mini**: Econ√≥mico y r√°pido")
            st.sidebar.success("üí∞ Costo estimado: ~$0.15-0.60 por 1M tokens")
            st.sidebar.caption("üî∏ Temperature = 0.1 | max_tokens = 4000")
    
    st.sidebar.info("Se consumir√° API de OpenAI")
    
    # Costo acumulado
    if 'gpt_costo_total' in st.session_state:
        st.sidebar.metric("üíµ Costo Total Sesi√≥n", f"${st.session_state.gpt_costo_total:.4f}")
    
    st.sidebar.markdown("---")
    
    # Preferencias
    st.sidebar.subheader("üîî Notificaciones")
    notificacion_sonido = st.sidebar.checkbox(
        "üîä Sonido al terminar",
        value=st.session_state.get('notificacion_sonido', True),
        help="Reproducir un sonido cuando termine la codificaci√≥n"
    )
    st.session_state.notificacion_sonido = notificacion_sonido
    
    st.sidebar.markdown("---")
    
    # Informaci√≥n del sistema
    st.sidebar.subheader("‚ÑπÔ∏è Informaci√≥n")
    st.sidebar.info("""
**Versi√≥n:** v0.5 H√≠brida

**Caracter√≠sticas:**
- ‚úÖ 100% Gen√©rico
- ‚úÖ Sin embeddings
- ‚úÖ GPT directo
- ‚úÖ Detecci√≥n autom√°tica
- ‚úÖ C√≥digos hist√≥ricos + nuevos

**Modelo:** {model}
    """.format(model=OPENAI_MODEL))


def cargar_archivos():
    """Interfaz para cargar archivos"""
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("üìÑ Archivo de Respuestas")
        archivo_respuestas = st.file_uploader(
            "Selecciona Excel con respuestas",
            type=["xlsx", "xls"],
            help="Excel con columnas de preguntas abiertas"
        )
        
        if archivo_respuestas:
            st.success("‚úÖ Archivo cargado")
            try:
                df = pd.read_excel(archivo_respuestas)
                
                with st.expander("üëÅÔ∏è Vista previa"):
                    st.dataframe(df.head(10), use_container_width=True)
                
                st.info(f"üìä **{len(df)}** respuestas | **{len(df.columns)}** columnas")
                
                # Detectar preguntas potenciales
                columnas_texto = [c for c in df.columns if df[c].dtype == 'object']
                st.caption(f"üîç Detectadas **{len(columnas_texto)}** columnas de texto")
                
            except Exception as e:
                st.error(f"‚ùå Error al leer archivo: {e}")
    
    with col2:
        st.subheader("üìö Cat√°logo de C√≥digos (Opcional)")
        archivo_codigos = st.file_uploader(
            "Selecciona Excel con c√≥digos hist√≥ricos",
            type=["xlsx", "xls"],
            help="Excel con hojas nombradas por pregunta, columnas: COD y TEXTO"
        )
        
        if archivo_codigos:
            st.success("‚úÖ Cat√°logo cargado")
            try:
                with pd.ExcelFile(archivo_codigos) as xls:
                    hojas = xls.sheet_names
                    st.info(f"üìë **{len(hojas)}** cat√°logos encontrados")
                    
                    with st.expander("üìã Hojas disponibles"):
                        for hoja in hojas:
                            df_hoja = pd.read_excel(xls, sheet_name=hoja)
                            if 'COD' in df_hoja.columns and 'TEXTO' in df_hoja.columns:
                                st.success(f"‚úÖ **{hoja}**: {len(df_hoja)} c√≥digos")
                            else:
                                st.warning(f"‚ö†Ô∏è **{hoja}**: Sin formato v√°lido")
            except Exception as e:
                st.error(f"‚ùå Error al leer cat√°logo: {e}")
        else:
            st.info("‚ÑπÔ∏è Sin cat√°logo ‚Üí Modo **generaci√≥n de c√≥digos**")

    return {
        'respuestas': archivo_respuestas,
        'codigos': archivo_codigos
    } if archivo_respuestas else None


# ========================================================================
# FUNCIONALIDAD DE CONTEXTO - TEMPORALMENTE DESACTIVADA
# ========================================================================
# def capturar_contexto():
#     """
#     Captura el contexto del proyecto (opcional) - EXTRACCION AUTOMATICA
#     """
#     st.subheader("üìù Contexto del Proyecto (Opcional)")
#     st.markdown("**Sube un documento** y el sistema extraer√° autom√°ticamente el contexto:")
#     st.caption("‚úÖ Soporta: Word (`.docx`, `.doc`), PDF (`.pdf`), Texto (`.txt`), Excel (`.xlsx`, `.xls`)")
#     
#     # Opci√≥n para forzar GPT en extracci√≥n de contexto
#     if USE_GPT_MOCK:
#         usar_gpt_extraccion = st.checkbox(
#             "ü§ñ Usar GPT para extracci√≥n inteligente (recomendado, ~$0.001 por doc)",
#             value=True,
#             help="GPT puede extraer contexto de documentos con formato libre. Regex solo funciona con formato estructurado."
#         )
#         st.session_state.forzar_gpt_contexto = usar_gpt_extraccion
#         
#         if not usar_gpt_extraccion:
#             st.warning("‚ö†Ô∏è Modo regex: El documento debe tener formato estructurado (ej: 'Objetivo: ...')")
#     
#     # File uploader para documento de contexto
#     archivo_contexto = st.file_uploader(
#         "üìÑ Subir Documento de Contexto",
#         type=['txt', 'docx', 'doc', 'pdf', 'xlsx', 'xls'],
#         help="Sube el instructivo, briefing o documento con informaci√≥n del proyecto. El sistema extraer√° autom√°ticamente: antecedentes, objetivo, grupo objetivo, etc.",
#         key="uploader_contexto"
#     )
#     
#     contexto = ContextoProyecto.vacio()
#     
#     if archivo_contexto:
#         try:
#             # Guardar temporalmente
#             temp_dir = Path("temp")
#             temp_dir.mkdir(exist_ok=True)
#             ruta_temp = temp_dir / archivo_contexto.name
#             
#             with open(ruta_temp, "wb") as f:
#                 f.write(archivo_contexto.getbuffer())
#             
#             # Extraer contexto autom√°ticamente
#             with st.spinner("üîç Extrayendo contexto del documento..."):
#                 # Siempre usar GPT para extracci√≥n de contexto (m√°s preciso)
#                 # Costo: ~$0.001 por documento (muy bajo)
#                 usar_gpt_contexto = not USE_GPT_MOCK or st.session_state.get('forzar_gpt_contexto', True)
#                 extractor = ExtractorContexto(usar_gpt=usar_gpt_contexto)
#                 contexto = extractor.extraer_desde_archivo(str(ruta_temp))
#             
#             # Limpiar archivo temporal
#             ruta_temp.unlink()
#             
#             # Mostrar contexto extra√≠do
#             if contexto.tiene_contexto():
#                 st.success("‚úÖ Contexto extra√≠do exitosamente")
#                 
#                 with st.expander("üëÅÔ∏è Ver Contexto Extra√≠do", expanded=True):
#                     col1, col2 = st.columns(2)
#                     
#                     with col1:
#                         if contexto.nombre_proyecto:
#                             st.markdown(f"**Proyecto:** {contexto.nombre_proyecto}")
#                         if contexto.cliente:
#                             st.markdown(f"**Cliente:** {contexto.cliente}")
#                         if contexto.antecedentes:
#                             st.markdown(f"**Antecedentes:**")
#                             st.caption(contexto.antecedentes[:200] + "..." if len(contexto.antecedentes) > 200 else contexto.antecedentes)
#                     
#                     with col2:
#                         if contexto.objetivo:
#                             st.markdown(f"**Objetivo:**")
#                             st.caption(contexto.objetivo[:200] + "..." if len(contexto.objetivo) > 200 else contexto.objetivo)
#                         if contexto.grupo_objetivo:
#                             st.markdown(f"**Grupo Objetivo:**")
#                             st.caption(contexto.grupo_objetivo[:200] + "..." if len(contexto.grupo_objetivo) > 200 else contexto.grupo_objetivo)
#                 
#                 # Opci√≥n de editar manualmente
#                 editar = st.checkbox("‚úèÔ∏è Editar contexto manualmente", value=False)
#                 
#                 if editar:
#                     st.markdown("---")
#                     col1, col2 = st.columns(2)
#                     
#                     with col1:
#                         contexto.nombre_proyecto = st.text_input("Nombre Proyecto", value=contexto.nombre_proyecto)
#                         contexto.cliente = st.text_input("Cliente", value=contexto.cliente)
#                         contexto.antecedentes = st.text_area("Antecedentes", value=contexto.antecedentes, height=100)
#                     
#                     with col2:
#                         contexto.objetivo = st.text_area("Objetivo", value=contexto.objetivo, height=100)
#                         contexto.grupo_objetivo = st.text_area("Grupo Objetivo", value=contexto.grupo_objetivo, height=100)
#                         contexto.notas_adicionales = st.text_area("Notas", value=contexto.notas_adicionales, height=100)
#             else:
#                 st.warning("‚ö†Ô∏è No se pudo extraer contexto del documento")
#                 
#                 if USE_GPT_MOCK and not st.session_state.get('forzar_gpt_contexto', True):
#                     st.info("üí° **Sugerencia:** Activa el checkbox 'ü§ñ Usar GPT para extracci√≥n inteligente' arriba para extraer contexto de documentos con formato libre")
#                 else:
#                     st.info("üí° El documento puede estar vac√≠o o no contener informaci√≥n relevante. Puedes editar manualmente usando el checkbox '‚úèÔ∏è Editar contexto manualmente'")
#                 
#         except ImportError as e:
#             st.error(f"‚ùå Error: Biblioteca faltante para procesar este formato")
#             st.info("üí° **Soluci√≥n:** Instala las dependencias necesarias:")
#             st.code("pip install python-docx PyPDF2")
#             st.caption(f"Detalles t√©cnicos: {e}")
#         except ValueError as e:
#             error_msg = str(e)
#             st.error(f"‚ùå Error al procesar documento")
#             
#             # Mostrar mensaje de error detallado
#             if "tiene extensi√≥n .doc pero es formato .docx" in error_msg:
#                 st.warning("‚ö†Ô∏è **Problema detectado:** Tu archivo tiene extensi√≥n `.doc` pero internamente es formato `.docx` moderno")
#                 
#                 st.markdown("### üîß Soluciones:")
#                 
#                 col1, col2 = st.columns(2)
#                 
#                 with col1:
#                     st.markdown("**Opci√≥n 1: Renombrar (R√°pido)**")
#                     st.info("Renombra tu archivo de `.doc` a `.docx` y s√∫belo de nuevo")
#                     st.caption("Ejemplo: `archivo.doc` ‚Üí `archivo.docx`")
#                 
#                 with col2:
#                     st.markdown("**Opci√≥n 2: Convertir a texto**")
#                     st.info("Abre el archivo en Word y gu√°rdalo como `.txt`")
#                     st.caption("Archivo ‚Üí Guardar como ‚Üí Formato: Texto plano (.txt)")
#                 
#                 st.markdown("**Opci√≥n 3: Usar script de conversi√≥n**")
#                 st.code(f'python convertir_doc_a_docx.py "{archivo_contexto.name}"')
#                 st.caption("Este script convierte autom√°ticamente el archivo")
#             else:
#                 st.error(f"{error_msg}")
#                 st.info("üí° Formatos soportados: DOCX, DOC, PDF, TXT, XLSX, XLS")
#         except Exception as e:
#             st.error(f"‚ùå Error al procesar documento: {e}")
#             st.info("üí° Verifica que el archivo no est√© corrupto y sea legible")
#             with st.expander("üîç Detalles t√©cnicos (para desarrolladores)"):
#                 import traceback
#                 st.code(traceback.format_exc())
#     else:
#         st.info("‚ÑπÔ∏è Sin documento de contexto - La codificaci√≥n funcionar√° normalmente")
#     
#     return contexto
# ========================================================================


def ejecutar_codificacion(archivos, contexto: ContextoProyecto):
    """Ejecutar proceso de codificaci√≥n"""
    temp_dir = Path("temp")
    temp_dir.mkdir(exist_ok=True)

    # Guardar archivos temporales
    ruta_respuestas = temp_dir / archivos['respuestas'].name
    with open(ruta_respuestas, "wb") as f:
        f.write(archivos['respuestas'].getbuffer())
    
    ruta_codigos = None
    if archivos['codigos']:
        ruta_codigos = temp_dir / archivos['codigos'].name
        with open(ruta_codigos, "wb") as f:
            f.write(archivos['codigos'].getbuffer())

    # Barra de progreso
    progress_bar = st.progress(0)
    status_text = st.empty()

    try:
        # 1. Inicializar (con contexto)
        status_text.text("üîß Inicializando codificador v0.5...")
        progress_bar.progress(10)

        # Obtener modelo seleccionado (o usar default)
        modelo_gpt = st.session_state.get('modelo_gpt', OPENAI_MODEL)
        codificador = CodificadorHibridoV05(contexto=contexto, modelo=modelo_gpt)
        
        if contexto.tiene_contexto():
            st.info(f"üìù Contexto: {contexto.resumen_corto()}")

        # 2. Procesar respuestas
        status_text.text("üìù Procesando respuestas (limpieza m√≠nima)...")
        progress_bar.progress(20)
        
        if not codificador.procesar_respuestas(str(ruta_respuestas)):
            st.error("‚ùå Error al procesar respuestas")
            return

        # 3. Cargar cat√°logos
        if ruta_codigos:
            status_text.text("üìö Cargando cat√°logos hist√≥ricos...")
            progress_bar.progress(30)
            codificador.cargar_catalogos(str(ruta_codigos))
        else:
            st.info("‚ÑπÔ∏è Modo generaci√≥n pura (sin cat√°logos)")

        # 4. Codificar con GPT
        status_text.text("ü§ñ Codificando con GPT (esto puede tardar)...")
        progress_bar.progress(40)
        
        # Ejecutar codificaci√≥n async
        resultados = asyncio.run(codificador.codificar_todas_preguntas())
        
        progress_bar.progress(80)

        # 5. Guardar resultados
        status_text.text("üíæ Guardando resultados...")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        nombre_proyecto = Path(archivos['respuestas'].name).stem
        ruta_resultados = f"result/codificaciones/resultados_{nombre_proyecto}_{timestamp}.xlsx"

        codificador.guardar_resultados(resultados, ruta_resultados)
        
        # 6. Exportar c√≥digos nuevos
        ruta_codigos_nuevos = codificador.exportar_catalogo_nuevos(
            nombre_proyecto=nombre_proyecto
        )

        progress_bar.progress(100)
        status_text.text("‚úÖ Codificaci√≥n completada!")

        # GUARDAR TODO EN SESSION_STATE para persistir entre recargas
        st.session_state.gpt_costo_total = codificador.gpt.costo_total
        st.session_state.resultados = resultados
        st.session_state.ruta_resultados = ruta_resultados
        st.session_state.ruta_codigos_nuevos = ruta_codigos_nuevos
        st.session_state.codificador = codificador
        st.session_state.codificacion_completada = True

        # Reproducir notificaci√≥n sonora
        st.success("üéâ ¬°Codificaci√≥n completada con √©xito!")
        reproducir_sonido_notificacion()
        st.balloons()  # Efecto visual adicional

        # Limpiar archivos temporales
        ruta_respuestas.unlink()
        if ruta_codigos:
            ruta_codigos.unlink()

    except Exception as e:
        st.error(f"‚ùå Error durante la codificaci√≥n: {e}")
        import traceback
        st.code(traceback.format_exc())
        progress_bar.progress(0)


def mostrar_resultados(resultados, ruta_resultados, ruta_codigos_nuevos, codificador):
    """Mostrar resultados de la codificaci√≥n"""
    st.header("‚úÖ Codificaci√≥n Completada")
    
    # M√©tricas
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìä Total Respuestas", len(resultados))
    
    with col2:
        total_preguntas = len(codificador.mapeo_columnas)
        st.metric("‚ùì Preguntas Procesadas", total_preguntas)
    
    with col3:
        total_nuevos = len(codificador.codigos_nuevos)
        st.metric("üÜï C√≥digos Nuevos", total_nuevos)
    
    with col4:
        costo = codificador.gpt.costo_total
        st.metric("üí∞ Costo Total", f"${costo:.4f}")
    
    st.markdown("---")
    
    # Descargas
    st.subheader("üì• Descargar Resultados")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üìä Resultados de Codificaci√≥n**")
        try:
            # Generar bytes solo una vez y guardar en session_state
            if 'excel_bytes_resultados' not in st.session_state:
                st.session_state.excel_bytes_resultados = df_a_excel_bytes(resultados)
            
            st.download_button(
                        label="‚¨áÔ∏è Descargar Resultados (.xlsx)",
                        data=st.session_state.excel_bytes_resultados,
                file_name=f"codificacion_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True,
                        key="download_resultados"
                )
            st.caption(f"üíæ Tambi√©n guardado en: `{ruta_resultados}`")
        except Exception as e:
            st.error(f"‚ùå Error preparando descarga: {e}")
    
    with col2:
        if ruta_codigos_nuevos:
            st.markdown("**üÜï Cat√°logo de C√≥digos Nuevos**")
            try:
                # Leer archivo solo una vez y guardar en session_state
                if 'excel_bytes_codigos_nuevos' not in st.session_state:
                    with open(ruta_codigos_nuevos, "rb") as f:
                        st.session_state.excel_bytes_codigos_nuevos = f.read()
                
                st.download_button(
                    label="‚¨áÔ∏è Descargar C√≥digos Nuevos (.xlsx)",
                    data=st.session_state.excel_bytes_codigos_nuevos,
                    file_name=f"codigos_nuevos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                    key="download_codigos_nuevos"
                )
                st.caption(f"üíæ Tambi√©n guardado en: `{ruta_codigos_nuevos}`")
            except Exception as e:
                st.error(f"‚ùå Error preparando descarga: {e}")
        else:
            st.info("‚ÑπÔ∏è No se generaron c√≥digos nuevos")

    
    # Vista previa
    st.markdown("---")
    st.subheader("üëÅÔ∏è Vista Previa de Resultados")
    
    with st.expander("Ver primeras 20 filas"):
        st.dataframe(resultados.head(20), use_container_width=True)
    
    # Estad√≠sticas por pregunta
    st.markdown("---")
    st.subheader("üìà Estad√≠sticas por Pregunta")
    
    for columna, pregunta in codificador.mapeo_columnas.items():
        with st.expander(f"üìã {pregunta}"):
            col1, col2, col3 = st.columns(3)
            
            # Contar decisiones
            col_decision = f"{pregunta}_decision"
            if col_decision in resultados.columns:
                decisiones = resultados[col_decision].value_counts()
                
                with col1:
                    st.metric("‚úÖ Asignados", decisiones.get('asignar', 0))
                
                with col2:
                    st.metric("üÜï Nuevos", decisiones.get('nuevo', 0))
                
                with col3:
                    st.metric("‚ùå Rechazados", decisiones.get('rechazar', 0))
                
                # Gr√°fico
                if len(decisiones) > 0:
                    fig = px.pie(
                        values=decisiones.values,
                        names=decisiones.index,
                        title=f"Distribuci√≥n de Decisiones - {pregunta}"
                    )
                    st.plotly_chart(fig, use_container_width=True)


def mostrar_estado():
    """Mostrar estado del sistema"""
    # Estado
    st.metric("Estado", "üü¢ Activo")
    
    # Modo
    if USE_GPT_MOCK:
        st.metric("Modo", "üß™ MOCK")
    else:
        st.metric("Modo", "‚ö° REAL")
    
    # Modelo
    st.metric("Modelo GPT", OPENAI_MODEL)
    


def df_a_excel_bytes(df: pd.DataFrame) -> bytes:
    """Convertir DataFrame a bytes de Excel"""
    buffer = BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="Codificacion")
    buffer.seek(0)
    return buffer.getvalue()


if __name__ == "__main__":
    main()
