{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Grafo V3: Evaluaci√≥n Booleana Exhaustiva\n",
    "\n",
    "Este notebook implementa **la versi√≥n m√°s robusta** con evaluaci√≥n expl√≠cita de TODOS los c√≥digos.\n",
    "\n",
    "## üéØ Mejoras sobre V2\n",
    "\n",
    "**Problema en V2:** Si encuentra 1 c√≥digo hist√≥rico, NO genera nuevos ‚Üí Pierde conceptos\n",
    "\n",
    "**Soluci√≥n en V3:**\n",
    "- ‚úÖ Eval√∫a **TODOS** los c√≥digos con True/False + confianza\n",
    "- ‚úÖ Identifica **gaps de cobertura** (qu√© NO est√° cubierto)\n",
    "- ‚úÖ Captura casos **mixtos** naturalmente\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Instalaci√≥n de Dependencias\n",
    "\n",
    "Si encuentras errores de import, ejecuta esta celda:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grandalf in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (0.8)\n",
      "Requirement already satisfied: langchain in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: langgraph in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: tenacity in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (9.1.2)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from grandalf) (3.2.3)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.6 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain) (1.0.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langgraph) (1.0.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (0.4.44)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.6->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain-openai) (2.8.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.8.29)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "üí° Si necesitas instalar dependencias, descomenta la l√≠nea de arriba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta esto si tienes errores de import\n",
    "%pip install grandalf langchain langchain-openai langgraph python-dotenv pandas openpyxl tenacity\n",
    "\n",
    "print(\"üí° Si necesitas instalar dependencias, descomenta la l√≠nea de arriba\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Utilidades y mejoras cargadas\n"
     ]
    }
   ],
   "source": [
    "# üõ†Ô∏è UTILIDADES Y MEJORAS\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "import re\n",
    "from typing import Tuple, Optional, List, Dict\n",
    "\n",
    "# ========== 1. RETRY LOGIC ==========\n",
    "def llamada_llm_con_retry(chain, input_data, max_intentos=3):\n",
    "    \"\"\"\n",
    "    Ejecuta una llamada al LLM con retry autom√°tico en caso de error.\n",
    "    \n",
    "    Args:\n",
    "        chain: Cadena de LangChain a ejecutar\n",
    "        input_data: Datos de entrada para el chain\n",
    "        max_intentos: N√∫mero m√°ximo de intentos (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        Resultado de la llamada al LLM\n",
    "    \"\"\"\n",
    "    @retry(\n",
    "        stop=stop_after_attempt(max_intentos),\n",
    "        wait=wait_exponential(multiplier=1, min=2, max=10),\n",
    "        retry=retry_if_exception_type((Exception,)),\n",
    "        reraise=True\n",
    "    )\n",
    "    def _intentar_llamada():\n",
    "        try:\n",
    "            return chain.invoke(input_data)\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Error en LLM: {type(e).__name__}, reintentando...\")\n",
    "            raise\n",
    "    \n",
    "    return _intentar_llamada()\n",
    "\n",
    "# ========== 2. DETECCI√ìN TEMPRANA DE RESPUESTAS ESPECIALES ==========\n",
    "PATRONES_ESPECIALES = {\n",
    "    # Patrones para c√≥digo 90: Ninguno\n",
    "    r'\\b(ninguno|ninguna|nada de eso|ninguno de|ninguna de)\\b': 90,\n",
    "    # Patrones para c√≥digo 91: No Recuerda\n",
    "    r'\\b(no recuerdo|no me acuerdo|no recuerdo|olvid√©|olvid√©)\\b': 91,\n",
    "    # Patrones para c√≥digo 92: No Sabe\n",
    "    r'\\b(no s√©|no se|no conozco|no tengo idea|no lo s√©|no lo se)\\b': 92,\n",
    "    # Patrones para c√≥digo 93: No Responde\n",
    "    r'^[\\s\\-\\.]+$|^$': 93,  # Vac√≠o, solo espacios, guiones o puntos\n",
    "    # Patrones para c√≥digo 94: Cualquiera\n",
    "    r'\\b(cualquiera|cualquier|da igual|me da igual|es igual)\\b': 94,\n",
    "    # Patrones para c√≥digo 95: Todos\n",
    "    r'\\b(todos|todas|todos los|todas las)\\b': 95,\n",
    "    # Patrones para c√≥digo 96: No Aplica\n",
    "    r'\\b(no aplica|no corresponde|no es para m√≠|no es mi caso)\\b': 96,\n",
    "    # Patrones para c√≥digo 97: Ning√∫n Otro\n",
    "    r'\\b(ning√∫n otro|ninguna otra|ninguno m√°s|ninguna m√°s)\\b': 97,\n",
    "    # Patrones para c√≥digo 98: Nada\n",
    "    r'^\\s*(nada|nada m√°s|nada en particular|nada especial)\\s*$': 98,\n",
    "}\n",
    "\n",
    "def detectar_codigo_especial(texto: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Detecta si una respuesta corresponde a un c√≥digo especial (90-98).\n",
    "    \n",
    "    Args:\n",
    "        texto: Texto de la respuesta a analizar\n",
    "    \n",
    "    Returns:\n",
    "        C√≥digo especial si se detecta, None en caso contrario\n",
    "    \"\"\"\n",
    "    texto_lower = texto.lower().strip()\n",
    "    \n",
    "    # Verificar patrones\n",
    "    for patron, codigo in PATRONES_ESPECIALES.items():\n",
    "        if re.search(patron, texto_lower, re.IGNORECASE):\n",
    "            return codigo\n",
    "    \n",
    "    return None\n",
    "\n",
    "# ========== 3. DEDUPLICACI√ìN DE C√ìDIGOS SIMILARES ==========\n",
    "def normalizar_texto(texto: str) -> str:\n",
    "    \"\"\"Normaliza texto para comparaci√≥n (lowercase, sin acentos b√°sicos)\"\"\"\n",
    "    texto = texto.lower().strip()\n",
    "    # Reemplazos b√°sicos\n",
    "    texto = texto.replace(\"√°\", \"a\").replace(\"√©\", \"e\").replace(\"√≠\", \"i\").replace(\"√≥\", \"o\").replace(\"√∫\", \"u\")\n",
    "    return texto\n",
    "\n",
    "def son_conceptos_similares(desc1: str, desc2: str) -> bool:\n",
    "    \"\"\"\n",
    "    Determina si dos descripciones representan el mismo concepto.\n",
    "    \n",
    "    Args:\n",
    "        desc1: Primera descripci√≥n\n",
    "        desc2: Segunda descripci√≥n\n",
    "    \n",
    "    Returns:\n",
    "        True si son similares, False en caso contrario\n",
    "    \"\"\"\n",
    "    # Definir palabras comunes al inicio\n",
    "    palabras_comunes = [\"para\", \"de\", \"en\", \"con\", \"sin\", \"por\", \"la\", \"el\", \"un\", \"una\"]\n",
    "    \n",
    "    desc1_norm = normalizar_texto(desc1)\n",
    "    desc2_norm = normalizar_texto(desc2)\n",
    "    \n",
    "    # Coincidencia exacta\n",
    "    if desc1_norm == desc2_norm:\n",
    "        return True\n",
    "    \n",
    "    # Una contiene a la otra (concepto m√°s general vs espec√≠fico)\n",
    "    if desc1_norm in desc2_norm or desc2_norm in desc1_norm:\n",
    "        # Verificar que no sea solo una palabra com√∫n\n",
    "        if desc1_norm not in palabras_comunes and desc2_norm not in palabras_comunes:\n",
    "            return True\n",
    "    \n",
    "    # Palabras clave similares (ej: \"saludable\", \"salud\", \"salubre\")\n",
    "    palabras1 = set(desc1_norm.split())\n",
    "    palabras2 = set(desc2_norm.split())\n",
    "    \n",
    "    # Si comparten m√°s del 50% de palabras significativas\n",
    "    palabras_significativas = palabras1 | palabras2\n",
    "    palabras_significativas = {p for p in palabras_significativas if len(p) > 3 and p not in palabras_comunes}\n",
    "    \n",
    "    if palabras_significativas:\n",
    "        interseccion = palabras1 & palabras2\n",
    "        if len(interseccion) / len(palabras_significativas) > 0.5:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def deduplicar_codigos_batch(conceptos_batch: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Deduplica c√≥digos similares dentro de un batch, agrup√°ndolos bajo el mismo c√≥digo.\n",
    "    \n",
    "    Args:\n",
    "        conceptos_batch: Lista de conceptos nuevos generados en el batch\n",
    "    \n",
    "    Returns:\n",
    "        Lista de conceptos deduplicados\n",
    "    \"\"\"\n",
    "    if not conceptos_batch:\n",
    "        return []\n",
    "    \n",
    "    # Agrupar conceptos similares\n",
    "    grupos = []\n",
    "    codigos_usados = {}  # descripcion_normalizada -> (codigo, descripcion_final)\n",
    "    \n",
    "    for concepto in conceptos_batch:\n",
    "        desc = concepto.get(\"descripcion\", \"\")\n",
    "        codigo = concepto.get(\"codigo\")\n",
    "        \n",
    "        # Buscar si ya existe un concepto similar\n",
    "        encontrado = False\n",
    "        for desc_existente, (cod_existente, desc_final) in codigos_usados.items():\n",
    "            if son_conceptos_similares(desc, desc_existente):\n",
    "                # Usar el c√≥digo existente\n",
    "                concepto[\"codigo\"] = cod_existente\n",
    "                concepto[\"descripcion\"] = desc_final  # Usar la descripci√≥n m√°s general\n",
    "                encontrado = True\n",
    "                break\n",
    "        \n",
    "        if not encontrado:\n",
    "            # Nuevo concepto √∫nico\n",
    "            desc_norm = normalizar_texto(desc)\n",
    "            codigos_usados[desc_norm] = (codigo, desc)\n",
    "    \n",
    "    return conceptos_batch\n",
    "\n",
    "# ========== 4. VALIDACI√ìN Y CORRECCI√ìN DE C√ìDIGOS GENERADOS ==========\n",
    "def validar_y_corregir_codigos(conceptos_nuevos: List[Dict], codigo_base: int) -> Tuple[List[Dict], int]:\n",
    "    \"\"\"\n",
    "    Valida y corrige c√≥digos generados para asegurar secuencialidad.\n",
    "    \n",
    "    Args:\n",
    "        conceptos_nuevos: Lista de conceptos nuevos generados por el LLM\n",
    "        codigo_base: C√≥digo base esperado para empezar\n",
    "    \n",
    "    Returns:\n",
    "        Tupla con (conceptos_corregidos, siguiente_codigo)\n",
    "    \"\"\"\n",
    "    if not conceptos_nuevos:\n",
    "        return [], codigo_base\n",
    "    \n",
    "    conceptos_corregidos = []\n",
    "    codigo_actual = codigo_base\n",
    "    \n",
    "    # Ordenar por c√≥digo original para mantener orden l√≥gico\n",
    "    conceptos_ordenados = sorted(conceptos_nuevos, key=lambda x: x.get(\"codigo\", codigo_actual))\n",
    "    \n",
    "    for concepto in conceptos_ordenados:\n",
    "        codigo_original = concepto.get(\"codigo\", codigo_actual)\n",
    "        \n",
    "        # Si el c√≥digo est√° fuera de secuencia, corregirlo\n",
    "        if codigo_original < codigo_base:\n",
    "            print(f\"   ‚ö†Ô∏è  C√≥digo {codigo_original} fuera de secuencia, corrigiendo a {codigo_actual}\")\n",
    "            concepto[\"codigo\"] = codigo_actual\n",
    "        elif codigo_original != codigo_actual:\n",
    "            # Si hay un salto, usar el c√≥digo actual\n",
    "            print(f\"   ‚ö†Ô∏è  Salto en secuencia: {codigo_original} -> {codigo_actual}, corrigiendo\")\n",
    "            concepto[\"codigo\"] = codigo_actual\n",
    "        \n",
    "        conceptos_corregidos.append(concepto)\n",
    "        codigo_actual += 1\n",
    "    \n",
    "    return conceptos_corregidos, codigo_actual\n",
    "\n",
    "# ========== 4. M√âTRICAS Y LOGGING ==========\n",
    "def inicializar_metricas() -> Dict:\n",
    "    \"\"\"Inicializa el diccionario de m√©tricas\"\"\"\n",
    "    return {\n",
    "        \"inicio_tiempo\": time.time(),\n",
    "        \"llamadas_llm\": 0,\n",
    "        \"errores_llm\": 0,\n",
    "        \"reintentos\": 0,\n",
    "        \"respuestas_especiales_detectadas\": 0,\n",
    "        \"codigos_corregidos\": 0,\n",
    "        \"tokens_estimados\": 0,\n",
    "        \"tiempo_por_nodo\": {}\n",
    "    }\n",
    "\n",
    "def registrar_tiempo_nodo(metricas: Dict, nombre_nodo: str, tiempo: float):\n",
    "    \"\"\"Registra el tiempo de ejecuci√≥n de un nodo\"\"\"\n",
    "    if nombre_nodo not in metricas[\"tiempo_por_nodo\"]:\n",
    "        metricas[\"tiempo_por_nodo\"][nombre_nodo] = []\n",
    "    metricas[\"tiempo_por_nodo\"][nombre_nodo].append(tiempo)\n",
    "\n",
    "def imprimir_metricas(metricas: Dict):\n",
    "    \"\"\"Imprime un resumen de las m√©tricas\"\"\"\n",
    "    tiempo_total = time.time() - metricas[\"inicio_tiempo\"]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìä M√âTRICAS DE EJECUCI√ìN\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"‚è±Ô∏è  Tiempo total: {tiempo_total:.2f}s\")\n",
    "    print(f\"ü§ñ Llamadas LLM: {metricas['llamadas_llm']}\")\n",
    "    print(f\"‚ùå Errores LLM: {metricas['errores_llm']}\")\n",
    "    print(f\"üîÑ Reintentos: {metricas['reintentos']}\")\n",
    "    print(f\"üéØ Respuestas especiales detectadas: {metricas['respuestas_especiales_detectadas']}\")\n",
    "    print(f\"üîß C√≥digos corregidos: {metricas['codigos_corregidos']}\")\n",
    "    \n",
    "    if metricas[\"tiempo_por_nodo\"]:\n",
    "        print(f\"\\n‚è±Ô∏è  Tiempo por nodo:\")\n",
    "        for nodo, tiempos in metricas[\"tiempo_por_nodo\"].items():\n",
    "            promedio = sum(tiempos) / len(tiempos)\n",
    "            total = sum(tiempos)\n",
    "            print(f\"   ‚Ä¢ {nodo}: {promedio:.2f}s promedio ({total:.2f}s total, {len(tiempos)} ejecuciones)\")\n",
    "\n",
    "print(\"‚úÖ Utilidades y mejoras cargadas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup completo\n",
      "üìÇ Ruta del proyecto: c:\\Users\\ivan\\Documents\\cod-script\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import TypedDict, List, Dict, Literal, Optional\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Configurar paths\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root / \"backend\" / \"src\"))\n",
    "\n",
    "# Cargar variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / \".env\")\n",
    "\n",
    "# Verificar API key\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"‚ùå Falta OPENAI_API_KEY en .env\"\n",
    "\n",
    "# Imports de LangChain\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "print(\"‚úÖ Setup completo\")\n",
    "print(f\"üìÇ Ruta del proyecto: {project_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Archivo: P2 - copia.xlsx\n",
      "üìö Cat√°logo: ‚ùå No\n",
      "ü§ñ Modelo: gpt-5\n",
      "üî¢ C√≥digos especiales: 9 (90-98)\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURACI√ìN\n",
    "ARCHIVO_RESPUESTAS = project_root / \"temp\" / \"P2 - copia.xlsx\"\n",
    "USAR_CATALOGO_HISTORICO = False\n",
    "ARCHIVO_CATALOGO = project_root / \"result\" / \"modelos\" / \"catalogo_propuestos.xlsx\"\n",
    "MAX_RESPUESTAS = None\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# üÜï MODO DATO AUXILIAR (Din√°mico - sin categor√≠as hardcodeadas)\n",
    "# Formato del archivo con dato auxiliar:\n",
    "# - Columna 1: ID\n",
    "# - Columna 2: Pregunta (opcional, para referencia)\n",
    "# - Columna 3: Respuesta abierta\n",
    "# - Columna 4: Dato auxiliar (categor√≠a - puede ser cualquier valor: \"Desconfianza\", \"Felicidad\", \"Categor√≠a A\", etc.)\n",
    "# \n",
    "# El sistema identificar√° autom√°ticamente las categor√≠as desde el dato auxiliar y generar√°\n",
    "# c√≥digos secuenciales independientes para cada categor√≠a.\n",
    "USAR_DATO_AUXILIAR = False  # Cambiar a True si el archivo tiene datos auxiliares\n",
    "\n",
    "# Modelos disponibles: \"gpt-5\", \"gpt-4o\", \"gpt-4o-mini\", \"gpt-4-turbo\"\n",
    "MODELO_GPT = \"gpt-5\"  # üÜï GPT-5 disponible desde 2025\n",
    "\n",
    "# C√ìDIGOS ESPECIALES (siempre disponibles)\n",
    "CODIGOS_ESPECIALES = [\n",
    "    {\"codigo\": 90, \"descripcion\": \"Ninguno\", \"seccion\": None, \"seccion_clave\": None},\n",
    "    {\"codigo\": 91, \"descripcion\": \"No Recuerda\", \"seccion\": None, \"seccion_clave\": None},\n",
    "    {\"codigo\": 92, \"descripcion\": \"No Sabe\", \"seccion\": None, \"seccion_clave\": None},\n",
    "    {\"codigo\": 93, \"descripcion\": \"No Responde\", \"seccion\": None, \"seccion_clave\": None},\n",
    "    {\"codigo\": 94, \"descripcion\": \"Cualquiera\", \"seccion\": None, \"seccion_clave\": None},\n",
    "    {\"codigo\": 95, \"descripcion\": \"Todos\", \"seccion\": None, \"seccion_clave\": None},\n",
    "    {\"codigo\": 96, \"descripcion\": \"No Aplica\", \"seccion\": None, \"seccion_clave\": None},\n",
    "    {\"codigo\": 97, \"descripcion\": \"Ning√∫n Otro\", \"seccion\": None, \"seccion_clave\": None},\n",
    "    {\"codigo\": 98, \"descripcion\": \"Nada\", \"seccion\": None, \"seccion_clave\": None}\n",
    "]\n",
    "\n",
    "print(f\"üìÑ Archivo: {ARCHIVO_RESPUESTAS.name}\")\n",
    "print(f\"üìö Cat√°logo: {'‚úÖ S√≠' if USAR_CATALOGO_HISTORICO else '‚ùå No'}\")\n",
    "print(f\"ü§ñ Modelo: {MODELO_GPT}\")\n",
    "print(f\"üî¢ C√≥digos especiales: {len(CODIGOS_ESPECIALES)} (90-98)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Respuestas cargadas: 14\n",
      "‚úÖ Pregunta: P2\n",
      "‚ö†Ô∏è  Sin cat√°logo hist√≥rico\n",
      "‚úÖ Cat√°logo final: 9 c√≥digos (incluye c√≥digos especiales 90-98)\n"
     ]
    }
   ],
   "source": [
    "def cargar_respuestas(archivo_excel, max_respuestas=None):\n",
    "    \"\"\"\n",
    "    Carga respuestas del Excel\n",
    "    \n",
    "    Formato:\n",
    "    - Primera columna = ID\n",
    "    - Segunda columna = Respuestas\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(archivo_excel)\n",
    "    \n",
    "    # Primera columna = ID\n",
    "    columna_id = df.columns[0]\n",
    "    # Segunda columna = Respuestas\n",
    "    columna_respuestas = df.columns[1]\n",
    "    nombre_pregunta = columna_respuestas\n",
    "    \n",
    "    respuestas = []\n",
    "    for idx, row in df.iterrows():\n",
    "        texto = str(row[columna_respuestas]).strip()\n",
    "        if texto and texto.lower() not in ['nan', 'none', '-', '.']:\n",
    "            # Obtener ID de la primera columna\n",
    "            id_valor = row[columna_id]\n",
    "            if pd.isna(id_valor):\n",
    "                id_valor = idx + 1\n",
    "            \n",
    "            respuestas.append({\n",
    "                \"id\": id_valor,\n",
    "                \"fila_excel\": idx + 2,\n",
    "                \"texto\": texto\n",
    "            })\n",
    "        \n",
    "        if max_respuestas and len(respuestas) >= max_respuestas:\n",
    "            break\n",
    "    \n",
    "    return respuestas, nombre_pregunta\n",
    "\n",
    "def cargar_catalogo(archivo_catalogo, nombre_pregunta):\n",
    "    \"\"\"Carga cat√°logo hist√≥rico de la hoja que coincida con el nombre\"\"\"\n",
    "    try:\n",
    "        # Intentar cargar el archivo\n",
    "        excel_file = pd.ExcelFile(archivo_catalogo)\n",
    "        hojas_disponibles = excel_file.sheet_names\n",
    "        \n",
    "        print(f\"\\nüìö Hojas disponibles en cat√°logo:\")\n",
    "        for hoja in hojas_disponibles:\n",
    "            print(f\"   ‚Ä¢ {hoja}\")\n",
    "        \n",
    "        # Buscar hoja que coincida con la pregunta\n",
    "        hoja_encontrada = None\n",
    "        \n",
    "        # B√∫squeda exacta\n",
    "        if nombre_pregunta in hojas_disponibles:\n",
    "            hoja_encontrada = nombre_pregunta\n",
    "        else:\n",
    "            # B√∫squeda flexible (normalizar nombres)\n",
    "            nombre_norm = nombre_pregunta.lower().strip()\n",
    "            for hoja in hojas_disponibles:\n",
    "                hoja_norm = hoja.lower().strip()\n",
    "                if nombre_norm in hoja_norm or hoja_norm in nombre_norm:\n",
    "                    hoja_encontrada = hoja\n",
    "                    break\n",
    "        \n",
    "        if not hoja_encontrada:\n",
    "            print(f\"\\n‚ö†Ô∏è  No se encontr√≥ hoja para: '{nombre_pregunta}'\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"\\n‚úÖ Usando hoja: '{hoja_encontrada}'\")\n",
    "        \n",
    "        # Cargar cat√°logo\n",
    "        df = pd.read_excel(archivo_catalogo, sheet_name=hoja_encontrada)\n",
    "        \n",
    "        if 'COD' not in df.columns or 'TEXTO' not in df.columns:\n",
    "            print(f\"‚ö†Ô∏è  Hoja sin columnas COD/TEXTO\")\n",
    "            return []\n",
    "        \n",
    "        catalogo = []\n",
    "        for _, row in df.iterrows():\n",
    "            if pd.notna(row['COD']) and pd.notna(row['TEXTO']):\n",
    "                codigo = int(row['COD'])\n",
    "                # Evitar duplicar c√≥digos especiales\n",
    "                if codigo not in [c[\"codigo\"] for c in CODIGOS_ESPECIALES]:\n",
    "                    catalogo.append({\n",
    "                        \"codigo\": codigo,\n",
    "                        \"descripcion\": str(row['TEXTO']).strip()\n",
    "                    })\n",
    "        \n",
    "        # SIEMPRE agregar c√≥digos especiales al final\n",
    "        catalogo.extend(CODIGOS_ESPECIALES)\n",
    "        \n",
    "        print(f\"‚úÖ Cat√°logo cargado: {len(catalogo)} c√≥digos (incluye {len(CODIGOS_ESPECIALES)} c√≥digos especiales)\")\n",
    "        return catalogo\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error al cargar cat√°logo: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Cargar datos\n",
    "respuestas_reales, nombre_pregunta = cargar_respuestas(ARCHIVO_RESPUESTAS, MAX_RESPUESTAS)\n",
    "print(f\"‚úÖ Respuestas cargadas: {len(respuestas_reales)}\")\n",
    "print(f\"‚úÖ Pregunta: {nombre_pregunta}\")\n",
    "\n",
    "if USAR_CATALOGO_HISTORICO:\n",
    "    catalogo_historico = cargar_catalogo(ARCHIVO_CATALOGO, nombre_pregunta)\n",
    "    print(f\"‚úÖ Cat√°logo: {len(catalogo_historico)} c√≥digos\")\n",
    "else:\n",
    "    catalogo_historico = []\n",
    "    print(\"‚ö†Ô∏è  Sin cat√°logo hist√≥rico\")\n",
    "\n",
    "# SIEMPRE agregar c√≥digos especiales al cat√°logo (aunque no haya cat√°logo hist√≥rico)\n",
    "# Evitar duplicados si ya est√°n en el cat√°logo\n",
    "codigos_existentes = {c[\"codigo\"] for c in catalogo_historico}\n",
    "for cod_esp in CODIGOS_ESPECIALES:\n",
    "    if cod_esp[\"codigo\"] not in codigos_existentes:\n",
    "        catalogo_historico.append(cod_esp.copy())\n",
    "        codigos_existentes.add(cod_esp[\"codigo\"])\n",
    "\n",
    "print(f\"‚úÖ Cat√°logo final: {len(catalogo_historico)} c√≥digos (incluye c√≥digos especiales 90-98)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Esquemas Pydantic V3 definidos\n"
     ]
    }
   ],
   "source": [
    "# ESQUEMAS PYDANTIC V3\n",
    "\n",
    "# 1Ô∏è‚É£ Validaci√≥n\n",
    "class ValidacionRespuesta(BaseModel):\n",
    "    respuesta_id: int\n",
    "    es_valida: bool\n",
    "    razon: str\n",
    "\n",
    "class ResultadoValidacion(BaseModel):\n",
    "    validaciones: List[ValidacionRespuesta]\n",
    "\n",
    "# 2Ô∏è‚É£ Evaluaci√≥n Booleana (NUEVO)\n",
    "class EvaluacionCodigo(BaseModel):\n",
    "    codigo: int\n",
    "    aplica: bool  # True/False expl√≠cito\n",
    "    confianza: float = Field(ge=0.0, le=1.0)\n",
    "\n",
    "class EvaluacionCatalogo(BaseModel):\n",
    "    respuesta_id: int\n",
    "    evaluaciones: List[EvaluacionCodigo]\n",
    "\n",
    "class ResultadoEvaluacion(BaseModel):\n",
    "    evaluaciones: List[EvaluacionCatalogo]\n",
    "\n",
    "# 3Ô∏è‚É£ An√°lisis de Cobertura (NUEVO)\n",
    "class ConceptoNuevo(BaseModel):\n",
    "    codigo: int  # ID num√©rico secuencial\n",
    "    descripcion: str\n",
    "    texto_original: str\n",
    "\n",
    "class AnalisisCobertura(BaseModel):\n",
    "    respuesta_id: int\n",
    "    respuesta_cubierta_completamente: bool\n",
    "    conceptos_nuevos: List[ConceptoNuevo] = Field(default_factory=list)\n",
    "\n",
    "class ResultadoCobertura(BaseModel):\n",
    "    analisis: List[AnalisisCobertura]\n",
    "\n",
    "# 4Ô∏è‚É£ Justificaci√≥n\n",
    "class Justificacion(BaseModel):\n",
    "    respuesta_id: int\n",
    "    justificacion: str\n",
    "\n",
    "class ResultadoJustificacion(BaseModel):\n",
    "    justificaciones: List[Justificacion]\n",
    "\n",
    "print(\"‚úÖ Esquemas Pydantic V3 definidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Nodo validar definido\n"
     ]
    }
   ],
   "source": [
    "# NODO 1: VALIDAR (con detecci√≥n temprana de c√≥digos especiales)\n",
    "def nodo_validar(state):\n",
    "    inicio_tiempo = time.time()\n",
    "    print(f\"\\n‚úÖ Validando {len(state['batch_respuestas'])} respuestas...\")\n",
    "    \n",
    "    # üÜï MEJORA: Detecci√≥n temprana de c√≥digos especiales\n",
    "    respuestas_para_validar = []\n",
    "    respuestas_especiales = {}  # respuesta_id -> codigo_especial\n",
    "    \n",
    "    for i, resp in enumerate(state[\"batch_respuestas\"]):\n",
    "        codigo_especial = detectar_codigo_especial(resp[\"texto\"])\n",
    "        if codigo_especial:\n",
    "            respuestas_especiales[i + 1] = codigo_especial\n",
    "            # Actualizar m√©tricas\n",
    "            if \"metricas\" in state:\n",
    "                state[\"metricas\"][\"respuestas_especiales_detectadas\"] += 1\n",
    "            print(f\"   üéØ Respuesta {i+1} detectada como c√≥digo especial {codigo_especial}\")\n",
    "        else:\n",
    "            respuestas_para_validar.append((i, resp))\n",
    "    \n",
    "    # Si todas son especiales, crear validaciones directamente\n",
    "    if not respuestas_para_validar:\n",
    "        validaciones = []\n",
    "        for i, resp in enumerate(state[\"batch_respuestas\"]):\n",
    "            codigo_esp = respuestas_especiales.get(i + 1)\n",
    "            validaciones.append({\n",
    "                \"respuesta_id\": i + 1,\n",
    "                \"es_valida\": True,  # Las especiales son v√°lidas\n",
    "                \"razon\": f\"C√≥digo especial {codigo_esp} detectado autom√°ticamente\"\n",
    "            })\n",
    "        \n",
    "        tiempo_nodo = time.time() - inicio_tiempo\n",
    "        if \"metricas\" in state:\n",
    "            registrar_tiempo_nodo(state[\"metricas\"], \"validar\", tiempo_nodo)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"validaciones_batch\": validaciones,\n",
    "            \"respuestas_especiales\": respuestas_especiales  # Guardar para usar despu√©s\n",
    "        }\n",
    "    \n",
    "    # Validar las que no son especiales con LLM\n",
    "    respuestas_str = \"\\n\".join([\n",
    "        f\"{i+1}. {r['texto']}\"\n",
    "        for i, r in respuestas_para_validar\n",
    "    ])\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Eres un experto en filtrar respuestas de encuestas.\n",
    "\n",
    "RECHAZAR si:\n",
    "- Est√° vac√≠a o solo tiene \\\"-\\\" o \\\".\\\"\n",
    "- Es incomprensible\n",
    "- No responde a la pregunta\n",
    "\n",
    "ACEPTAR si tiene contenido relevante. Responde en JSON.\"\"\"),\n",
    "        (\"user\", \"PREGUNTA: {pregunta}\\n\\nRESPUESTAS:\\n{respuestas}\")\n",
    "    ])\n",
    "    \n",
    "    llm = ChatOpenAI(model=state[\"modelo_gpt\"], temperature=0)\n",
    "    chain = prompt | llm.with_structured_output(ResultadoValidacion)\n",
    "    \n",
    "    # üÜï MEJORA: Usar retry\n",
    "    try:\n",
    "        if \"metricas\" in state:\n",
    "            state[\"metricas\"][\"llamadas_llm\"] += 1\n",
    "        resultado = llamada_llm_con_retry(chain, {\n",
    "            \"pregunta\": state[\"pregunta\"],\n",
    "            \"respuestas\": respuestas_str\n",
    "        })\n",
    "    except Exception as e:\n",
    "        if \"metricas\" in state:\n",
    "            state[\"metricas\"][\"errores_llm\"] += 1\n",
    "        print(f\"   ‚ùå Error en validaci√≥n: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Combinar validaciones: especiales + LLM\n",
    "    validaciones = []\n",
    "    idx_llm = 0\n",
    "    for i, resp in enumerate(state[\"batch_respuestas\"]):\n",
    "        if (i + 1) in respuestas_especiales:\n",
    "            validaciones.append({\n",
    "                \"respuesta_id\": i + 1,\n",
    "                \"es_valida\": True,\n",
    "                \"razon\": f\"C√≥digo especial {respuestas_especiales[i+1]} detectado autom√°ticamente\"\n",
    "            })\n",
    "        else:\n",
    "            validaciones.append(resultado.validaciones[idx_llm].model_dump())\n",
    "            idx_llm += 1\n",
    "    \n",
    "    validas = sum(1 for v in validaciones if v[\"es_valida\"])\n",
    "    print(f\"   ‚úÖ V√°lidas: {validas}/{len(validaciones)}\")\n",
    "    \n",
    "    tiempo_nodo = time.time() - inicio_tiempo\n",
    "    if \"metricas\" in state:\n",
    "        registrar_tiempo_nodo(state[\"metricas\"], \"validar\", tiempo_nodo)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"validaciones_batch\": validaciones,\n",
    "        \"respuestas_especiales\": respuestas_especiales\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Nodo validar definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Nodo evaluar_catalogo_v3 definido\n"
     ]
    }
   ],
   "source": [
    "# NODO 2: EVALUAR_CATALOGO (BOOLEANO EXHAUSTIVO)\n",
    "def nodo_evaluar_catalogo_v3(state):\n",
    "    validas = [\n",
    "        (i, resp) \n",
    "        for i, (resp, val) in enumerate(zip(\n",
    "            state[\"batch_respuestas\"],\n",
    "            state[\"validaciones_batch\"]\n",
    "        ))\n",
    "        if val[\"es_valida\"]\n",
    "    ]\n",
    "    \n",
    "    if not validas or not state[\"catalogo\"]:\n",
    "        print(f\"   ‚ö†Ô∏è  Sin respuestas v√°lidas o sin cat√°logo\")\n",
    "        return {**state, \"evaluaciones_batch\": []}\n",
    "    \n",
    "    print(f\"\\nüìä Evaluando cat√°logo para {len(validas)} respuestas...\")\n",
    "    \n",
    "    respuestas_str = \"\\n\".join([f\"{idx+1}. {resp['texto']}\" for idx, resp in validas])\n",
    "    \n",
    "    # Separar c√≥digos especiales del resto\n",
    "    codigos_normales = [c for c in state[\"catalogo\"] if c[\"codigo\"] < 90]\n",
    "    codigos_especiales = [c for c in state[\"catalogo\"] if c[\"codigo\"] >= 90]\n",
    "    \n",
    "    # Limitar c√≥digos normales a 30 para no saturar el prompt\n",
    "    catalogo_str = \"\\n\".join([\n",
    "        f\"  {c['codigo']}. {c['descripcion']}\"\n",
    "        for c in codigos_normales[:30]\n",
    "    ])\n",
    "    \n",
    "    # Siempre incluir c√≥digos especiales completos\n",
    "    if codigos_especiales:\n",
    "        catalogo_str += \"\\n\\n**C√ìDIGOS ESPECIALES (90-98):**\\n\"\n",
    "        catalogo_str += \"\\n\".join([\n",
    "            f\"  {c['codigo']}. {c['descripcion']}\"\n",
    "            for c in codigos_especiales\n",
    "        ])\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"Eres un experto en codificaci√≥n de respuestas de encuestas.\n",
    "\n",
    "CAT√ÅLOGO HIST√ìRICO:\n",
    "{catalogo_str}\n",
    "\n",
    "**TU TAREA:**\n",
    "Para CADA respuesta, eval√∫a CADA c√≥digo del cat√°logo:\n",
    "- aplica = True: Si el c√≥digo describe el contenido de la respuesta\n",
    "- aplica = False: Si NO es relevante\n",
    "- confianza: 0.0 a 1.0 (qu√© tan seguro est√°s)\n",
    "\n",
    "**REGLAS DE EVALUACI√ìN:**\n",
    "\n",
    "1. **Considera el nivel de especificidad del c√≥digo:**\n",
    "   - Los c√≥digos son GENERALES pero CLAROS\n",
    "   - Ejemplo: Si el c√≥digo dice \"Apto para diabetes\", aplica a respuestas que mencionen diabetes, endulzante para diab√©ticos, etc.\n",
    "   - NO busques coincidencias exactas de palabras, busca la IDEA CENTRAL\n",
    "\n",
    "2. **Una respuesta puede tener m√∫ltiples c√≥digos aplicables:**\n",
    "   - Si la respuesta toca varios temas del cat√°logo, marca aplica=True para TODOS los relevantes\n",
    "   - Ejemplo: \"Es apto para diabetes y no tiene calor√≠as\" ‚Üí aplica=True para \"Apto para diabetes\" Y \"Sin calor√≠as\"\n",
    "\n",
    "3. **Confianza:**\n",
    "   - 0.95-1.0: Coincidencia clara y directa (SOLO estos se aplicar√°n)\n",
    "   - 0.85-0.94: Coincidencia probable pero con alguna variaci√≥n (NO se aplicar√°n)\n",
    "   - <0.85: No aplica (marca aplica=False)\n",
    "\n",
    "4. **S√© MUY CONSERVADOR:**\n",
    "   - Solo marca aplica=True si est√°s MUY seguro (confianza >= 0.95)\n",
    "   - Precisi√≥n > Cobertura: Mejor dejar sin c√≥digo que asignar incorrecto\n",
    "   - El umbral de confianza es ALTO (0.95) para asegurar asignaciones correctas\n",
    "\n",
    "5. **C√ìDIGOS ESPECIALES (90-98):**\n",
    "   - Usa estos c√≥digos cuando la respuesta indique:\n",
    "     * 90 \"Ninguno\": La respuesta dice \"ninguno\", \"ninguna\", \"nada de eso\"\n",
    "     * 91 \"No Recuerda\": La respuesta dice \"no recuerdo\", \"no me acuerdo\"\n",
    "     * 92 \"No Sabe\": La respuesta dice \"no s√©\", \"no conozco\", \"no tengo idea\"\n",
    "     * 93 \"No Responde\": La respuesta est√° vac√≠a, es \"-\", \".\", o no responde\n",
    "     * 94 \"Cualquiera\": La respuesta dice \"cualquiera\", \"cualquier\", \"da igual\"\n",
    "     * 95 \"Todos\": La respuesta dice \"todos\", \"todas\", \"todos los\"\n",
    "     * 96 \"No Aplica\": La respuesta indica que la pregunta no aplica a su caso\n",
    "     * 97 \"Ning√∫n Otro\": La respuesta dice \"ning√∫n otro\", \"ninguna otra\"\n",
    "     * 98 \"Nada\": La respuesta dice \"nada\", \"nada m√°s\", \"nada en particular\"\n",
    "   - Estos c√≥digos pueden aplicarse SOLOS o junto con otros c√≥digos seg√∫n el contexto\n",
    "\n",
    "Eval√∫a TODOS los c√≥digos para TODAS las respuestas.\n",
    "Responde en JSON.\"\"\"),\n",
    "        (\"user\", \"PREGUNTA: {pregunta}\\n\\nRESPUESTAS:\\n{respuestas}\")\n",
    "    ])\n",
    "    \n",
    "    llm = ChatOpenAI(model=state[\"modelo_gpt\"], temperature=0)\n",
    "    chain = prompt | llm.with_structured_output(ResultadoEvaluacion)\n",
    "    \n",
    "    # üÜï MEJORA: Usar retry y m√©tricas\n",
    "    inicio_tiempo = time.time()\n",
    "    try:\n",
    "        if \"metricas\" in state:\n",
    "            state[\"metricas\"][\"llamadas_llm\"] += 1\n",
    "        resultado = llamada_llm_con_retry(chain, {\n",
    "            \"pregunta\": state[\"pregunta\"],\n",
    "            \"respuestas\": respuestas_str\n",
    "        })\n",
    "    except Exception as e:\n",
    "        if \"metricas\" in state:\n",
    "            state[\"metricas\"][\"errores_llm\"] += 1\n",
    "        print(f\"   ‚ùå Error en evaluaci√≥n: {e}\")\n",
    "        raise\n",
    "    \n",
    "    matches = sum(\n",
    "        1 for ev in resultado.evaluaciones\n",
    "        for cod in ev.evaluaciones\n",
    "        if cod.aplica and cod.confianza >= 0.95\n",
    "    )\n",
    "    \n",
    "    print(f\"   ‚úÖ Matches (confianza >= 0.95): {matches}\")\n",
    "    \n",
    "    tiempo_nodo = time.time() - inicio_tiempo\n",
    "    if \"metricas\" in state:\n",
    "        registrar_tiempo_nodo(state[\"metricas\"], \"evaluar_catalogo\", tiempo_nodo)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"evaluaciones_batch\": [ev.model_dump() for ev in resultado.evaluaciones]\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Nodo evaluar_catalogo_v3 definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Nodo identificar_conceptos_v3 definido\n"
     ]
    }
   ],
   "source": [
    "# NODO 3: IDENTIFICAR_CONCEPTOS_NUEVOS (DETECTAR GAPS)\n",
    "def nodo_identificar_conceptos_v3(state):\n",
    "    # Obtener TODAS las respuestas v√°lidas (con o sin cat√°logo)\n",
    "    validas_con_eval = []\n",
    "    \n",
    "    for i, (resp, val) in enumerate(zip(\n",
    "        state[\"batch_respuestas\"],\n",
    "        state[\"validaciones_batch\"]\n",
    "    )):\n",
    "        if not val[\"es_valida\"]:\n",
    "            continue\n",
    "        \n",
    "        resp_id = i + 1\n",
    "        \n",
    "        # Buscar evaluaci√≥n (puede estar vac√≠o si no hay cat√°logo)\n",
    "        evaluacion = next(\n",
    "            (ev for ev in state[\"evaluaciones_batch\"] if ev[\"respuesta_id\"] == resp_id),\n",
    "            None\n",
    "        )\n",
    "        \n",
    "        if evaluacion:\n",
    "            # Hay cat√°logo: obtener c√≥digos aplicados (solo con confianza >= 0.95)\n",
    "            codigos_aplicados = [\n",
    "                cod[\"codigo\"] for cod in evaluacion[\"evaluaciones\"]\n",
    "                if cod[\"aplica\"] and cod[\"confianza\"] >= 0.95\n",
    "            ]\n",
    "        else:\n",
    "            # NO hay cat√°logo o no hay evaluaci√≥n: c√≥digos_asignados = []\n",
    "            codigos_aplicados = []\n",
    "        \n",
    "        # SIEMPRE agregar la respuesta v√°lida (con o sin c√≥digos hist√≥ricos)\n",
    "        validas_con_eval.append({\n",
    "            \"respuesta_id\": resp_id,\n",
    "            \"texto\": resp[\"texto\"],\n",
    "            \"codigos_asignados\": codigos_aplicados\n",
    "        })\n",
    "    \n",
    "    if not validas_con_eval:\n",
    "        print(f\"   ‚ö†Ô∏è  Sin respuestas v√°lidas\")\n",
    "        return {**state, \"cobertura_batch\": []}\n",
    "    \n",
    "    # Usar el contador global de c√≥digos nuevos\n",
    "    codigo_base = state[\"proximo_codigo_nuevo\"]\n",
    "    \n",
    "    print(f\"\\nüîç Analizando cobertura para {len(validas_con_eval)} respuestas...\")\n",
    "    print(f\"   (C√≥digos nuevos empezar√°n desde: {codigo_base})\")\n",
    "    \n",
    "    # Recolectar c√≥digos ya creados en batches anteriores para evitar duplicados\n",
    "    codigos_ya_creados = {}\n",
    "    if state.get(\"codificaciones\"):\n",
    "        for cod in state[\"codificaciones\"]:\n",
    "            if cod.get(\"codigos_nuevos\"):\n",
    "                for nuevo in cod[\"codigos_nuevos\"]:\n",
    "                    cod_id = nuevo.get(\"codigo\")\n",
    "                    desc = nuevo.get(\"descripcion\", \"\")\n",
    "                    if cod_id and desc:\n",
    "                        codigos_ya_creados[cod_id] = desc\n",
    "    \n",
    "    # Construir string de c√≥digos ya creados para el prompt\n",
    "    codigos_existentes_str = \"\"\n",
    "    if codigos_ya_creados:\n",
    "        codigos_existentes_str = \"\\n**C√ìDIGOS NUEVOS YA CREADOS EN BATCHES ANTERIORES:**\\n\"\n",
    "        for cod_id in sorted(codigos_ya_creados.keys()):\n",
    "            codigos_existentes_str += f\"  {cod_id}: {codigos_ya_creados[cod_id]}\\n\"\n",
    "        codigos_existentes_str += \"\\n**IMPORTANTE:** Si encuentras un concepto similar a uno de estos, NO crees un c√≥digo nuevo. El sistema los agrupar√° despu√©s.\\n\"\n",
    "    \n",
    "    respuestas_str = \"\"\n",
    "    for item in validas_con_eval:\n",
    "        resp_id = item[\"respuesta_id\"]\n",
    "        texto = item[\"texto\"]\n",
    "        codigos = item[\"codigos_asignados\"]\n",
    "        \n",
    "        if codigos and state[\"catalogo\"]:\n",
    "            # Hay c√≥digos asignados: mostrar descripciones\n",
    "            descrips = []\n",
    "            for cod_id in codigos:\n",
    "                desc = next(\n",
    "                    (c[\"descripcion\"] for c in state[\"catalogo\"] if c[\"codigo\"] == cod_id),\n",
    "                    f\"C√≥digo {cod_id}\"\n",
    "                )\n",
    "                descrips.append(f\"[{cod_id}: {desc}]\")\n",
    "            \n",
    "            respuestas_str += f\"{resp_id}. \\\"{texto}\\\"\\n   C√≥digos asignados: {', '.join(descrips)}\\n\\n\"\n",
    "        else:\n",
    "            # NO hay c√≥digos: toda la respuesta necesita c√≥digos nuevos\n",
    "            respuestas_str += f\"{resp_id}. \\\"{texto}\\\"\\n   C√≥digos asignados: NINGUNO (generar c√≥digos para TODA la respuesta)\\n\\n\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"Eres un experto en codificaci√≥n de respuestas de encuestas de opini√≥n p√∫blica.\n",
    "\n",
    "**PREGUNTA DE LA ENCUESTA:**\n",
    "{{pregunta}}\n",
    "\n",
    "**PROCESO DE TRABAJO - SEGUIR EN ESTE ORDEN:**\n",
    "\n",
    "**PASO 1: LEE TODAS LAS RESPUESTAS PRIMERO**\n",
    "- Antes de crear cualquier c√≥digo, lee y analiza TODAS las respuestas del batch\n",
    "- Identifica los conceptos √∫nicos que aparecen en todas las respuestas\n",
    "- NO crees c√≥digos de forma aislada para cada respuesta\n",
    "- Compara conceptos entre respuestas para identificar duplicados\n",
    "\n",
    "**PASO 2: IDENTIFICA CONCEPTOS √öNICOS Y AGR√öPALOS**\n",
    "- Agrupa respuestas que mencionan el mismo concepto\n",
    "- Ejemplo: Si varias respuestas mencionan \"saludable\", \"es saludable\", \"muy saludable\" ‚Üí Es el MISMO concepto ‚Üí UN SOLO c√≥digo\n",
    "- Ejemplo: Si varias respuestas mencionan \"apto para diabetes\", \"para diab√©ticos\", \"endulzante para personas con diabetes\" ‚Üí Es el MISMO concepto ‚Üí UN SOLO c√≥digo\n",
    "- **CR√çTICO:** Si ya identificaste un concepto en una respuesta anterior, REUTILIZA ese mismo c√≥digo para respuestas similares\n",
    "\n",
    "**PASO 3: CREA C√ìDIGOS CON REDACCI√ìN COHERENTE Y √öNICA**\n",
    "- Asigna UN c√≥digo a cada concepto √∫nico identificado\n",
    "- La redacci√≥n debe ser COHERENTE: no muy general, no muy espec√≠fica\n",
    "- ‚úÖ CORRECTO: \"Saludable\", \"Apto para diabetes\", \"Sin calor√≠as\", \"Versatilidad de uso\"\n",
    "- ‚ùå MUY GENERAL: \"Bueno\", \"√ötil\", \"Me gusta\"\n",
    "- ‚ùå MUY ESPEC√çFICO: \"Saludable para personas con diabetes tipo 2 que buscan endulzantes naturales\", \"Versatilidad de uso en comidas y bebidas calientes\"\n",
    "\n",
    "**REGLAS CR√çTICAS DE ESPECIFICIDAD Y UNICIDAD:**\n",
    "\n",
    "1. **Precisi√≥n > Cobertura** (mejor dejar sin c√≥digo que asignar incorrecto)\n",
    "\n",
    "2. **Nivel de especificidad - CR√çTICO:**\n",
    "   - ‚úÖ CORRECTO: \"Versatilidad de uso\", \"Apto para diabetes\", \"Sin calor√≠as\", \"Sabor\", \"Textura\"\n",
    "   - ‚ùå MUY GENERAL: \"Bueno\", \"√ötil\", \"Me gusta\", \"Calidad\"\n",
    "   - ‚ùå MUY ESPEC√çFICO: \"Versatilidad de uso en comidas\", \"Apto para personas con diabetes tipo 2\", \"Sabor dulce natural sin qu√≠micos\"\n",
    "   - **Principio:** Si dos descripciones comparten la MISMA IDEA CENTRAL, deben usar el MISMO c√≥digo\n",
    "\n",
    "3. **Agrupa bajo el MISMO c√≥digo si:**\n",
    "   - Comparten el tema/concepto principal\n",
    "   - Solo difieren en detalles o contexto espec√≠fico\n",
    "   - Ejemplo: \"Sabor agradable\", \"Buen sabor\", \"Sabor rico\" ‚Üí MISMO c√≥digo \"Sabor\"\n",
    "   - Ejemplo: \"Apto para diabetes\", \"Para diab√©ticos\", \"Endulzante para personas con diabetes\" ‚Üí MISMO c√≥digo \"Apto para diabetes\"\n",
    "\n",
    "4. **Crea C√ìDIGOS SEPARADOS solo si:**\n",
    "   - Son temas REALMENTE distintos e independientes\n",
    "   - No se pueden agrupar bajo una categor√≠a com√∫n\n",
    "   - Ejemplo: \"Sabor\" vs \"Textura\" vs \"Precio\" ‚Üí Diferentes c√≥digos\n",
    "   - Ejemplo: \"Apto para diabetes\" vs \"Sin calor√≠as\" vs \"Versatilidad de uso\" ‚Üí Diferentes c√≥digos\n",
    "\n",
    "5. **Descripciones GENERALES pero CLARAS:**\n",
    "   - ‚úÖ BIEN: \"Precio accesible\", \"Sabor\", \"Textura\", \"Calidad nutricional\", \"Apto para diabetes\", \"Sin calor√≠as\"\n",
    "   - ‚ùå MAL: \"Precio accesible para familias\", \"Sabor dulce natural\", \"Textura suave\", \"Apto para personas con diabetes tipo 2\"\n",
    "   - Usa el nivel de abstracci√≥n del cat√°logo hist√≥rico como referencia (si existe)\n",
    "\n",
    "6. **NO uses frases como:** \"Menci√≥n sobre...\", \"Referencias a...\", \"Menciones de...\", \"Percepci√≥n de...\"\n",
    "\n",
    "7. **UNICIDAD Y REUTILIZACI√ìN - CR√çTICO:**\n",
    "   - Cada c√≥digo = Un concepto √∫nico\n",
    "   - Si encuentras el mismo concepto en m√∫ltiples respuestas, REUTILIZA el mismo c√≥digo\n",
    "   - NO crees c√≥digos diferentes para el mismo concepto con diferentes redacciones\n",
    "   - **Ejemplo PROHIBIDO:** NO crees c√≥digo {codigo_base} para \"Saludable\" y luego c√≥digo {codigo_base + 1} para \"Es saludable\" o c√≥digo {codigo_base + 2} para \"Muy saludable\"\n",
    "   - **TODOS deben usar el MISMO c√≥digo {codigo_base} con la MISMA descripci√≥n \"Saludable\"**\n",
    "\n",
    "8. **COHERENCIA EN LA REDACCI√ìN:**\n",
    "   - Si ya creaste un c√≥digo para un concepto, usa la MISMA redacci√≥n para ese concepto en todas las respuestas\n",
    "   - NO crees c√≥digos diferentes con redacciones diferentes para el mismo concepto\n",
    "   - Mant√©n consistencia: misma descripci√≥n = mismo c√≥digo\n",
    "\n",
    "**FORMATO DE C√ìDIGOS:**\n",
    "- codigo: N√∫mero secuencial √öNICO empezando desde {codigo_base}\n",
    "- descripcion: Descripci√≥n COHERENTE (equilibrio entre general y espec√≠fico)\n",
    "- texto_original: Fragmento del texto que justifica el c√≥digo\n",
    "\n",
    "**SECUENCIALIDAD:**\n",
    "- Primer c√≥digo nuevo: {codigo_base}\n",
    "- Segundo c√≥digo nuevo: {codigo_base + 1}\n",
    "- Tercer c√≥digo nuevo: {codigo_base + 2}\n",
    "- etc.\n",
    "\n",
    "**DECISIONES:**\n",
    "- Si NO hay c√≥digos asignados: respuesta_cubierta_completamente=False, generar c√≥digos\n",
    "- Si hay c√≥digos pero faltan conceptos: respuesta_cubierta_completamente=False, agregar c√≥digos\n",
    "- Si est√° completamente cubierta: respuesta_cubierta_completamente=True, conceptos_nuevos=[]\n",
    "- Puedes generar M√öLTIPLES c√≥digos por respuesta si toca temas distintos\n",
    "\n",
    "**RECORDATORIO CR√çTICO - LEE ANTES DE RESPONDER:**\n",
    "1. LEE TODAS LAS RESPUESTAS PRIMERO (no crees c√≥digos aislados)\n",
    "2. IDENTIFICA CONCEPTOS √öNICOS (agrupa similares bajo el mismo c√≥digo)\n",
    "3. CREA UN C√ìDIGO POR CONCEPTO √öNICO (no repitas c√≥digos con el mismo texto)\n",
    "4. REUTILIZA EL MISMO C√ìDIGO para el mismo concepto en diferentes respuestas\n",
    "5. MANT√âN COHERENCIA en la redacci√≥n (misma descripci√≥n para el mismo concepto)\n",
    "6. NO crees c√≥digos diferentes para variaciones del mismo concepto (ej: \"Saludable\", \"Es saludable\", \"Muy saludable\" ‚Üí TODOS el mismo c√≥digo)\n",
    "\n",
    "Responde en JSON.\"\"\"),\n",
    "        (\"user\", \"PREGUNTA: {pregunta}\\n{codigos_existentes}RESPUESTAS:\\n{respuestas}\")\n",
    "    ])\n",
    "    \n",
    "    llm = ChatOpenAI(model=state[\"modelo_gpt\"], temperature=0)\n",
    "    chain = prompt | llm.with_structured_output(ResultadoCobertura)\n",
    "    \n",
    "    # üÜï MEJORA: Usar retry y m√©tricas\n",
    "    inicio_tiempo = time.time()\n",
    "    try:\n",
    "        if \"metricas\" in state:\n",
    "            state[\"metricas\"][\"llamadas_llm\"] += 1\n",
    "        resultado = llamada_llm_con_retry(chain, {\n",
    "            \"pregunta\": state[\"pregunta\"],\n",
    "            \"codigos_existentes\": codigos_existentes_str,\n",
    "            \"respuestas\": respuestas_str\n",
    "        })\n",
    "    except Exception as e:\n",
    "        if \"metricas\" in state:\n",
    "            state[\"metricas\"][\"errores_llm\"] += 1\n",
    "        print(f\"   ‚ùå Error en identificaci√≥n: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # üÜï MEJORA: Deduplicaci√≥n autom√°tica como respaldo (solo si el modelo no lo hizo bien)\n",
    "    # Recolectar TODOS los conceptos del batch\n",
    "    todos_conceptos_batch = []\n",
    "    for analisis in resultado.analisis:\n",
    "        for concepto in analisis.conceptos_nuevos:\n",
    "            concepto_dict = concepto.model_dump()\n",
    "            concepto_dict[\"_respuesta_id\"] = analisis.respuesta_id\n",
    "            todos_conceptos_batch.append(concepto_dict)\n",
    "    \n",
    "    # Detectar duplicados obvios (descripciones id√©nticas o muy similares)\n",
    "    grupos_similares = {}  # descripcion_normalizada -> lista de conceptos\n",
    "    for concepto in todos_conceptos_batch:\n",
    "        desc = concepto.get(\"descripcion\", \"\")\n",
    "        desc_norm = normalizar_texto(desc)\n",
    "        \n",
    "        # Buscar si ya existe un grupo similar\n",
    "        encontrado = False\n",
    "        for desc_existente, grupo in grupos_similares.items():\n",
    "            if son_conceptos_similares(desc, desc_existente):\n",
    "                grupo.append(concepto)\n",
    "                encontrado = True\n",
    "                break\n",
    "        \n",
    "        if not encontrado:\n",
    "            grupos_similares[desc_norm] = [concepto]\n",
    "    \n",
    "    # Crear mapeo solo para duplicados obvios (descripciones id√©nticas o casi id√©nticas)\n",
    "    mapeo_deduplicacion = {}  # descripcion_normalizada -> codigo_unificado\n",
    "    codigo_unificado = codigo_base\n",
    "    descripciones_finales = {}  # codigo_unificado -> descripcion_final\n",
    "    \n",
    "    duplicados_detectados = 0\n",
    "    for desc_norm, grupo in grupos_similares.items():\n",
    "        # Solo agrupar si hay m√°s de un concepto (duplicado obvio)\n",
    "        if len(grupo) > 1:\n",
    "            # Usar la descripci√≥n m√°s corta como representante\n",
    "            desc_final = min(grupo, key=lambda x: len(x.get(\"descripcion\", \"\"))).get(\"descripcion\", \"\")\n",
    "            mapeo_deduplicacion[desc_norm] = codigo_unificado\n",
    "            descripciones_finales[codigo_unificado] = desc_final\n",
    "            \n",
    "            duplicados_detectados += len(grupo) - 1\n",
    "            descs_originales = [c.get(\"descripcion\", \"\") for c in grupo]\n",
    "            print(f\"   üîó Agrupando {len(grupo)} conceptos similares bajo c√≥digo {codigo_unificado}: {desc_final}\")\n",
    "            print(f\"      Originales: {', '.join(set(descs_originales))}\")\n",
    "            \n",
    "            codigo_unificado += 1\n",
    "        else:\n",
    "            # Concepto √∫nico, mantener su c√≥digo original\n",
    "            concepto = grupo[0]\n",
    "            cod_orig = concepto.get(\"codigo\", codigo_unificado)\n",
    "            mapeo_deduplicacion[desc_norm] = cod_orig\n",
    "            descripciones_finales[cod_orig] = concepto.get(\"descripcion\", \"\")\n",
    "            codigo_unificado = max(codigo_unificado, cod_orig + 1)\n",
    "    \n",
    "    if duplicados_detectados > 0:\n",
    "        print(f\"   ‚úÖ Duplicados detectados y agrupados: {duplicados_detectados}\")\n",
    "    \n",
    "    # Aplicar deduplicaci√≥n solo a duplicados obvios\n",
    "    analisis_corregidos = []\n",
    "    codigo_actual = codigo_base\n",
    "\n",
    "    for analisis in resultado.analisis:\n",
    "        conceptos_nuevos = [c.model_dump() for c in analisis.conceptos_nuevos]\n",
    "\n",
    "        # Aplicar deduplicaci√≥n solo si hay duplicados obvios\n",
    "        conceptos_dedup = []\n",
    "        codigos_vistos = set()\n",
    "\n",
    "        for concepto in conceptos_nuevos:\n",
    "            desc = concepto.get(\"descripcion\", \"\")\n",
    "            desc_norm = normalizar_texto(desc)\n",
    "\n",
    "            # Solo aplicar deduplicaci√≥n si est√° en el mapeo (duplicado detectado)\n",
    "            if desc_norm in mapeo_deduplicacion:\n",
    "                codigo_final = mapeo_deduplicacion[desc_norm]\n",
    "                desc_final = descripciones_finales.get(codigo_final, desc)\n",
    "            else:\n",
    "                # Mantener c√≥digo original del modelo\n",
    "                codigo_final = concepto.get(\"codigo\", codigo_actual)\n",
    "                desc_final = desc\n",
    "\n",
    "            # Evitar duplicados en la misma respuesta\n",
    "            if codigo_final not in codigos_vistos:\n",
    "                codigos_vistos.add(codigo_final)\n",
    "                concepto_final = {\n",
    "                    \"codigo\": codigo_final,\n",
    "                    \"descripcion\": desc_final,\n",
    "                    \"texto_original\": concepto.get(\"texto_original\", \"\")\n",
    "                }\n",
    "                conceptos_dedup.append(concepto_final)\n",
    "\n",
    "        # NO volver a renumerar aqu√≠: usamos directamente conceptos_dedup\n",
    "        analisis_corregidos.append({\n",
    "            \"respuesta_id\": analisis.respuesta_id,\n",
    "            \"respuesta_cubierta_completamente\": analisis.respuesta_cubierta_completamente,\n",
    "            \"conceptos_nuevos\": conceptos_dedup\n",
    "        })\n",
    "\n",
    "    # Actualizar el siguiente c√≥digo global: tomar el m√°ximo c√≥digo usado en el batch + 1\n",
    "    if todos_conceptos_batch:\n",
    "        max_codigo = max(\n",
    "            c[\"codigo\"] for c in todos_conceptos_batch\n",
    "            if c.get(\"codigo\") is not None\n",
    "        )\n",
    "        codigo_actual = max(max_codigo + 1, codigo_base)\n",
    "\n",
    "    cubiertas = sum(1 for a in analisis_corregidos if a[\"respuesta_cubierta_completamente\"])\n",
    "    con_nuevos = sum(1 for a in analisis_corregidos if len(a[\"conceptos_nuevos\"]) > 0)\n",
    "    total_conceptos = sum(len(a[\"conceptos_nuevos\"]) for a in analisis_corregidos)\n",
    "\n",
    "    print(f\"   ‚úÖ Completamente cubiertas: {cubiertas}/{len(analisis_corregidos)}\")\n",
    "    print(f\"   üÜï Con conceptos nuevos: {con_nuevos}/{len(analisis_corregidos)}\")\n",
    "    print(f\"   üÜï Total conceptos nuevos: {total_conceptos}\")\n",
    "\n",
    "    tiempo_nodo = time.time() - inicio_tiempo\n",
    "    if \"metricas\" in state:\n",
    "        registrar_tiempo_nodo(state[\"metricas\"], \"identificar_conceptos\", tiempo_nodo)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"cobertura_batch\": analisis_corregidos,\n",
    "        \"proximo_codigo_nuevo\": codigo_actual  # Actualizar para el siguiente batch\n",
    "    }\n",
    "\n",
    "def procesar_grupo_respuestas(respuestas_grupo, state, codigo_base, codigos_historicos_categoria, categoria):\n",
    "    \"\"\"\n",
    "    Procesa un grupo de respuestas (con o sin categor√≠a)\n",
    "    \n",
    "    Args:\n",
    "        respuestas_grupo: Lista de respuestas del mismo grupo\n",
    "        state: Estado del grafo\n",
    "        codigo_base: C√≥digo base para empezar a generar c√≥digos nuevos\n",
    "        codigos_historicos_categoria: C√≥digos hist√≥ricos relacionados con esta categor√≠a (para referencia)\n",
    "        categoria: Nombre de la categor√≠a (o None si no hay categor√≠a)\n",
    "    \"\"\"\n",
    "    # Recolectar c√≥digos ya creados en batches anteriores para esta categor√≠a\n",
    "    codigos_ya_creados = {}\n",
    "    if state.get(\"codificaciones\"):\n",
    "        for cod in state[\"codificaciones\"]:\n",
    "            # Solo incluir c√≥digos de la misma categor√≠a\n",
    "            if categoria and cod.get(\"dato_auxiliar\") != categoria:\n",
    "                continue\n",
    "            if cod.get(\"codigos_nuevos\"):\n",
    "                for nuevo in cod[\"codigos_nuevos\"]:\n",
    "                    cod_id = nuevo.get(\"codigo\")\n",
    "                    desc = nuevo.get(\"descripcion\", \"\")\n",
    "                    if cod_id and desc:\n",
    "                        codigos_ya_creados[cod_id] = desc\n",
    "    \n",
    "    # Construir string de c√≥digos ya creados\n",
    "    codigos_existentes_str = \"\"\n",
    "    if codigos_ya_creados:\n",
    "        codigos_existentes_str = \"\\n**C√ìDIGOS NUEVOS YA CREADOS EN BATCHES ANTERIORES:**\\n\"\n",
    "        for cod_id in sorted(codigos_ya_creados.keys()):\n",
    "            codigos_existentes_str += f\"  {cod_id}: {codigos_ya_creados[cod_id]}\\n\"\n",
    "        codigos_existentes_str += \"\\n**IMPORTANTE:** Si encuentras un concepto similar a uno de estos, NO crees un c√≥digo nuevo. El sistema los agrupar√° despu√©s.\\n\"\n",
    "    \n",
    "    # Construir string de respuestas\n",
    "    respuestas_str = \"\"\n",
    "    for item in respuestas_grupo:\n",
    "        resp_id = item[\"respuesta_id\"]\n",
    "        texto = item[\"texto\"]\n",
    "        codigos = item[\"codigos_asignados\"]\n",
    "        \n",
    "        if codigos and state[\"catalogo\"]:\n",
    "            descrips = []\n",
    "            for cod_id in codigos:\n",
    "                desc = next(\n",
    "                    (c[\"descripcion\"] for c in state[\"catalogo\"] if c[\"codigo\"] == cod_id),\n",
    "                    f\"C√≥digo {cod_id}\"\n",
    "                )\n",
    "                descrips.append(f\"[{cod_id}: {desc}]\")\n",
    "            respuestas_str += f\"{resp_id}. \\\"{texto}\\\"\\n   C√≥digos asignados: {', '.join(descrips)}\\n\\n\"\n",
    "        else:\n",
    "            respuestas_str += f\"{resp_id}. \\\"{texto}\\\"\\n   C√≥digos asignados: NINGUNO (generar c√≥digos para TODA la respuesta)\\n\\n\"\n",
    "    \n",
    "    # Construir prompt con informaci√≥n de categor√≠a si hay\n",
    "    info_categoria = \"\"\n",
    "    if categoria:\n",
    "        info_categoria = f\"\"\"\n",
    "**INFORMACI√ìN DE CATEGOR√çA:**\n",
    "- Esta respuesta pertenece a la categor√≠a: **{categoria}**\n",
    "- Los c√≥digos nuevos para esta categor√≠a empezar√°n desde: **{codigo_base}**\n",
    "- Genera c√≥digos secuenciales dentro de esta categor√≠a: {codigo_base}, {codigo_base + 1}, {codigo_base + 2}, etc.\n",
    "\"\"\"\n",
    "        if codigos_historicos_categoria:\n",
    "            info_categoria += f\"- Hay {len(codigos_historicos_categoria)} c√≥digos hist√≥ricos relacionados con esta categor√≠a (para referencia)\\n\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"Eres un experto en codificaci√≥n de respuestas de encuestas de opini√≥n p√∫blica.\n",
    "\n",
    "Tu trabajo:\n",
    "1. Si NO hay c√≥digos asignados ‚Üí Crear c√≥digos para TODA la respuesta\n",
    "2. Si hay c√≥digos asignados ‚Üí Identificar conceptos NO CUBIERTOS\n",
    "{info_categoria}\n",
    "**REGLAS CR√çTICAS DE ESPECIFICIDAD:**\n",
    "\n",
    "1. **Nivel de especificidad - CR√çTICO:**\n",
    "   - ‚úÖ CORRECTO: \"Versatilidad de uso\", \"Apto para diabetes\", \"Sin calor√≠as\"\n",
    "   - ‚ùå INCORRECTO: \"Versatilidad de uso en comidas\", \"Apto para personas con diabetes tipo 2\", \"Sin calor√≠as adicionales al consumirlo\"\n",
    "   - Principio: Si dos descripciones comparten la MISMA IDEA CENTRAL, deben usar el MISMO c√≥digo\n",
    "\n",
    "2. **Agrupa bajo el MISMO c√≥digo si:**\n",
    "   - Comparten el tema/concepto principal\n",
    "   - Solo difieren en detalles o contexto espec√≠fico\n",
    "   - Ejemplo: \"Sabor agradable\", \"Buen sabor\", \"Sabor rico\" ‚Üí MISMO c√≥digo \"Sabor\"\n",
    "   - Ejemplo: \"Apto para diabetes\", \"Para diab√©ticos\", \"Endulzante para personas con diabetes\" ‚Üí MISMO c√≥digo \"Apto para diabetes\"\n",
    "\n",
    "3. **Crea C√ìDIGOS SEPARADOS solo si:**\n",
    "   - Son temas REALMENTE distintos e independientes\n",
    "   - No se pueden agrupar bajo una categor√≠a com√∫n\n",
    "   - Ejemplo: \"Sabor\" vs \"Textura\" vs \"Precio\" ‚Üí Diferentes c√≥digos\n",
    "   - Ejemplo: \"Apto para diabetes\" vs \"Sin calor√≠as\" vs \"Versatilidad de uso\" ‚Üí Diferentes c√≥digos\n",
    "\n",
    "4. **Descripciones GENERALES pero CLARAS:**\n",
    "   - ‚úÖ BIEN: \"Precio accesible\", \"Sabor\", \"Textura\", \"Calidad nutricional\", \"Apto para diabetes\", \"Sin calor√≠as\"\n",
    "   - ‚ùå MAL: \"Precio accesible para familias\", \"Sabor dulce natural\", \"Textura suave\", \"Apto para personas con diabetes tipo 2\"\n",
    "\n",
    "5. **NO uses frases como:** \"Menci√≥n sobre...\", \"Referencias a...\", \"Menciones de...\", \"Percepci√≥n de...\"\n",
    "\n",
    "6. **CADA c√≥digo debe ser √öNICO:**\n",
    "   - Un c√≥digo = Un concepto espec√≠fico\n",
    "   - NO reutilices el mismo c√≥digo para conceptos diferentes\n",
    "   - Si encuentras un concepto similar a uno ya creado, REUTILIZA ese c√≥digo\n",
    "\n",
    "**FORMATO DE C√ìDIGOS:**\n",
    "- codigo: N√∫mero secuencial √öNICO empezando desde {codigo_base}\n",
    "- descripcion: Descripci√≥n GENERAL pero CLARA (sin detalles espec√≠ficos)\n",
    "- texto_original: Fragmento del texto que justifica el c√≥digo\n",
    "\n",
    "**SECUENCIALIDAD:**\n",
    "- Primer c√≥digo nuevo: {codigo_base}\n",
    "- Segundo c√≥digo nuevo: {codigo_base + 1}\n",
    "- Tercer c√≥digo nuevo: {codigo_base + 2}\n",
    "- etc.\n",
    "\n",
    "**DECISIONES:**\n",
    "- Si NO hay c√≥digos asignados: respuesta_cubierta_completamente=False, generar c√≥digos\n",
    "- Si hay c√≥digos pero faltan conceptos: respuesta_cubierta_completamente=False, agregar c√≥digos\n",
    "- Si est√° completamente cubierta: respuesta_cubierta_completamente=True, conceptos_nuevos=[]\n",
    "- Puedes generar M√öLTIPLES c√≥digos por respuesta si toca temas distintos\n",
    "\n",
    "**IMPORTANTE:** \n",
    "- Revisa si un concepto similar ya fue creado en respuestas anteriores del batch\n",
    "- Si es similar, REUTILIZA el c√≥digo existente en lugar de crear uno nuevo\n",
    "- Cada c√≥digo debe representar UN SOLO concepto √∫nico\n",
    "- NO crees c√≥digos diferentes para variaciones del mismo concepto\n",
    "- Ejemplo: Si ya creaste c√≥digo {codigo_base} para \"Apto para diabetes\", NO crees otro c√≥digo para \"Para diab√©ticos\" o \"Endulzante para personas con diabetes\"\n",
    "\n",
    "Responde en JSON.\"\"\"),\n",
    "        (\"user\", \"PREGUNTA: {pregunta}\\n{codigos_existentes}RESPUESTAS:\\n{respuestas}\")\n",
    "    ])\n",
    "    \n",
    "    llm = ChatOpenAI(model=state[\"modelo_gpt\"], temperature=0)\n",
    "    chain = prompt | llm.with_structured_output(ResultadoCobertura)\n",
    "    \n",
    "    resultado = chain.invoke({\n",
    "        \"pregunta\": state[\"pregunta\"],\n",
    "        \"codigos_existentes\": codigos_existentes_str,\n",
    "        \"respuestas\": respuestas_str\n",
    "    })\n",
    "    \n",
    "    # Los c√≥digos generados son secuenciales dentro de la categor√≠a\n",
    "    # No hay validaci√≥n de rangos - el sistema conf√≠a en que el LLM genere c√≥digos correctos\n",
    "    # Si hay problemas, se pueden ajustar manualmente despu√©s\n",
    "    \n",
    "    cubiertas = sum(1 for a in resultado.analisis if a.respuesta_cubierta_completamente)\n",
    "    con_nuevos = sum(1 for a in resultado.analisis if len(a.conceptos_nuevos) > 0)\n",
    "    total_conceptos = sum(len(a.conceptos_nuevos) for a in resultado.analisis)\n",
    "    \n",
    "    print(f\"   ‚úÖ Completamente cubiertas: {cubiertas}/{len(resultado.analisis)}\")\n",
    "    print(f\"   üÜï Con conceptos nuevos: {con_nuevos}/{len(resultado.analisis)}\")\n",
    "    print(f\"   üÜï Total conceptos nuevos: {total_conceptos}\")\n",
    "    \n",
    "    return [a.model_dump() for a in resultado.analisis]\n",
    "\n",
    "print(\"‚úÖ Nodo identificar_conceptos_v3 definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Nodos justificar_v3 y ensamblar_v3 definidos\n"
     ]
    }
   ],
   "source": [
    "# NODO 4: JUSTIFICAR\n",
    "def nodo_justificar_v3(state):\n",
    "    print(f\"\\nüìù Generando justificaciones...\")\n",
    "    \n",
    "    resumen = []\n",
    "    for i, (resp, val) in enumerate(zip(state[\"batch_respuestas\"], state[\"validaciones_batch\"])):\n",
    "        resp_id = i + 1\n",
    "        \n",
    "        if not val[\"es_valida\"]:\n",
    "            resumen.append(f\"{resp_id}. RECHAZADA: {val['razon']}\")\n",
    "            continue\n",
    "        \n",
    "        evaluacion = next((ev for ev in state[\"evaluaciones_batch\"] if ev[\"respuesta_id\"] == resp_id), {\"evaluaciones\": []})\n",
    "        codigos_hist = [cod[\"codigo\"] for cod in evaluacion.get(\"evaluaciones\", []) if cod[\"aplica\"] and cod[\"confianza\"] >= 0.95]\n",
    "        \n",
    "        cobertura = next((cob for cob in state[\"cobertura_batch\"] if cob[\"respuesta_id\"] == resp_id), {\"conceptos_nuevos\": []})\n",
    "        conceptos_nuevos = cobertura.get(\"conceptos_nuevos\", [])\n",
    "        \n",
    "        resumen.append(f\"{resp_id}. Hist:{len(codigos_hist)} Nuevos:{len(conceptos_nuevos)}\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Genera justificaciones BREVES (1-2 oraciones).\n",
    "S√© CONCISO. Responde en JSON.\"\"\"),\n",
    "        (\"user\", \"DECISIONES:\\n{resumen}\")\n",
    "    ])\n",
    "    \n",
    "    llm = ChatOpenAI(model=state[\"modelo_gpt\"], temperature=0)\n",
    "    chain = prompt | llm.with_structured_output(ResultadoJustificacion)\n",
    "    \n",
    "    # üÜï MEJORA: Usar retry y m√©tricas\n",
    "    inicio_tiempo = time.time()\n",
    "    try:\n",
    "        if \"metricas\" in state:\n",
    "            state[\"metricas\"][\"llamadas_llm\"] += 1\n",
    "        resultado = llamada_llm_con_retry(chain, {\"resumen\": \"\\n\".join(resumen)})\n",
    "    except Exception as e:\n",
    "        if \"metricas\" in state:\n",
    "            state[\"metricas\"][\"errores_llm\"] += 1\n",
    "        print(f\"   ‚ùå Error en justificaci√≥n: {e}\")\n",
    "        raise\n",
    "    \n",
    "    print(f\"   ‚úÖ Justificaciones generadas\")\n",
    "    \n",
    "    tiempo_nodo = time.time() - inicio_tiempo\n",
    "    if \"metricas\" in state:\n",
    "        registrar_tiempo_nodo(state[\"metricas\"], \"justificar\", tiempo_nodo)\n",
    "    \n",
    "    return {**state, \"justificaciones_batch\": [j.model_dump() for j in resultado.justificaciones]}\n",
    "\n",
    "# NODO 5: ENSAMBLAR\n",
    "def nodo_ensamblar_v3(state):\n",
    "    print(f\"\\nüîß Ensamblando resultados...\")\n",
    "    \n",
    "    codificaciones_batch = []\n",
    "    \n",
    "    for i, (resp, val) in enumerate(zip(state[\"batch_respuestas\"], state[\"validaciones_batch\"])):\n",
    "        resp_id = i + 1\n",
    "        justif = next((j for j in state[\"justificaciones_batch\"] if j[\"respuesta_id\"] == resp_id), {\"justificacion\": \"Sin justificaci√≥n\"})\n",
    "        \n",
    "        if not val[\"es_valida\"]:\n",
    "            codificaciones_batch.append({\n",
    "                \"fila_excel\": resp[\"fila_excel\"],\n",
    "                \"texto\": resp[\"texto\"],\n",
    "                \"decision\": \"rechazar\",\n",
    "                \"codigos_historicos\": [],\n",
    "                \"codigos_nuevos\": [],\n",
    "                \"justificacion\": justif[\"justificacion\"]\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # üÜï MEJORA: Verificar si tiene c√≥digo especial detectado\n",
    "        codigo_especial = state.get(\"respuestas_especiales\", {}).get(resp_id)\n",
    "        \n",
    "        if codigo_especial:\n",
    "            # Respuesta con c√≥digo especial detectado autom√°ticamente\n",
    "            codigos_hist = [codigo_especial]\n",
    "            codigos_nuevos = []\n",
    "            decision = \"historico\"  # Los especiales son hist√≥ricos\n",
    "        else:\n",
    "            evaluacion = next((ev for ev in state[\"evaluaciones_batch\"] if ev[\"respuesta_id\"] == resp_id), {\"evaluaciones\": []})\n",
    "            codigos_hist = [cod[\"codigo\"] for cod in evaluacion.get(\"evaluaciones\", []) if cod[\"aplica\"] and cod[\"confianza\"] >= 0.95]\n",
    "            \n",
    "            cobertura = next((cob for cob in state[\"cobertura_batch\"] if cob[\"respuesta_id\"] == resp_id), {\"conceptos_nuevos\": []})\n",
    "            # C√≥digos nuevos con ID y descripci√≥n\n",
    "            codigos_nuevos = [\n",
    "                {\"codigo\": c[\"codigo\"], \"descripcion\": c[\"descripcion\"]} \n",
    "                for c in cobertura.get(\"conceptos_nuevos\", [])\n",
    "            ]\n",
    "            \n",
    "            if codigos_hist and codigos_nuevos:\n",
    "                decision = \"mixto\"\n",
    "            elif codigos_hist:\n",
    "                decision = \"historico\"\n",
    "            elif codigos_nuevos:\n",
    "                decision = \"nuevo\"\n",
    "            else:\n",
    "                decision = \"rechazar\"\n",
    "        \n",
    "        codificaciones_batch.append({\n",
    "            \"fila_excel\": resp[\"fila_excel\"],\n",
    "            \"texto\": resp[\"texto\"],\n",
    "            \"decision\": decision,\n",
    "            \"codigos_historicos\": codigos_hist,\n",
    "            \"codigos_nuevos\": codigos_nuevos,\n",
    "            \"justificacion\": justif[\"justificacion\"]\n",
    "        })\n",
    "    \n",
    "    decisiones = {}\n",
    "    for cod in codificaciones_batch:\n",
    "        dec = cod[\"decision\"]\n",
    "        decisiones[dec] = decisiones.get(dec, 0) + 1\n",
    "    \n",
    "    print(f\"   üìä Decisiones: {decisiones}\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"codificaciones\": state[\"codificaciones\"] + codificaciones_batch\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Nodos justificar_v3 y ensamblar_v3 definidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Grafo V3 compilado\n",
      "\n",
      "üìä Nodos:\n",
      "   ‚Ä¢ __start__\n",
      "   ‚Ä¢ preparar_batch\n",
      "   ‚Ä¢ validar\n",
      "   ‚Ä¢ evaluar_catalogo\n",
      "   ‚Ä¢ identificar_conceptos\n",
      "   ‚Ä¢ justificar\n",
      "   ‚Ä¢ ensamblar\n",
      "   ‚Ä¢ finalizar\n",
      "   ‚Ä¢ __end__\n"
     ]
    }
   ],
   "source": [
    "# NODOS AUXILIARES (reutilizamos del notebook 03)\n",
    "def nodo_preparar_batch(state):\n",
    "    inicio = state[\"batch_actual\"] * state[\"batch_size\"]\n",
    "    fin = inicio + state[\"batch_size\"]\n",
    "    batch = state[\"respuestas\"][inicio:fin]\n",
    "    return {**state, \"batch_respuestas\": batch}\n",
    "\n",
    "def decidir_continuar(state):\n",
    "    if (state[\"batch_actual\"] + 1) * state[\"batch_size\"] < len(state[\"respuestas\"]):\n",
    "        return \"preparar_batch\"\n",
    "    return \"finalizar\"\n",
    "\n",
    "# Estado\n",
    "class EstadoCodificacionV3(TypedDict):\n",
    "    pregunta: str\n",
    "    modelo_gpt: str\n",
    "    batch_size: int\n",
    "    respuestas: List[Dict]\n",
    "    catalogo: List[Dict]\n",
    "    batch_actual: int\n",
    "    batch_respuestas: List[Dict]\n",
    "    codificaciones: List[Dict]\n",
    "    validaciones_batch: List[Dict]\n",
    "    evaluaciones_batch: List[Dict]\n",
    "    cobertura_batch: List[Dict]\n",
    "    justificaciones_batch: List[Dict]\n",
    "    proximo_codigo_nuevo: int  # üÜï Contador global de c√≥digos nuevos\n",
    "    metricas: Dict  # üÜï M√©tricas de ejecuci√≥n\n",
    "    respuestas_especiales: Dict[int, int]  # üÜï respuesta_id -> codigo_especial\n",
    "\n",
    "# CONSTRUIR GRAFO V3\n",
    "workflow_v3 = StateGraph(EstadoCodificacionV3)\n",
    "\n",
    "workflow_v3.add_node(\"preparar_batch\", nodo_preparar_batch)\n",
    "workflow_v3.add_node(\"validar\", nodo_validar)\n",
    "workflow_v3.add_node(\"evaluar_catalogo\", nodo_evaluar_catalogo_v3)\n",
    "workflow_v3.add_node(\"identificar_conceptos\", nodo_identificar_conceptos_v3)\n",
    "workflow_v3.add_node(\"justificar\", nodo_justificar_v3)\n",
    "workflow_v3.add_node(\"ensamblar\", nodo_ensamblar_v3)\n",
    "workflow_v3.add_node(\"finalizar\", lambda state: {**state, \"batch_actual\": state[\"batch_actual\"] + 1})\n",
    "\n",
    "workflow_v3.set_entry_point(\"preparar_batch\")\n",
    "workflow_v3.add_edge(\"preparar_batch\", \"validar\")\n",
    "workflow_v3.add_edge(\"validar\", \"evaluar_catalogo\")\n",
    "workflow_v3.add_edge(\"evaluar_catalogo\", \"identificar_conceptos\")\n",
    "workflow_v3.add_edge(\"identificar_conceptos\", \"justificar\")\n",
    "workflow_v3.add_edge(\"justificar\", \"ensamblar\")\n",
    "workflow_v3.add_edge(\"ensamblar\", \"finalizar\")\n",
    "workflow_v3.add_conditional_edges(\n",
    "    \"finalizar\",\n",
    "    decidir_continuar,\n",
    "    {\"preparar_batch\": \"preparar_batch\", \"finalizar\": END}\n",
    ")\n",
    "\n",
    "app_v3 = workflow_v3.compile()\n",
    "\n",
    "print(\"‚úÖ Grafo V3 compilado\")\n",
    "print(\"\\nüìä Nodos:\")\n",
    "for nodo in app_v3.get_graph().nodes.keys():\n",
    "    print(f\"   ‚Ä¢ {nodo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîç VERIFICACI√ìN PRE-EJECUCI√ìN\n",
      "============================================================\n",
      "\n",
      "üìä Respuestas cargadas: 14\n",
      "üìö Cat√°logo hist√≥rico: 9 c√≥digos\n",
      "\n",
      "‚úÖ Cat√°logo cargado correctamente\n",
      "   Primeros 3 c√≥digos:\n",
      "   ‚Ä¢ [90] Ninguno\n",
      "   ‚Ä¢ [91] No Recuerda\n",
      "   ‚Ä¢ [92] No Sabe\n",
      "\n",
      "üßÆ Batches esperados: 2\n",
      "‚öôÔ∏è  L√≠mite de recursi√≥n: 100\n",
      "üî¢ C√≥digo inicial para nuevos c√≥digos: 1\n",
      "   (C√≥digos especiales 90-98 excluidos del c√°lculo)\n",
      "\n",
      "============================================================\n",
      "üöÄ EJECUTANDO GRAFO V3\n",
      "============================================================\n",
      "\n",
      "üìä Respuestas: 14\n",
      "üì¶ Batch size: 10\n",
      "ü§ñ Modelo: gpt-5\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "‚úÖ Validando 10 respuestas...\n",
      "   üéØ Respuesta 8 detectada como c√≥digo especial 90\n",
      "   ‚úÖ V√°lidas: 9/10\n",
      "\n",
      "üìä Evaluando cat√°logo para 9 respuestas...\n",
      "   ‚úÖ Matches (confianza >= 0.95): 1\n",
      "\n",
      "üîç Analizando cobertura para 9 respuestas...\n",
      "   (C√≥digos nuevos empezar√°n desde: 1)\n",
      "   üîó Agrupando 2 conceptos similares bajo c√≥digo 4: Confianza en la marca\n",
      "      Originales: Familiaridad con la marca, Confianza en la marca\n",
      "   ‚úÖ Duplicados detectados y agrupados: 1\n",
      "   ‚úÖ Completamente cubiertas: 2/9\n",
      "   üÜï Con conceptos nuevos: 7/9\n",
      "   üÜï Total conceptos nuevos: 13\n",
      "\n",
      "üìù Generando justificaciones...\n",
      "   ‚úÖ Justificaciones generadas\n",
      "\n",
      "üîß Ensamblando resultados...\n",
      "   üìä Decisiones: {'rechazar': 2, 'nuevo': 7, 'historico': 1}\n",
      "\n",
      "============================================================\n",
      "‚úÖ PROCESO V3 COMPLETADO\n",
      "============================================================\n",
      "\n",
      "üìä Resultados:\n",
      "   Total respuestas: 10\n",
      "\n",
      "üìà Decisiones:\n",
      "   nuevo        :   7 (70.0%)\n",
      "   rechazar     :   2 (20.0%)\n",
      "   historico    :   1 (10.0%)\n",
      "\n",
      "üìã C√ìDIGOS NUEVOS GENERADOS: 13\n",
      "\n",
      "   ID     DESCRIPCI√ìN\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   1      Sorpresa\n",
      "   2      Variedad de productos\n",
      "   3      Presentaci√≥n elegante\n",
      "   4      Confianza en la marca\n",
      "   5      Agrado por el producto\n",
      "   6      Confianza en la marca\n",
      "   7      Emoci√≥n\n",
      "   8      Saludable\n",
      "   9      Sabor\n",
      "   10     Uso diario\n",
      "   11     Conexi√≥n con necesidades del consumidor\n",
      "   12     Informaci√≥n relevante\n",
      "   13     Informaci√≥n diferente\n",
      "\n",
      "   Total respuestas con c√≥digos nuevos: 7\n",
      "\n",
      "============================================================\n",
      "üìä M√âTRICAS DE EJECUCI√ìN\n",
      "============================================================\n",
      "‚è±Ô∏è  Tiempo total: 216.77s\n",
      "ü§ñ Llamadas LLM: 4\n",
      "‚ùå Errores LLM: 0\n",
      "üîÑ Reintentos: 0\n",
      "üéØ Respuestas especiales detectadas: 1\n",
      "üîß C√≥digos corregidos: 0\n",
      "\n",
      "‚è±Ô∏è  Tiempo por nodo:\n",
      "   ‚Ä¢ validar: 15.04s promedio (15.04s total, 1 ejecuciones)\n",
      "   ‚Ä¢ evaluar_catalogo: 75.96s promedio (75.96s total, 1 ejecuciones)\n",
      "   ‚Ä¢ identificar_conceptos: 91.65s promedio (91.65s total, 1 ejecuciones)\n",
      "   ‚Ä¢ justificar: 34.10s promedio (34.10s total, 1 ejecuciones)\n"
     ]
    }
   ],
   "source": [
    "# EJECUTAR GRAFO V3\n",
    "\n",
    "# Verificar datos antes de ejecutar\n",
    "print(\"=\"*60)\n",
    "print(\"üîç VERIFICACI√ìN PRE-EJECUCI√ìN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Respuestas cargadas: {len(respuestas_reales)}\")\n",
    "print(f\"üìö Cat√°logo hist√≥rico: {len(catalogo_historico)} c√≥digos\")\n",
    "if len(catalogo_historico) == 0:\n",
    "    print(\"\\n‚ö†Ô∏è  ADVERTENCIA: Sin cat√°logo hist√≥rico!\")\n",
    "    print(\"   Solo se generar√°n c√≥digos nuevos.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Cat√°logo cargado correctamente\")\n",
    "    print(f\"   Primeros 3 c√≥digos:\")\n",
    "    for c in catalogo_historico[:3]:\n",
    "        print(f\"   ‚Ä¢ [{c['codigo']}] {c['descripcion']}\")\n",
    "\n",
    "# Calcular l√≠mite de recursi√≥n necesario\n",
    "batches_esperados = (len(respuestas_reales) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "# Cada batch ejecuta ~7 nodos + decisi√≥n = ~8 pasos\n",
    "# Agregar margen de seguridad 20%\n",
    "recursion_limit = max(batches_esperados * 10, 100)\n",
    "\n",
    "print(f\"\\nüßÆ Batches esperados: {batches_esperados}\")\n",
    "print(f\"‚öôÔ∏è  L√≠mite de recursi√≥n: {recursion_limit}\")\n",
    "\n",
    "# Calcular el c√≥digo inicial para nuevos c√≥digos\n",
    "# üÜï CORRECCI√ìN: Excluir c√≥digos especiales (90-98) del c√°lculo\n",
    "if catalogo_historico:\n",
    "    # Solo considerar c√≥digos NO especiales (< 90)\n",
    "    codigos_normales = [c[\"codigo\"] for c in catalogo_historico if c[\"codigo\"] < 90]\n",
    "    if codigos_normales:\n",
    "        proximo_codigo_inicial = max(codigos_normales) + 1\n",
    "    else:\n",
    "        # Si solo hay c√≥digos especiales, empezar desde 1\n",
    "        proximo_codigo_inicial = 1\n",
    "else:\n",
    "    proximo_codigo_inicial = 1\n",
    "\n",
    "print(f\"üî¢ C√≥digo inicial para nuevos c√≥digos: {proximo_codigo_inicial}\")\n",
    "print(f\"   (C√≥digos especiales 90-98 excluidos del c√°lculo)\")\n",
    "\n",
    "# üÜï MEJORA: Inicializar m√©tricas\n",
    "metricas = inicializar_metricas()\n",
    "\n",
    "estado_inicial = {\n",
    "    \"pregunta\": nombre_pregunta,\n",
    "    \"modelo_gpt\": MODELO_GPT,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"respuestas\": respuestas_reales,\n",
    "    \"catalogo\": catalogo_historico,\n",
    "    \"batch_actual\": 0,\n",
    "    \"batch_respuestas\": [],\n",
    "    \"codificaciones\": [],\n",
    "    \"validaciones_batch\": [],\n",
    "    \"evaluaciones_batch\": [],\n",
    "    \"cobertura_batch\": [],\n",
    "    \"justificaciones_batch\": [],\n",
    "    \"proximo_codigo_nuevo\": proximo_codigo_inicial,\n",
    "    \"metricas\": metricas,  # üÜï M√©tricas\n",
    "    \"respuestas_especiales\": {}  # üÜï Respuestas especiales detectadas\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üöÄ EJECUTANDO GRAFO V3\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Respuestas: {len(respuestas_reales)}\")\n",
    "print(f\"üì¶ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"ü§ñ Modelo: {MODELO_GPT}\")\n",
    "print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "# EJECUTAR con recursion_limit configurado\n",
    "from langgraph.pregel.main import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=recursion_limit)\n",
    "resultado_final_v3 = app_v3.invoke(estado_inicial, config=config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ PROCESO V3 COMPLETADO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Estad√≠sticas\n",
    "decisiones = {}\n",
    "for cod in resultado_final_v3[\"codificaciones\"]:\n",
    "    dec = cod[\"decision\"]\n",
    "    decisiones[dec] = decisiones.get(dec, 0) + 1\n",
    "\n",
    "print(f\"\\nüìä Resultados:\")\n",
    "print(f\"   Total respuestas: {len(resultado_final_v3['codificaciones'])}\")\n",
    "print(f\"\\nüìà Decisiones:\")\n",
    "for decision, cantidad in sorted(decisiones.items(), key=lambda x: -x[1]):\n",
    "    porcentaje = (cantidad / len(resultado_final_v3['codificaciones'])) * 100\n",
    "    print(f\"   {decision:12} : {cantidad:3} ({porcentaje:.1f}%)\")\n",
    "\n",
    "# Casos mixtos\n",
    "mixtos = [c for c in resultado_final_v3[\"codificaciones\"] if c[\"decision\"] == \"mixto\"]\n",
    "if mixtos:\n",
    "    print(f\"\\nüéØ Casos MIXTOS capturados: {len(mixtos)}\")\n",
    "    print(f\"   (Respuestas con c√≥digos hist√≥ricos Y nuevos)\")\n",
    "\n",
    "# C√≥digos nuevos generados\n",
    "nuevos_con_codigos = [c for c in resultado_final_v3[\"codificaciones\"] if c[\"codigos_nuevos\"]]\n",
    "if nuevos_con_codigos:\n",
    "    # Recolectar todos los c√≥digos √∫nicos\n",
    "    codigos_unicos = {}\n",
    "    for cod in nuevos_con_codigos:\n",
    "        for nuevo in cod[\"codigos_nuevos\"]:\n",
    "            cod_id = nuevo[\"codigo\"]\n",
    "            if cod_id not in codigos_unicos:\n",
    "                codigos_unicos[cod_id] = nuevo[\"descripcion\"]\n",
    "    \n",
    "    print(f\"\\nüìã C√ìDIGOS NUEVOS GENERADOS: {len(codigos_unicos)}\")\n",
    "    print(f\"\\n   {'ID':<6} DESCRIPCI√ìN\")\n",
    "    print(f\"   {'‚îÄ'*6} {'‚îÄ'*60}\")\n",
    "    for cod_id in sorted(codigos_unicos.keys()):\n",
    "        print(f\"   {cod_id:<6} {codigos_unicos[cod_id]}\")\n",
    "    \n",
    "    print(f\"\\n   Total respuestas con c√≥digos nuevos: {len(nuevos_con_codigos)}\")\n",
    "\n",
    "# üÜï MEJORA: Mostrar m√©tricas al final\n",
    "if \"metricas\" in resultado_final_v3:\n",
    "    imprimir_metricas(resultado_final_v3[\"metricas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä DIAGRAMA DEL GRAFO V3\n",
      "======================================================================\n",
      "\n",
      "Flujo del proceso:\n",
      "\n",
      "  START\n",
      "    ‚Üì\n",
      "  preparar_batch  ‚Üê [LOOP: toma siguiente grupo de respuestas]\n",
      "    ‚Üì\n",
      "  validar  ‚Üí Filtrar respuestas basura\n",
      "    ‚Üì\n",
      "  evaluar_catalogo  ‚Üí Evaluar TODOS los c√≥digos (True/False + confianza)\n",
      "    ‚Üì\n",
      "  identificar_conceptos  ‚Üí Detectar gaps (qu√© NO est√° cubierto)\n",
      "    ‚Üì\n",
      "  justificar  ‚Üí Explicar decisiones\n",
      "    ‚Üì\n",
      "  ensamblar  ‚Üí Combinar resultados\n",
      "    ‚Üì\n",
      "  finalizar  ‚Üí Incrementar batch_actual\n",
      "    ‚Üì\n",
      "  ¬øHay m√°s batches?\n",
      "    ‚îú‚îÄ S√ç ‚Üí volver a preparar_batch\n",
      "    ‚îî‚îÄ NO ‚Üí END\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üéØ VENTAJA CLAVE DE V3:\n",
      "\n",
      "  ‚Ä¢ evaluar_catalogo: Eval√∫a CADA c√≥digo hist√≥rico expl√≠citamente\n",
      "  ‚Ä¢ identificar_conceptos: Solo genera c√≥digos para conceptos NO cubiertos\n",
      "  ‚Ä¢ Captura casos MIXTOS: Respuestas que necesitan hist√≥ricos + nuevos\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üìã Diagrama ASCII del grafo:\n",
      "\n",
      "                     +-----------+          \n",
      "                     | __start__ |          \n",
      "                     +-----------+          \n",
      "                            *               \n",
      "                            *               \n",
      "                            *               \n",
      "                  +----------------+        \n",
      "                  | preparar_batch |        \n",
      "                  +----------------+        \n",
      "                   ***            ...       \n",
      "                 **                  ..     \n",
      "               **                      ..   \n",
      "       +---------+                       .. \n",
      "       | validar |                        . \n",
      "       +---------+                        . \n",
      "            *                             . \n",
      "            *                             . \n",
      "            *                             . \n",
      "  +------------------+                    . \n",
      "  | evaluar_catalogo |                    . \n",
      "  +------------------+                    . \n",
      "            *                             . \n",
      "            *                             . \n",
      "            *                             . \n",
      "+-----------------------+                 . \n",
      "| identificar_conceptos |                 . \n",
      "+-----------------------+                 . \n",
      "            *                             . \n",
      "            *                             . \n",
      "            *                             . \n",
      "      +------------+                      . \n",
      "      | justificar |                      . \n",
      "      +------------+                      . \n",
      "            *                             . \n",
      "            *                             . \n",
      "            *                             . \n",
      "      +-----------+                      .. \n",
      "      | ensamblar |                    ..   \n",
      "      +-----------+                  ..     \n",
      "                   ***            ...       \n",
      "                      **        ..          \n",
      "                        **    ..            \n",
      "                     +-----------+          \n",
      "                     | finalizar |          \n",
      "                     +-----------+          \n",
      "                            .               \n",
      "                            .               \n",
      "                            .               \n",
      "                      +---------+           \n",
      "                      | __end__ |           \n",
      "                      +---------+           \n"
     ]
    }
   ],
   "source": [
    "# VISUALIZACI√ìN DEL GRAFO V3\n",
    "print(\"=\"*70)\n",
    "print(\"üìä DIAGRAMA DEL GRAFO V3\")\n",
    "print(\"=\"*70)\n",
    "print(\"\")\n",
    "print(\"Flujo del proceso:\")\n",
    "print(\"\")\n",
    "print(\"  START\")\n",
    "print(\"    ‚Üì\")\n",
    "print(\"  preparar_batch  ‚Üê [LOOP: toma siguiente grupo de respuestas]\")\n",
    "print(\"    ‚Üì\")\n",
    "print(\"  validar  ‚Üí Filtrar respuestas basura\")\n",
    "print(\"    ‚Üì\")\n",
    "print(\"  evaluar_catalogo  ‚Üí Evaluar TODOS los c√≥digos (True/False + confianza)\")\n",
    "print(\"    ‚Üì\")\n",
    "print(\"  identificar_conceptos  ‚Üí Detectar gaps (qu√© NO est√° cubierto)\")\n",
    "print(\"    ‚Üì\")\n",
    "print(\"  justificar  ‚Üí Explicar decisiones\")\n",
    "print(\"    ‚Üì\")\n",
    "print(\"  ensamblar  ‚Üí Combinar resultados\")\n",
    "print(\"    ‚Üì\")\n",
    "print(\"  finalizar  ‚Üí Incrementar batch_actual\")\n",
    "print(\"    ‚Üì\")\n",
    "print(\"  ¬øHay m√°s batches?\")\n",
    "print(\"    ‚îú‚îÄ S√ç ‚Üí volver a preparar_batch\")\n",
    "print(\"    ‚îî‚îÄ NO ‚Üí END\")\n",
    "print(\"\")\n",
    "print(\"=\"*70)\n",
    "print(\"\")\n",
    "print(\"üéØ VENTAJA CLAVE DE V3:\")\n",
    "print(\"\")\n",
    "print(\"  ‚Ä¢ evaluar_catalogo: Eval√∫a CADA c√≥digo hist√≥rico expl√≠citamente\")\n",
    "print(\"  ‚Ä¢ identificar_conceptos: Solo genera c√≥digos para conceptos NO cubiertos\")\n",
    "print(\"  ‚Ä¢ Captura casos MIXTOS: Respuestas que necesitan hist√≥ricos + nuevos\")\n",
    "print(\"\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Diagrama ASCII del grafo\n",
    "print(\"\\nüìã Diagrama ASCII del grafo:\\n\")\n",
    "try:\n",
    "    print(app_v3.get_graph().draw_ascii())\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  Para ver el diagrama ASCII, instala: pip install grandalf\")\n",
    "    print(\"\\nüìä Diagrama simplificado:\\n\")\n",
    "    print(\"  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "    print(\"  ‚îÇ preparar_batch  ‚îÇ\")\n",
    "    print(\"  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "    print(\"           ‚îÇ\")\n",
    "    print(\"  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "    print(\"  ‚îÇ    validar      ‚îÇ\")\n",
    "    print(\"  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "    print(\"           ‚îÇ\")\n",
    "    print(\"  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "    print(\"  ‚îÇ  evaluar_catalogo   ‚îÇ\")\n",
    "    print(\"  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "    print(\"           ‚îÇ\")\n",
    "    print(\"  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "    print(\"  ‚îÇ identificar_conceptos     ‚îÇ\")\n",
    "    print(\"  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "    print(\"           ‚îÇ\")\n",
    "    print(\"  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "    print(\"  ‚îÇ   justificar    ‚îÇ\")\n",
    "    print(\"  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "    print(\"           ‚îÇ\")\n",
    "    print(\"  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "    print(\"  ‚îÇ    ensamblar    ‚îÇ\")\n",
    "    print(\"  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "    print(\"           ‚îÇ\")\n",
    "    print(\"  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "    print(\"  ‚îÇ   finalizar     ‚îÇ\")\n",
    "    print(\"  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "    print(\"           ‚îÇ\")\n",
    "    print(\"     [loop o END]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üì• RESULTADOS EXPORTADOS\n",
      "============================================================\n",
      "\n",
      "‚úÖ Archivo: resultados_v3_20251201_104548.xlsx\n",
      "üìä Hojas:\n",
      "   ‚Ä¢ Resultados: 10 filas\n",
      "     Columnas: ID, 'P2', C√≥digos asignados\n",
      "   ‚Ä¢ C√≥digos Nuevos: 13 c√≥digos\n",
      "     Columnas: COD, TEXTO\n",
      "\n",
      "üìã Vista previa de Resultados (primeras 3 filas):\n",
      "\n",
      "       ID                                                                                      P2 C√≥digos asignados\n",
      "0  NUMERO  2.¬øPor qu√© seleccion√≥ la cara cuando vio esta imagen?Seleccion√≥ cara cuando vio imagen                  \n",
      "1      11                          por que me sorprendi√≥ que tuvieran artos productos y elegantes           1; 2; 3\n",
      "2      13                                     porque ya conocio la marca, asi que no me sorprendi                 4\n",
      "\n",
      "üìã Vista previa de C√≥digos Nuevos:\n",
      "\n",
      "   COD                   TEXTO\n",
      "0    1                Sorpresa\n",
      "1    2   Variedad de productos\n",
      "2    3   Presentaci√≥n elegante\n",
      "3    4   Confianza en la marca\n",
      "4    5  Agrado por el producto\n",
      "5    6   Confianza en la marca\n",
      "6    7                 Emoci√≥n\n",
      "7    8               Saludable\n",
      "8    9                   Sabor\n",
      "9   10              Uso diario\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# EXPORTAR RESULTADOS\n",
    "\n",
    "# Obtener nombre de la pregunta (columna de respuestas)\n",
    "nombre_pregunta = resultado_final_v3[\"pregunta\"]\n",
    "\n",
    "# Crear diccionario para mapear fila_excel a ID\n",
    "# Necesitamos cargar el archivo original para obtener los IDs\n",
    "df_original = pd.read_excel(ARCHIVO_RESPUESTAS)\n",
    "columna_id = df_original.columns[0]\n",
    "\n",
    "# Mapeo: fila_excel -> ID\n",
    "mapeo_id = {}\n",
    "for idx, row in df_original.iterrows():\n",
    "    fila_excel = idx + 2\n",
    "    id_valor = row[columna_id]\n",
    "    if pd.isna(id_valor):\n",
    "        id_valor = idx + 1\n",
    "    mapeo_id[fila_excel] = id_valor\n",
    "\n",
    "# Construir datos para Excel 1: ID, [nombre_pregunta], C√≥digos asignados\n",
    "datos_exportar = []\n",
    "\n",
    "for cod in resultado_final_v3[\"codificaciones\"]:\n",
    "    # Obtener ID del mapeo\n",
    "    fila_excel = cod[\"fila_excel\"]\n",
    "    id_valor = mapeo_id.get(fila_excel, fila_excel - 1)  # Fallback si no encuentra\n",
    "    \n",
    "    # Construir c√≥digos asignados\n",
    "    codigos_asignados = []\n",
    "    \n",
    "    # C√≥digos hist√≥ricos (solo n√∫meros)\n",
    "    if cod[\"codigos_historicos\"]:\n",
    "        codigos_asignados.extend([str(c) for c in cod[\"codigos_historicos\"]])\n",
    "    \n",
    "    # C√≥digos nuevos (solo n√∫meros)\n",
    "    if cod[\"codigos_nuevos\"]:\n",
    "        codigos_asignados.extend([str(nuevo[\"codigo\"]) for nuevo in cod[\"codigos_nuevos\"]])\n",
    "    \n",
    "    # Unir con punto y coma\n",
    "    codigos_final = \"; \".join(codigos_asignados) if codigos_asignados else \"\"\n",
    "    \n",
    "    # Construir fila de datos\n",
    "    datos_exportar.append({\n",
    "        \"ID\": id_valor,\n",
    "        nombre_pregunta: cod[\"texto\"],  # Columna con el nombre de la pregunta\n",
    "        \"C√≥digos asignados\": codigos_final\n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(datos_exportar)\n",
    "\n",
    "# Excel 2: Crear cat√°logo de c√≥digos nuevos (solo si hay c√≥digos nuevos)\n",
    "codigos_nuevos_unicos = {}\n",
    "for cod in resultado_final_v3[\"codificaciones\"]:\n",
    "    if cod[\"codigos_nuevos\"]:\n",
    "        for nuevo in cod[\"codigos_nuevos\"]:\n",
    "            cod_id = nuevo[\"codigo\"]\n",
    "            if cod_id not in codigos_nuevos_unicos:\n",
    "                codigos_nuevos_unicos[cod_id] = nuevo[\"descripcion\"]\n",
    "\n",
    "df_catalogo_nuevos = pd.DataFrame([\n",
    "    {\"COD\": cod_id, \"TEXTO\": descripcion}\n",
    "    for cod_id, descripcion in sorted(codigos_nuevos_unicos.items())\n",
    "])\n",
    "\n",
    "# Guardar en Excel con 2 hojas\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "archivo_salida = project_root / \"notebooks\" / \"resultados\" / f\"resultados_v3_{timestamp}.xlsx\"\n",
    "archivo_salida.parent.mkdir(exist_ok=True)\n",
    "\n",
    "with pd.ExcelWriter(archivo_salida, engine='openpyxl') as writer:\n",
    "    # Excel 1: Resultados\n",
    "    df_resultados.to_excel(writer, sheet_name='Resultados', index=False)\n",
    "    \n",
    "    # Excel 2: C√≥digos Nuevos (solo si hay c√≥digos nuevos)\n",
    "    if not df_catalogo_nuevos.empty:\n",
    "        df_catalogo_nuevos.to_excel(writer, sheet_name='C√≥digos Nuevos', index=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üì• RESULTADOS EXPORTADOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úÖ Archivo: {archivo_salida.name}\")\n",
    "print(f\"üìä Hojas:\")\n",
    "print(f\"   ‚Ä¢ Resultados: {len(df_resultados)} filas\")\n",
    "print(f\"     Columnas: ID, '{nombre_pregunta}', C√≥digos asignados\")\n",
    "if not df_catalogo_nuevos.empty:\n",
    "    print(f\"   ‚Ä¢ C√≥digos Nuevos: {len(df_catalogo_nuevos)} c√≥digos\")\n",
    "    print(f\"     Columnas: COD, TEXTO\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ C√≥digos Nuevos: (vac√≠o - no se generaron c√≥digos nuevos)\")\n",
    "\n",
    "print(f\"\\nüìã Vista previa de Resultados (primeras 3 filas):\\n\")\n",
    "print(df_resultados.head(3).to_string())\n",
    "if not df_catalogo_nuevos.empty:\n",
    "    print(f\"\\nüìã Vista previa de C√≥digos Nuevos:\\n\")\n",
    "    print(df_catalogo_nuevos.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Divisi√≥n de Prompts por Nodo\n",
    "\n",
    "### **Nodo 1: VALIDAR** ‚úÖ\n",
    "- **Responsabilidad**: Filtrar respuestas basura\n",
    "- **Prompt**: Simple, solo reglas de rechazo/aceptaci√≥n\n",
    "- **No necesita** reglas de especificidad\n",
    "\n",
    "### **Nodo 2: EVALUAR_CATALOGO** ‚úÖ\n",
    "- **Responsabilidad**: Evaluar si c√≥digos hist√≥ricos aplican (booleano)\n",
    "- **Prompt**: Mejorado con reglas de evaluaci√≥n:\n",
    "  - Considera nivel de especificidad (busca idea central, no palabras exactas)\n",
    "  - Permite m√∫ltiples c√≥digos por respuesta\n",
    "  - Gu√≠a de confianza (0.7-1.0 para aplicar)\n",
    "  - Enfoque conservador (mejor dejar sin c√≥digo que asignar incorrecto)\n",
    "\n",
    "### **Nodo 3: IDENTIFICAR_CONCEPTOS** ‚úÖ\n",
    "- **Responsabilidad**: Crear c√≥digos nuevos o identificar gaps\n",
    "- **Prompt**: **COMPLETO** con todas las reglas de especificidad de `gpt_hibrido.py`\n",
    "- **Incluye**: Nivel de especificidad, agrupaci√≥n, unicidad, etc.\n",
    "\n",
    "### **Nodo 4: JUSTIFICAR** ‚úÖ\n",
    "- **Responsabilidad**: Generar justificaciones breves\n",
    "- **Prompt**: Muy simple, solo pide ser conciso\n",
    "\n",
    "### **Nodo 5: ENSAMBLAR** ‚úÖ\n",
    "- **Responsabilidad**: Combinar resultados\n",
    "- **Sin prompt**: Solo l√≥gica de ensamblaje\n",
    "\n",
    "**Conclusi√≥n**: Los prompts est√°n divididos correctamente. El Nodo 3 tiene todas las reglas cr√≠ticas para crear c√≥digos nuevos.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Resumen de Mejoras V3\n",
    "\n",
    "### ‚úÖ C√≥digos Secuenciales Globales\n",
    "- Los c√≥digos nuevos son **secuenciales entre batches**\n",
    "- Contador global `proximo_codigo_nuevo` persiste durante toda la ejecuci√≥n\n",
    "- Si hay cat√°logo hist√≥rico ‚Üí empieza desde (max_codigo + 1)\n",
    "- Si NO hay cat√°logo ‚Üí empieza desde 1\n",
    "\n",
    "### ü§ñ GPT-5 Disponible\n",
    "- Modelo por defecto: **gpt-5** (disponible desde 2025)\n",
    "- Otros modelos: gpt-4o, gpt-4o-mini, gpt-4-turbo\n",
    "\n",
    "### üìä Exportaci√≥n Mejorada\n",
    "- **2 hojas en Excel:**\n",
    "  - Resultados: Respuestas con c√≥digos asignados\n",
    "  - C√≥digos Nuevos: Cat√°logo con IDs num√©ricos (COD, TEXTO)\n",
    "\n",
    "### üî¢ Ejemplo de Secuencialidad:\n",
    "```\n",
    "Batch 1: Genera c√≥digos 1, 2, 3\n",
    "Batch 2: Genera c√≥digos 4, 5, 6  ‚úÖ (no reinicia)\n",
    "Batch 3: Genera c√≥digos 7, 8     ‚úÖ (contin√∫a)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codificacion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
