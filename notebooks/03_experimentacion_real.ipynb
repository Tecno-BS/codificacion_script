{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß™ Experimentaci√≥n con Datos REALES\n",
        "\n",
        "Este notebook te permite experimentar con **tus archivos Excel reales** para ver c√≥mo funciona LangGraph con:\n",
        "\n",
        "1. ‚úÖ **Con cat√°logo hist√≥rico** - Reutilizar c√≥digos existentes\n",
        "2. ‚úÖ **Sin cat√°logo hist√≥rico** - Generar todo desde cero\n",
        "3. ‚úÖ **Control de costos** - Limitar n√∫mero de respuestas\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö†Ô∏è ADVERTENCIA\n",
        "\n",
        "Este notebook **S√ç consume cr√©ditos de OpenAI API**. \n",
        "\n",
        "- Puedes limitar el n√∫mero de respuestas a procesar\n",
        "- Costo estimado: ~$0.01-0.05 por cada 20-50 respuestas (con gpt-4o-mini)\n",
        "- Recomendaci√≥n: Empieza con 10-20 respuestas para probar\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Setup completo\n",
            "üìÇ Ruta del proyecto: c:\\Users\\ivan\\Documents\\cod-script\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Agregar ruta del proyecto\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.append(str(project_root / \"backend\" / \"src\"))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(project_root / \".env\")\n",
        "\n",
        "# Verificar\n",
        "assert os.getenv(\"OPENAI_API_KEY\"), \"‚ùå Falta OPENAI_API_KEY\"\n",
        "print(\"‚úÖ Setup completo\")\n",
        "print(f\"üìÇ Ruta del proyecto: {project_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Imports cargados\n"
          ]
        }
      ],
      "source": [
        "# Imports necesarios\n",
        "from typing import TypedDict, List, Dict, Literal\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "print(\"‚úÖ Imports cargados\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìÇ Paso 1: Cargar Datos Reales\n",
        "\n",
        "Carga tu archivo Excel con respuestas y (opcionalmente) el cat√°logo hist√≥rico.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚öôÔ∏è Configuraci√≥n:\n",
            "   üìÑ Archivo: P5 - copia.xlsx\n",
            "   üìö Cat√°logo hist√≥rico: ‚úÖ S√≠\n",
            "   üìä L√≠mite respuestas: Sin l√≠mite\n",
            "   ü§ñ Modelo: gpt-4.1\n",
            "   üì¶ Tama√±o de batch: 10\n",
            "\n",
            "üí° NOTA: La SEGUNDA columna del Excel se usar√° autom√°ticamente como respuestas\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# üéõÔ∏è CONFIGURACI√ìN EDITABLE\n",
        "# ========================================\n",
        "\n",
        "# 1. Archivo Excel con respuestas\n",
        "ARCHIVO_RESPUESTAS = project_root / \"temp\" / \"P5 - copia.xlsx\"  # üìù Cambia esta ruta\n",
        "\n",
        "# 2. Cat√°logo hist√≥rico (opcional)\n",
        "USAR_CATALOGO_HISTORICO = True  # üìù True = con cat√°logo, False = sin cat√°logo\n",
        "ARCHIVO_CATALOGO = project_root / \"result\" / \"modelos\" / \"catalogo_propuestos.xlsx\"\n",
        "\n",
        "# 3. Control de costos\n",
        "MAX_RESPUESTAS = None  # üìù L√≠mite de respuestas a procesar (None = todas)\n",
        "BATCH_SIZE = 10      # üìù Cu√°ntas respuestas enviar por llamada a GPT\n",
        "\n",
        "# 4. Modelo GPT\n",
        "MODELO_GPT = \"gpt-4.1\"  # üìù Opciones: \"gpt-4o-mini\" (barato) | \"gpt-4o\" (preciso)\n",
        "\n",
        "# ========================================\n",
        "\n",
        "print(\"‚öôÔ∏è Configuraci√≥n:\")\n",
        "print(f\"   üìÑ Archivo: {ARCHIVO_RESPUESTAS.name}\")\n",
        "print(f\"   üìö Cat√°logo hist√≥rico: {'‚úÖ S√≠' if USAR_CATALOGO_HISTORICO else '‚ùå No'}\")\n",
        "print(f\"   üìä L√≠mite respuestas: {MAX_RESPUESTAS if MAX_RESPUESTAS else 'Sin l√≠mite'}\")\n",
        "print(f\"   ü§ñ Modelo: {MODELO_GPT}\")\n",
        "print(f\"   üì¶ Tama√±o de batch: {BATCH_SIZE}\")\n",
        "\n",
        "print(\"\\nüí° NOTA: La SEGUNDA columna del Excel se usar√° autom√°ticamente como respuestas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìÇ CARGANDO RESPUESTAS\n",
            "============================================================\n",
            "\n",
            "üìã Estructura del Excel:\n",
            "   Columna 0: 'ID' (280 valores) \n",
            "   Columna 1: '5.Teniendo en cuenta la imagen que acaba de ver ¬øQu√© cree que le est√° tratando de comunicar? Profundice en su respuestaLe tratando comunicar' (280 valores) üëà RESPUESTAS\n",
            "\n",
            "‚úÖ Usando columna de respuestas: '5.Teniendo en cuenta la imagen que acaba de ver ¬øQu√© cree que le est√° tratando de comunicar? Profundice en su respuestaLe tratando comunicar'\n",
            "\n",
            "‚úÖ Cargadas 280 respuestas de la pregunta '5.Teniendo en cuenta la imagen que acaba de ver ¬øQu√© cree que le est√° tratando de comunicar? Profundice en su respuestaLe tratando comunicar'\n",
            "\n",
            "üìù Primeros 3 ejemplos:\n",
            "   1. (Fila 2) -\n",
            "   2. (Fila 3) que podemos ocuparla para cualquier alimento o bebida\n",
            "   3. (Fila 4) -\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n para cargar datos reales (SIMPLIFICADA)\n",
        "def cargar_datos_excel(archivo_path: Path, max_respuestas: int = None) -> tuple[List[Dict], str]:\n",
        "    \"\"\"\n",
        "    Carga respuestas desde Excel real\n",
        "    CONVENCI√ìN: La SEGUNDA columna (√≠ndice 1) SIEMPRE contiene las respuestas\n",
        "    \"\"\"\n",
        "    if not archivo_path.exists():\n",
        "        raise FileNotFoundError(f\"‚ùå No se encontr√≥: {archivo_path}\")\n",
        "    \n",
        "    # Leer Excel\n",
        "    df = pd.read_excel(archivo_path)\n",
        "    \n",
        "    print(f\"\\nüìã Estructura del Excel:\")\n",
        "    for i, col in enumerate(df.columns):\n",
        "        tipo = df[col].dtype\n",
        "        no_nulos = df[col].notna().sum()\n",
        "        indicador = \"üëà RESPUESTAS\" if i == 1 else \"\"\n",
        "        print(f\"   Columna {i}: '{col}' ({no_nulos} valores) {indicador}\")\n",
        "    \n",
        "    # SIEMPRE usar la segunda columna (√≠ndice 1)\n",
        "    if len(df.columns) < 2:\n",
        "        raise ValueError(\"El Excel debe tener al menos 2 columnas (ID y Respuestas)\")\n",
        "    \n",
        "    columna_respuestas = df.columns[1]\n",
        "    nombre_pregunta = str(columna_respuestas)  # Para usar en reportes\n",
        "    \n",
        "    print(f\"\\n‚úÖ Usando columna de respuestas: '{columna_respuestas}'\")\n",
        "    \n",
        "    # Filtrar respuestas v√°lidas\n",
        "    df_respuestas = df[[columna_respuestas]].copy()\n",
        "    df_respuestas = df_respuestas.dropna()  # Eliminar NaN\n",
        "    df_respuestas = df_respuestas[df_respuestas[columna_respuestas].astype(str).str.strip() != \"\"]  # Eliminar vac√≠as\n",
        "    \n",
        "    # Limitar si se especifica\n",
        "    if max_respuestas:\n",
        "        df_respuestas = df_respuestas.head(max_respuestas)\n",
        "    \n",
        "    # Convertir a formato interno\n",
        "    respuestas = []\n",
        "    for idx, row in df_respuestas.iterrows():\n",
        "        texto = str(row[columna_respuestas]).strip()\n",
        "        respuestas.append({\n",
        "            \"texto\": texto,\n",
        "            \"fila_excel\": idx + 2  # +2 porque Excel empieza en 1 y tiene header\n",
        "        })\n",
        "    \n",
        "    return respuestas, nombre_pregunta\n",
        "\n",
        "# Cargar respuestas\n",
        "print(\"=\"*60)\n",
        "print(\"üìÇ CARGANDO RESPUESTAS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    respuestas_reales, nombre_pregunta = cargar_datos_excel(ARCHIVO_RESPUESTAS, MAX_RESPUESTAS)\n",
        "    print(f\"\\n‚úÖ Cargadas {len(respuestas_reales)} respuestas de la pregunta '{nombre_pregunta}'\")\n",
        "    print(f\"\\nüìù Primeros 3 ejemplos:\")\n",
        "    for i, resp in enumerate(respuestas_reales[:3], 1):\n",
        "        texto_corto = resp['texto'][:70] + \"...\" if len(resp['texto']) > 70 else resp['texto']\n",
        "        print(f\"   {i}. (Fila {resp['fila_excel']}) {texto_corto}\")\n",
        "    print(\"=\"*60)\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error al cargar respuestas: {e}\")\n",
        "    print(\"\\nüí° Aseg√∫rate de que:\")\n",
        "    print(\"   1. El Excel tiene al menos 2 columnas\")\n",
        "    print(\"   2. La SEGUNDA columna contiene las respuestas\")\n",
        "    print(\"   3. El archivo existe en la ruta especificada\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üìö CARGANDO CAT√ÅLOGO HIST√ìRICO\n",
            "============================================================\n",
            "‚ö†Ô∏è No se encontr√≥ cat√°logo: c:\\Users\\ivan\\Documents\\cod-script\\result\\modelos\\catalogo_propuestos.xlsx\n",
            "\n",
            "‚ö†Ô∏è No se cargaron c√≥digos del cat√°logo\n",
            "   Revisa que el archivo exista y tenga el formato correcto\n",
            "   Archivo: c:\\Users\\ivan\\Documents\\cod-script\\result\\modelos\\catalogo_propuestos.xlsx\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n para cargar cat√°logo hist√≥rico (MEJORADA)\n",
        "def cargar_catalogo_historico(archivo_path: Path, pregunta: str) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Carga cat√°logo hist√≥rico desde Excel\n",
        "    Asume que el archivo YA est√° filtrado por pregunta (no necesita buscar)\n",
        "    \"\"\"\n",
        "    if not archivo_path.exists():\n",
        "        print(f\"‚ö†Ô∏è No se encontr√≥ cat√°logo: {archivo_path}\")\n",
        "        return []\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_excel(archivo_path)\n",
        "        \n",
        "        print(f\"\\nüìã Columnas en el cat√°logo:\")\n",
        "        print(f\"   {list(df.columns)}\")\n",
        "        \n",
        "        # Buscar columnas de c√≥digo y descripci√≥n (flexibles)\n",
        "        col_codigo = None\n",
        "        col_descripcion = None\n",
        "        \n",
        "        # Buscar columna de c√≥digo\n",
        "        for col in df.columns:\n",
        "            col_lower = str(col).lower()\n",
        "            if any(palabra in col_lower for palabra in ['codigo', 'code', 'cod', 'id']):\n",
        "                col_codigo = col\n",
        "                break\n",
        "        \n",
        "        # Buscar columna de descripci√≥n\n",
        "        for col in df.columns:\n",
        "            col_lower = str(col).lower()\n",
        "            if any(palabra in col_lower for palabra in ['descripcion', 'description', 'desc', 'categoria']):\n",
        "                col_descripcion = col\n",
        "                break\n",
        "        \n",
        "        # Si no se encuentran, usar las primeras dos columnas (despu√©s de ID si existe)\n",
        "        if col_codigo is None or col_descripcion is None:\n",
        "            columnas_validas = [c for c in df.columns if str(c).lower() not in ['unnamed', 'pregunta']]\n",
        "            if len(columnas_validas) >= 2:\n",
        "                col_codigo = columnas_validas[0]\n",
        "                col_descripcion = columnas_validas[1]\n",
        "                print(f\"\\nüí° Usando columnas por defecto:\")\n",
        "                print(f\"   C√≥digo: '{col_codigo}'\")\n",
        "                print(f\"   Descripci√≥n: '{col_descripcion}'\")\n",
        "        \n",
        "        if col_codigo is None or col_descripcion is None:\n",
        "            print(f\"‚ö†Ô∏è No se pudieron identificar columnas de c√≥digo/descripci√≥n\")\n",
        "            return []\n",
        "        \n",
        "        # Extraer c√≥digos\n",
        "        catalogo = []\n",
        "        for idx, row in df.iterrows():\n",
        "            codigo = row[col_codigo]\n",
        "            descripcion = row[col_descripcion]\n",
        "            \n",
        "            if pd.notna(codigo) and pd.notna(descripcion):\n",
        "                # Limpiar y validar\n",
        "                desc_str = str(descripcion).strip()\n",
        "                if desc_str and desc_str.lower() not in ['nan', 'none', '']:\n",
        "                    catalogo.append({\n",
        "                        \"codigo\": int(codigo) if isinstance(codigo, (int, float)) else codigo,\n",
        "                        \"descripcion\": desc_str\n",
        "                    })\n",
        "        \n",
        "        return catalogo\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error al cargar cat√°logo: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return []\n",
        "\n",
        "# Cargar cat√°logo (si est√° habilitado)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìö CARGANDO CAT√ÅLOGO HIST√ìRICO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if USAR_CATALOGO_HISTORICO:\n",
        "    catalogo_historico = cargar_catalogo_historico(ARCHIVO_CATALOGO, PREGUNTA_A_CODIFICAR)\n",
        "    \n",
        "    if catalogo_historico:\n",
        "        print(f\"\\n‚úÖ Cat√°logo hist√≥rico cargado: {len(catalogo_historico)} c√≥digos\")\n",
        "        print(f\"\\nüìã Primeros 5 c√≥digos:\")\n",
        "        for cod in catalogo_historico[:5]:\n",
        "            desc_corta = cod['descripcion'][:50] + \"...\" if len(cod['descripcion']) > 50 else cod['descripcion']\n",
        "            print(f\"   [{cod['codigo']}] {desc_corta}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è No se cargaron c√≥digos del cat√°logo\")\n",
        "        print(f\"   Revisa que el archivo exista y tenga el formato correcto\")\n",
        "        print(f\"   Archivo: {ARCHIVO_CATALOGO}\")\n",
        "else:\n",
        "    catalogo_historico = []\n",
        "    print(f\"\\n‚ö†Ô∏è Cat√°logo hist√≥rico DESACTIVADO\")\n",
        "    print(f\"   Se generar√°n TODOS los c√≥digos desde cero\")\n",
        "\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üèóÔ∏è Paso 2: Definir el Grafo LangGraph\n",
        "\n",
        "Reutilizamos el mismo grafo del notebook anterior, pero adaptado para datos reales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Esquemas definidos\n"
          ]
        }
      ],
      "source": [
        "# Definir estado\n",
        "class EstadoCodificacion(TypedDict):\n",
        "    \"\"\"Estado que fluye por el grafo\"\"\"\n",
        "    pregunta: str\n",
        "    modelo_gpt: str\n",
        "    batch_size: int\n",
        "    respuestas: List[Dict]\n",
        "    catalogo: List[Dict]\n",
        "    batch_actual: int\n",
        "    total_batches: int\n",
        "    batch_respuestas: List[Dict]\n",
        "    codificaciones: List[Dict]\n",
        "    codigos_nuevos_global: Dict[str, str]\n",
        "    contador_codigo_nuevo: int\n",
        "    costo_total: float\n",
        "    tokens_total: int\n",
        "    mensaje_estado: str\n",
        "    progreso_pct: float\n",
        "    tiempo_inicio: float\n",
        "    tiempo_total: float\n",
        "\n",
        "# Esquemas Pydantic\n",
        "class ResultadoCodificacionGPT(BaseModel):\n",
        "    respuesta_id: int = Field(description=\"ID de la respuesta (1-based)\")\n",
        "    decision: Literal[\"historico\", \"nuevo\", \"mixto\", \"rechazar\"] = Field(\n",
        "        description=\"Tipo de codificaci√≥n\"\n",
        "    )\n",
        "    codigos_historicos: List[int] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"C√≥digos del cat√°logo hist√≥rico\"\n",
        "    )\n",
        "    codigos_nuevos: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Descripciones de c√≥digos nuevos\"\n",
        "    )\n",
        "    justificacion: str = Field(description=\"Por qu√© se asignaron estos c√≥digos\")\n",
        "\n",
        "class RespuestaBatchGPT(BaseModel):\n",
        "    codificaciones: List[ResultadoCodificacionGPT] = Field(\n",
        "        description=\"Lista de codificaciones para el batch\"\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Esquemas definidos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Nodos definidos\n"
          ]
        }
      ],
      "source": [
        "# NODOS DEL GRAFO\n",
        "\n",
        "def nodo_inicializar(state: EstadoCodificacion) -> EstadoCodificacion:\n",
        "    \"\"\"Prepara el estado inicial\"\"\"\n",
        "    total_batches = (len(state[\"respuestas\"]) + state[\"batch_size\"] - 1) // state[\"batch_size\"]\n",
        "    print(f\"\\nüöÄ Iniciando codificaci√≥n\")\n",
        "    print(f\"   üì¶ {len(state['respuestas'])} respuestas en {total_batches} batches\")\n",
        "    print(f\"   üìö Cat√°logo: {len(state['catalogo'])} c√≥digos hist√≥ricos\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"total_batches\": total_batches,\n",
        "        \"batch_actual\": 0,\n",
        "        \"tiempo_inicio\": time.time()\n",
        "    }\n",
        "\n",
        "def nodo_preparar_batch(state: EstadoCodificacion) -> EstadoCodificacion:\n",
        "    \"\"\"Extrae el siguiente batch\"\"\"\n",
        "    inicio = state[\"batch_actual\"] * state[\"batch_size\"]\n",
        "    fin = min(inicio + state[\"batch_size\"], len(state[\"respuestas\"]))\n",
        "    batch = state[\"respuestas\"][inicio:fin]\n",
        "    progreso = ((state[\"batch_actual\"] + 1) / state[\"total_batches\"]) * 100\n",
        "    \n",
        "    print(f\"\\nüì¶ Batch {state['batch_actual'] + 1}/{state['total_batches']} ({progreso:.1f}%)\")\n",
        "    print(f\"   Procesando respuestas {inicio+1} a {fin}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"batch_respuestas\": batch,\n",
        "        \"progreso_pct\": progreso,\n",
        "        \"mensaje_estado\": f\"Batch {state['batch_actual'] + 1}/{state['total_batches']}\"\n",
        "    }\n",
        "\n",
        "def nodo_codificar_batch(state: EstadoCodificacion) -> EstadoCodificacion:\n",
        "    \"\"\"Llama a GPT para codificar\"\"\"\n",
        "    # Preparar prompt\n",
        "    if state[\"catalogo\"]:\n",
        "        catalogo_str = \"\\\\n\".join([\n",
        "            f\"- C√≥digo {c['codigo']}: {c['descripcion']}\"\n",
        "            for c in state[\"catalogo\"]\n",
        "        ])\n",
        "        instruccion_catalogo = f\"\"\"\n",
        "CAT√ÅLOGO HIST√ìRICO DISPONIBLE:\n",
        "{catalogo_str}\n",
        "\n",
        "PRIORIDAD: Usa c√≥digos hist√≥ricos cuando apliquen. Solo crea nuevos si la idea NO est√° en el cat√°logo.\n",
        "\"\"\"\n",
        "    else:\n",
        "        catalogo_str = \"Sin cat√°logo hist√≥rico disponible.\"\n",
        "        instruccion_catalogo = \"\"\"\n",
        "NO HAY CAT√ÅLOGO HIST√ìRICO: Debes crear c√≥digos nuevos para TODAS las respuestas v√°lidas.\n",
        "\"\"\"\n",
        "    \n",
        "    respuestas_str = \"\\\\n\".join([\n",
        "        f\"{i+1}. {r['texto']}\"\n",
        "        for i, r in enumerate(state[\"batch_respuestas\"])\n",
        "    ])\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", f\"\"\"Eres un experto en codificaci√≥n de respuestas abiertas.\n",
        "\n",
        "{instruccion_catalogo}\n",
        "\n",
        "INSTRUCCIONES:\n",
        "1. Para cada respuesta, decide:\n",
        "   - \"historico\": Si hay c√≥digos del cat√°logo que apliquen\n",
        "   - \"nuevo\": Si se necesitan c√≥digos nuevos\n",
        "   - \"mixto\": Combinaci√≥n de hist√≥ricos y nuevos\n",
        "   - \"rechazar\": Si la respuesta no es v√°lida\n",
        "\n",
        "2. Puedes asignar M√öLTIPLES c√≥digos si hay varias ideas diferentes.\n",
        "\n",
        "3. Para c√≥digos nuevos, s√© ESPEC√çFICO pero NO redundante:\n",
        "   ‚úÖ \"Versatilidad de uso\"\n",
        "   ‚ùå \"Versatilidad de uso en diferentes comidas\" (muy espec√≠fico)\n",
        "   ‚ùå \"Versatilidad\" (muy gen√©rico)\n",
        "\n",
        "4. UNIFICA descripciones similares:\n",
        "   - \"Buen sabor\" y \"Sabor agradable\" ‚Üí Usa UNA sola\n",
        "   - \"F√°cil de usar\" y \"Facilidad de uso\" ‚Üí Usa UNA sola\n",
        "\n",
        "Responde en formato JSON estructurado.\"\"\"),\n",
        "        (\"user\", \"PREGUNTA: {pregunta}\\\\n\\\\nRESPUESTAS:\\\\n{respuestas}\")\n",
        "    ])\n",
        "    \n",
        "    # Llamar a GPT\n",
        "    llm = ChatOpenAI(model=state[\"modelo_gpt\"], temperature=0)\n",
        "    chain = prompt | llm.with_structured_output(RespuestaBatchGPT)\n",
        "    \n",
        "    print(f\"   ü§ñ Llamando a {state['modelo_gpt']}...\")\n",
        "    inicio_llamada = time.time()\n",
        "    \n",
        "    resultado = chain.invoke({\n",
        "        \"pregunta\": state[\"pregunta\"],\n",
        "        \"respuestas\": respuestas_str\n",
        "    })\n",
        "    \n",
        "    tiempo_llamada = time.time() - inicio_llamada\n",
        "    print(f\"   ‚úÖ Respuesta recibida en {tiempo_llamada:.1f}s\")\n",
        "    \n",
        "    # Convertir a formato interno\n",
        "    codificaciones_batch = []\n",
        "    for cod in resultado.codificaciones:\n",
        "        codificaciones_batch.append({\n",
        "            \"fila_excel\": state[\"batch_respuestas\"][cod.respuesta_id - 1][\"fila_excel\"],\n",
        "            \"texto\": state[\"batch_respuestas\"][cod.respuesta_id - 1][\"texto\"],\n",
        "            \"decision\": cod.decision,\n",
        "            \"codigos_historicos\": cod.codigos_historicos,\n",
        "            \"codigos_nuevos\": cod.codigos_nuevos,\n",
        "            \"justificacion\": cod.justificacion\n",
        "        })\n",
        "    \n",
        "    # Mostrar resumen\n",
        "    decisiones = {}\n",
        "    for cod in codificaciones_batch:\n",
        "        dec = cod[\"decision\"]\n",
        "        decisiones[dec] = decisiones.get(dec, 0) + 1\n",
        "    \n",
        "    print(f\"   üìä Decisiones: {decisiones}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"codificaciones\": state[\"codificaciones\"] + codificaciones_batch,\n",
        "        \"mensaje_estado\": f\"Batch {state['batch_actual'] + 1} completado\"\n",
        "    }\n",
        "\n",
        "def nodo_incrementar_batch(state: EstadoCodificacion) -> EstadoCodificacion:\n",
        "    \"\"\"Avanza al siguiente batch\"\"\"\n",
        "    nuevo_batch = state[\"batch_actual\"] + 1\n",
        "    print(f\"   ‚è≠Ô∏è  Incrementando batch: {state['batch_actual']} ‚Üí {nuevo_batch}\")\n",
        "    return {**state, \"batch_actual\": nuevo_batch}\n",
        "\n",
        "def similitud_jaccard(desc1: str, desc2: str) -> float:\n",
        "    \"\"\"Calcula similitud entre descripciones\"\"\"\n",
        "    palabras1 = set(desc1.lower().split())\n",
        "    palabras2 = set(desc2.lower().split())\n",
        "    interseccion = len(palabras1 & palabras2)\n",
        "    union = len(palabras1 | palabras2)\n",
        "    return interseccion / union if union > 0 else 0.0\n",
        "\n",
        "def nodo_normalizar(state: EstadoCodificacion) -> EstadoCodificacion:\n",
        "    \"\"\"Unifica c√≥digos nuevos redundantes\"\"\"\n",
        "    print(f\"\\\\nüîß Normalizando c√≥digos nuevos...\")\n",
        "    \n",
        "    descripciones_vistas = {}\n",
        "    mapeo = {}\n",
        "    contador = 1\n",
        "    \n",
        "    for cod in state[\"codificaciones\"]:\n",
        "        for desc in cod[\"codigos_nuevos\"]:\n",
        "            encontrado = False\n",
        "            for desc_norm, _ in descripciones_vistas.items():\n",
        "                # Similitud por Jaccard\n",
        "                sim = similitud_jaccard(desc, desc_norm)\n",
        "                # O si una contiene a la otra\n",
        "                contiene = desc.lower() in desc_norm.lower() or desc_norm.lower() in desc.lower()\n",
        "                \n",
        "                if sim > 0.6 or contiene:\n",
        "                    mapeo[desc] = desc_norm\n",
        "                    encontrado = True\n",
        "                    print(f\"   ‚ôªÔ∏è  '{desc}' ‚Üí '{desc_norm}'\")\n",
        "                    break\n",
        "            \n",
        "            if not encontrado:\n",
        "                mapeo[desc] = desc\n",
        "                descripciones_vistas[desc] = contador\n",
        "                contador += 1\n",
        "    \n",
        "    codigos_nuevos_global = {}\n",
        "    contador_nuevo = 1\n",
        "    for desc_norm in descripciones_vistas.keys():\n",
        "        codigo_final = f\"N{contador_nuevo}\"\n",
        "        codigos_nuevos_global[desc_norm] = codigo_final\n",
        "        contador_nuevo += 1\n",
        "    \n",
        "    print(f\"   ‚úÖ {len(codigos_nuevos_global)} c√≥digos nuevos √∫nicos\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"codigos_nuevos_global\": codigos_nuevos_global,\n",
        "        \"contador_codigo_nuevo\": contador_nuevo,\n",
        "        \"mensaje_estado\": \"Normalizaci√≥n completa\"\n",
        "    }\n",
        "\n",
        "def nodo_finalizar(state: EstadoCodificacion) -> EstadoCodificacion:\n",
        "    \"\"\"Calcula m√©tricas finales\"\"\"\n",
        "    tiempo_total = time.time() - state[\"tiempo_inicio\"]\n",
        "    \n",
        "    print(f\"\\\\nüéâ ¬°Codificaci√≥n completada!\")\n",
        "    print(f\"   ‚è±Ô∏è  Tiempo total: {tiempo_total:.1f}s\")\n",
        "    print(f\"   üìä {len(state['codificaciones'])} respuestas codificadas\")\n",
        "    print(f\"   üÜï {len(state['codigos_nuevos_global'])} c√≥digos nuevos generados\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"tiempo_total\": tiempo_total,\n",
        "        \"progreso_pct\": 100.0,\n",
        "        \"mensaje_estado\": \"Completado\"\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Nodos definidos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Grafo compilado y listo para ejecutar\n",
            "üí° L√≠mite de recursi√≥n: 25 iteraciones por defecto\n"
          ]
        }
      ],
      "source": [
        "# Construir el grafo\n",
        "def decidir_continuar(state: EstadoCodificacion) -> str:\n",
        "    \"\"\"\n",
        "    Decide si procesar m√°s batches o terminar\n",
        "    IMPORTANTE: Esta funci√≥n se llama DESPU√âS de incrementar batch_actual\n",
        "    \"\"\"\n",
        "    batches_procesados = state[\"batch_actual\"]\n",
        "    total = state[\"total_batches\"]\n",
        "    \n",
        "    print(f\"\\nüîÑ Decisi√≥n: Batch {batches_procesados}/{total}\")\n",
        "    \n",
        "    if batches_procesados < total:\n",
        "        print(f\"   ‚û°Ô∏è  Continuar con siguiente batch\")\n",
        "        return \"preparar_batch\"\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Todos los batches procesados, normalizando...\")\n",
        "        return \"normalizar\"\n",
        "\n",
        "workflow = StateGraph(EstadoCodificacion)\n",
        "\n",
        "workflow.add_node(\"inicializar\", nodo_inicializar)\n",
        "workflow.add_node(\"preparar_batch\", nodo_preparar_batch)\n",
        "workflow.add_node(\"codificar\", nodo_codificar_batch)\n",
        "workflow.add_node(\"incrementar\", nodo_incrementar_batch)\n",
        "workflow.add_node(\"normalizar\", nodo_normalizar)\n",
        "workflow.add_node(\"finalizar\", nodo_finalizar)\n",
        "\n",
        "workflow.set_entry_point(\"inicializar\")\n",
        "workflow.add_edge(\"inicializar\", \"preparar_batch\")\n",
        "workflow.add_edge(\"preparar_batch\", \"codificar\")\n",
        "workflow.add_edge(\"codificar\", \"incrementar\")\n",
        "\n",
        "# Decisi√≥n condicional despu√©s de incrementar\n",
        "workflow.add_conditional_edges(\n",
        "    \"incrementar\",\n",
        "    decidir_continuar,\n",
        "    {\n",
        "        \"preparar_batch\": \"preparar_batch\",\n",
        "        \"normalizar\": \"normalizar\"\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"normalizar\", \"finalizar\")\n",
        "workflow.add_edge(\"finalizar\", END)\n",
        "\n",
        "# Compilar con l√≠mite de recursi√≥n aumentado\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"‚úÖ Grafo compilado y listo para ejecutar\")\n",
        "print(\"üí° L√≠mite de recursi√≥n: 25 iteraciones por defecto\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Respuestas cargadas: 280\n",
            "‚ö†Ô∏è  ADVERTENCIA: Cat√°logo hist√≥rico habilitado pero vac√≠o\n",
            "   Se generar√°n todos los c√≥digos como nuevos\n",
            "\n",
            "‚úÖ Todas las validaciones pasaron. Listo para ejecutar!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 2. Validar respuestas cargadas\n",
        "if len(respuestas_reales) == 0:\n",
        "    print(f\"\\n‚ùå ERROR: No hay respuestas cargadas\")\n",
        "    raise ValueError(\"respuestas_reales est√° vac√≠o\")\n",
        "else:\n",
        "    print(f\"‚úÖ Respuestas cargadas: {len(respuestas_reales)}\")\n",
        "\n",
        "# 3. Validar cat√°logo (si est√° habilitado)\n",
        "if USAR_CATALOGO_HISTORICO:\n",
        "    if len(catalogo_historico) == 0:\n",
        "        print(f\"‚ö†Ô∏è  ADVERTENCIA: Cat√°logo hist√≥rico habilitado pero vac√≠o\")\n",
        "        print(f\"   Se generar√°n todos los c√≥digos como nuevos\")\n",
        "    else:\n",
        "        print(f\"‚úÖ Cat√°logo cargado: {len(catalogo_historico)} c√≥digos\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Cat√°logo hist√≥rico deshabilitado - solo c√≥digos nuevos\")\n",
        "\n",
        "print(f\"\\n‚úÖ Todas las validaciones pasaron. Listo para ejecutar!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üöÄ Paso 3: EJECUTAR Codificaci√≥n\n",
        "\n",
        "‚ö†Ô∏è **Esta celda S√ç consume API de OpenAI**\n",
        "\n",
        "Seg√∫n tu configuraci√≥n:\n",
        "- Modelo: **{MODELO}**\n",
        "- Respuestas: **{MAX}**\n",
        "- Costo estimado: **~${COSTO}**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üöÄ INICIANDO CODIFICACI√ìN CON DATOS REALES\n",
            "============================================================\n",
            "\n",
            "üìä Resumen PRE-EJECUCI√ìN:\n",
            "   Total respuestas: 280\n",
            "   Batch size: 10\n",
            "   Cat√°logo: 0 c√≥digos\n",
            "   Batch actual: 0\n",
            "   Total batches: 0\n",
            "   Modelo: gpt-4.1\n",
            "\n",
            "üßÆ C√°lculo de batches:\n",
            "   280 respuestas √∑ 10 por batch\n",
            "   = 28 batches esperados\n",
            "\n",
            "‚öôÔ∏è Configuraci√≥n LangGraph:\n",
            "   L√≠mite de recursi√≥n: 150\n",
            "   (suficiente para 28 batches)\n",
            "\n",
            "============================================================\n",
            "EJECUTANDO...\n",
            "============================================================\n",
            "\n",
            "\n",
            "üöÄ Iniciando codificaci√≥n\n",
            "   üì¶ 280 respuestas en 28 batches\n",
            "   üìö Cat√°logo: 0 c√≥digos hist√≥ricos\n",
            "\n",
            "üì¶ Batch 1/28 (3.6%)\n",
            "   Procesando respuestas 1 a 10\n",
            "   ü§ñ Llamando a gpt-4.1...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Respuesta recibida en 5.4s\n",
            "   üìä Decisiones: {'rechazar': 6, 'nuevo': 4}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 0 ‚Üí 1\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 1/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 2/28 (7.1%)\n",
            "   Procesando respuestas 11 a 20\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 13.7s\n",
            "   üìä Decisiones: {'nuevo': 6, 'rechazar': 4}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 1 ‚Üí 2\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 2/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 3/28 (10.7%)\n",
            "   Procesando respuestas 21 a 30\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 12.9s\n",
            "   üìä Decisiones: {'rechazar': 5, 'nuevo': 5}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 2 ‚Üí 3\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 3/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 4/28 (14.3%)\n",
            "   Procesando respuestas 31 a 40\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 7.3s\n",
            "   üìä Decisiones: {'rechazar': 6, 'nuevo': 4}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 3 ‚Üí 4\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 4/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 5/28 (17.9%)\n",
            "   Procesando respuestas 41 a 50\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.0s\n",
            "   üìä Decisiones: {'nuevo': 4, 'rechazar': 6}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 4 ‚Üí 5\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 5/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 6/28 (21.4%)\n",
            "   Procesando respuestas 51 a 60\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 14.0s\n",
            "   üìä Decisiones: {'nuevo': 4, 'rechazar': 6}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 5 ‚Üí 6\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 6/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 7/28 (25.0%)\n",
            "   Procesando respuestas 61 a 70\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 7.0s\n",
            "   üìä Decisiones: {'rechazar': 4, 'nuevo': 6}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 6 ‚Üí 7\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 7/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 8/28 (28.6%)\n",
            "   Procesando respuestas 71 a 80\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 7.6s\n",
            "   üìä Decisiones: {'rechazar': 5, 'nuevo': 5}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 7 ‚Üí 8\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 8/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 9/28 (32.1%)\n",
            "   Procesando respuestas 81 a 90\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 2.6s\n",
            "   üìä Decisiones: {'nuevo': 3}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 8 ‚Üí 9\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 9/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 10/28 (35.7%)\n",
            "   Procesando respuestas 91 a 100\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 4.0s\n",
            "   üìä Decisiones: {'nuevo': 4}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 9 ‚Üí 10\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 10/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 11/28 (39.3%)\n",
            "   Procesando respuestas 101 a 110\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.8s\n",
            "   üìä Decisiones: {'nuevo': 5, 'rechazar': 5}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 10 ‚Üí 11\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 11/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 12/28 (42.9%)\n",
            "   Procesando respuestas 111 a 120\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.0s\n",
            "   üìä Decisiones: {'rechazar': 6, 'nuevo': 4}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 11 ‚Üí 12\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 12/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 13/28 (46.4%)\n",
            "   Procesando respuestas 121 a 130\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.4s\n",
            "   üìä Decisiones: {'nuevo': 7, 'rechazar': 3}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 12 ‚Üí 13\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 13/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 14/28 (50.0%)\n",
            "   Procesando respuestas 131 a 140\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 4.4s\n",
            "   üìä Decisiones: {'rechazar': 5, 'nuevo': 5}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 13 ‚Üí 14\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 14/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 15/28 (53.6%)\n",
            "   Procesando respuestas 141 a 150\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.4s\n",
            "   üìä Decisiones: {'nuevo': 5, 'rechazar': 5}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 14 ‚Üí 15\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 15/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 16/28 (57.1%)\n",
            "   Procesando respuestas 151 a 160\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 8.4s\n",
            "   üìä Decisiones: {'rechazar': 5, 'nuevo': 5}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 15 ‚Üí 16\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 16/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 17/28 (60.7%)\n",
            "   Procesando respuestas 161 a 170\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.7s\n",
            "   üìä Decisiones: {'nuevo': 4}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 16 ‚Üí 17\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 17/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 18/28 (64.3%)\n",
            "   Procesando respuestas 171 a 180\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 10.8s\n",
            "   üìä Decisiones: {'nuevo': 7, 'rechazar': 3}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 17 ‚Üí 18\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 18/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 19/28 (67.9%)\n",
            "   Procesando respuestas 181 a 190\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 4.8s\n",
            "   üìä Decisiones: {'rechazar': 7, 'nuevo': 3}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 18 ‚Üí 19\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 19/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 20/28 (71.4%)\n",
            "   Procesando respuestas 191 a 200\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.9s\n",
            "   üìä Decisiones: {'nuevo': 6, 'rechazar': 4}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 19 ‚Üí 20\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 20/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 21/28 (75.0%)\n",
            "   Procesando respuestas 201 a 210\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 6.5s\n",
            "   üìä Decisiones: {'nuevo': 5, 'rechazar': 5}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 20 ‚Üí 21\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 21/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 22/28 (78.6%)\n",
            "   Procesando respuestas 211 a 220\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.5s\n",
            "   üìä Decisiones: {'rechazar': 7, 'nuevo': 3}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 21 ‚Üí 22\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 22/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 23/28 (82.1%)\n",
            "   Procesando respuestas 221 a 230\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.5s\n",
            "   üìä Decisiones: {'nuevo': 7, 'rechazar': 3}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 22 ‚Üí 23\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 23/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 24/28 (85.7%)\n",
            "   Procesando respuestas 231 a 240\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.7s\n",
            "   üìä Decisiones: {'rechazar': 7, 'nuevo': 3}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 23 ‚Üí 24\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 24/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 25/28 (89.3%)\n",
            "   Procesando respuestas 241 a 250\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.3s\n",
            "   üìä Decisiones: {'rechazar': 5, 'nuevo': 5}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 24 ‚Üí 25\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 25/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 26/28 (92.9%)\n",
            "   Procesando respuestas 251 a 260\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.5s\n",
            "   üìä Decisiones: {'rechazar': 5, 'nuevo': 5}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 25 ‚Üí 26\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 26/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 27/28 (96.4%)\n",
            "   Procesando respuestas 261 a 270\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 5.8s\n",
            "   üìä Decisiones: {'rechazar': 5, 'nuevo': 5}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 26 ‚Üí 27\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 27/28\n",
            "   ‚û°Ô∏è  Continuar con siguiente batch\n",
            "\n",
            "üì¶ Batch 28/28 (100.0%)\n",
            "   Procesando respuestas 271 a 280\n",
            "   ü§ñ Llamando a gpt-4.1...\n",
            "   ‚úÖ Respuesta recibida en 6.1s\n",
            "   üìä Decisiones: {'nuevo': 5, 'rechazar': 5}\n",
            "   ‚è≠Ô∏è  Incrementando batch: 27 ‚Üí 28\n",
            "\n",
            "üîÑ Decisi√≥n: Batch 28/28\n",
            "   ‚úÖ Todos los batches procesados, normalizando...\n",
            "\\nüîß Normalizando c√≥digos nuevos...\n",
            "   ‚ôªÔ∏è  'Endulzante sin calor√≠as para uso cotidiano' ‚Üí 'Endulzante sin calor√≠as'\n",
            "   ‚ôªÔ∏è  'Producto saludable' ‚Üí 'Producto saludable para la salud'\n",
            "   ‚ôªÔ∏è  'Producto apto para personas con diabetes' ‚Üí 'Producto apto para personas con diabetes'\n",
            "   ‚ôªÔ∏è  'Versatilidad de uso en diferentes recetas y bebidas' ‚Üí 'Versatilidad de uso en alimentos y bebidas'\n",
            "   ‚ôªÔ∏è  'Versatilidad de uso' ‚Üí 'Versatilidad de uso en alimentos y bebidas'\n",
            "   ‚ôªÔ∏è  'El producto es m√°s saludable que el az√∫car' ‚Üí 'El producto es m√°s saludable'\n",
            "   ‚ôªÔ∏è  'El producto es saludable' ‚Üí 'El producto es m√°s saludable'\n",
            "   ‚ôªÔ∏è  'El producto aporta muchos beneficios para la salud' ‚Üí 'Beneficios para la salud'\n",
            "   ‚ôªÔ∏è  'Versatilidad de uso en alimentos y bebidas' ‚Üí 'Versatilidad de uso en alimentos y bebidas'\n",
            "   ‚ôªÔ∏è  'Endulzante sin calor√≠as' ‚Üí 'Endulzante sin calor√≠as'\n",
            "   ‚ôªÔ∏è  'Producto natural y saludable' ‚Üí 'Producto natural'\n",
            "   ‚ôªÔ∏è  'Beneficios del producto' ‚Üí 'Comunicaci√≥n de los beneficios del producto'\n",
            "   ‚ôªÔ∏è  'Opci√≥n saludable' ‚Üí 'Opci√≥n saludable para endulzar'\n",
            "   ‚ôªÔ∏è  'Producto para la salud personal' ‚Üí 'Producto saludable para la salud'\n",
            "   ‚ôªÔ∏è  'Promueve el cuidado de la salud' ‚Üí 'Promueve el cuidado de la salud'\n",
            "   ‚ôªÔ∏è  'Producto de alta calidad' ‚Üí 'Producto de alta calidad'\n",
            "   ‚ôªÔ∏è  'Versatilidad de uso en bebidas y postres' ‚Üí 'Versatilidad de uso en alimentos y bebidas'\n",
            "   ‚ôªÔ∏è  'Beneficios para la salud del producto' ‚Üí 'Beneficios para la salud'\n",
            "   ‚ôªÔ∏è  'Versatilidad de uso' ‚Üí 'Versatilidad de uso en alimentos y bebidas'\n",
            "   ‚ôªÔ∏è  'Endulzante sin calor√≠as' ‚Üí 'Endulzante sin calor√≠as'\n",
            "   ‚ôªÔ∏è  'Producto saludable' ‚Üí 'Producto saludable para la salud'\n",
            "   ‚ôªÔ∏è  'Producto saludable' ‚Üí 'Producto saludable para la salud'\n",
            "   ‚ôªÔ∏è  'Cuidar la salud' ‚Üí 'Recomendaci√≥n de usar un endulzante m√°s sano y de mejor calidad para cuidar la salud'\n",
            "   ‚ôªÔ∏è  'Bajo en calor√≠as' ‚Üí 'Variedad de preparaciones posibles con el endulzante bajo en calor√≠as'\n",
            "   ‚ôªÔ∏è  'Producto saludable' ‚Üí 'Producto saludable para la salud'\n",
            "   ‚ôªÔ∏è  'Endulzar sin calor√≠as' ‚Üí 'Producto para endulzar sin calor√≠as adicionales'\n",
            "   ‚ôªÔ∏è  'Versatilidad de uso' ‚Üí 'Versatilidad de uso en alimentos y bebidas'\n",
            "   ‚úÖ 127 c√≥digos nuevos √∫nicos\n",
            "\\nüéâ ¬°Codificaci√≥n completada!\n",
            "   ‚è±Ô∏è  Tiempo total: 187.6s\n",
            "   üìä 261 respuestas codificadas\n",
            "   üÜï 127 c√≥digos nuevos generados\n",
            "\n",
            "============================================================\n",
            "‚úÖ PROCESO COMPLETADO EXITOSAMENTE\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Estado inicial\n",
        "estado_inicial = {\n",
        "    \"pregunta\": nombre_pregunta,  # Usar el nombre detectado autom√°ticamente\n",
        "    \"modelo_gpt\": MODELO_GPT,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"respuestas\": respuestas_reales,\n",
        "    \"catalogo\": catalogo_historico,\n",
        "    \"batch_actual\": 0,\n",
        "    \"total_batches\": 0,\n",
        "    \"batch_respuestas\": [],\n",
        "    \"codificaciones\": [],\n",
        "    \"codigos_nuevos_global\": {},\n",
        "    \"contador_codigo_nuevo\": 1,\n",
        "    \"costo_total\": 0.0,\n",
        "    \"tokens_total\": 0,\n",
        "    \"mensaje_estado\": \"Iniciando...\",\n",
        "    \"progreso_pct\": 0.0,\n",
        "    \"tiempo_inicio\": 0.0,\n",
        "    \"tiempo_total\": 0.0\n",
        "}\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ INICIANDO CODIFICACI√ìN CON DATOS REALES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Validar estado inicial\n",
        "print(f\"\\nüìä Resumen PRE-EJECUCI√ìN:\")\n",
        "print(f\"   Total respuestas: {len(estado_inicial['respuestas'])}\")\n",
        "print(f\"   Batch size: {estado_inicial['batch_size']}\")\n",
        "print(f\"   Cat√°logo: {len(estado_inicial['catalogo'])} c√≥digos\")\n",
        "print(f\"   Batch actual: {estado_inicial['batch_actual']}\")\n",
        "print(f\"   Total batches: {estado_inicial['total_batches']}\")\n",
        "print(f\"   Modelo: {estado_inicial['modelo_gpt']}\")\n",
        "\n",
        "# Calcular batches esperados\n",
        "batches_esperados = (len(estado_inicial['respuestas']) + estado_inicial['batch_size'] - 1) // estado_inicial['batch_size']\n",
        "print(f\"\\nüßÆ C√°lculo de batches:\")\n",
        "print(f\"   {len(estado_inicial['respuestas'])} respuestas √∑ {estado_inicial['batch_size']} por batch\")\n",
        "print(f\"   = {batches_esperados} batches esperados\")\n",
        "\n",
        "if batches_esperados == 0:\n",
        "    print(f\"\\n‚ùå ERROR: No hay respuestas para procesar!\")\n",
        "    raise ValueError(\"No hay respuestas cargadas\")\n",
        "\n",
        "# EJECUTAR con configuraci√≥n de l√≠mite de recursi√≥n\n",
        "from langgraph.pregel.main import RunnableConfig\n",
        "\n",
        "# Calcular l√≠mite necesario: batches * 5 nodos por iteraci√≥n + margen\n",
        "limite_calculado = max(batches_esperados * 5 + 10, 50)\n",
        "\n",
        "config = RunnableConfig(\n",
        "    recursion_limit=limite_calculado\n",
        ")\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è Configuraci√≥n LangGraph:\")\n",
        "print(f\"   L√≠mite de recursi√≥n: {limite_calculado}\")\n",
        "print(f\"   (suficiente para {batches_esperados} batches)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EJECUTANDO...\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    resultado_final = app.invoke(estado_inicial, config=config)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ PROCESO COMPLETADO EXITOSAMENTE\")\n",
        "    print(\"=\"*60)\n",
        "except Exception as e:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚ùå ERROR DURANTE EJECUCI√ìN\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nError: {e}\")\n",
        "    print(f\"\\nTipo: {type(e).__name__}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìä Paso 4: Analizar Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä RESUMEN DE DECISIONES\n",
            "============================================================\n",
            "   NUEVO        : 134 respuestas (51.3%)\n",
            "   RECHAZAR     : 127 respuestas (48.7%)\n",
            "\n",
            "üÜï C√ìDIGOS NUEVOS GENERADOS: 127\n",
            "\\nüìã Lista de c√≥digos nuevos:\n",
            "   N1: Versatilidad de uso en alimentos y bebidas\n",
            "   N10: Beneficios para la salud\n",
            "   N100: Sensaci√≥n de bienestar al usar el producto\n",
            "   N101: El producto es un endulzante que cuida la salud\n",
            "   N102: Ayuda a reducir el consumo de az√∫car para mejorar la calidad de vida\n",
            "   N103: El producto es libre de az√∫car y calor√≠as\n",
            "   N104: Promueve el consumo de alimentos bajos en az√∫car\n",
            "   N105: Az√∫car saludable\n",
            "   N106: Versatilidad de uso en cualquier ocasi√≥n\n",
            "   N107: Promoci√≥n de edulcorantes\n",
            "   N108: Comunica que el producto es saludable\n",
            "   N109: Es una publicidad de un producto\n",
            "   N11: Permite conservar la salud sin sacrificar el sabor\n",
            "   N110: El producto es una opci√≥n sana para agregar a bebidas\n",
            "   N111: Sustituir el az√∫car por edulcorante\n",
            "   N112: Acompa√±amiento ideal para alimentos\n",
            "   N113: Usar Splenda para endulzar bebidas en lugar de az√∫car\n",
            "   N114: Opci√≥n m√°s rica y saludable para endulzar\n",
            "   N115: Mejor opci√≥n para cuidar la salud\n",
            "   N116: Producto m√°s saludable\n",
            "   N117: Apto para dieta\n",
            "   N118: Endulzar alimentos de manera saludable\n",
            "   N119: No da√±ar la salud al consumir el producto\n",
            "   N12: Invitaci√≥n a usar el producto\n",
            "   N120: Ayuda a mantener niveles de az√∫car controlados\n",
            "   N121: Consumo de az√∫car sano\n",
            "   N122: Desorden visual en la imagen\n",
            "   N123: Consumir un producto que beneficia la salud\n",
            "   N124: Promueve el cuidado del cuerpo al reducir el consumo de az√∫car\n",
            "   N125: No percibe ning√∫n mensaje\n",
            "   N126: Naturalidad y familiaridad del producto\n",
            "   N127: Asociaci√≥n del producto con personas saludables\n",
            "   N13: Producto para endulzar sin calor√≠as adicionales\n",
            "   N14: Beneficio para la salud\n",
            "   N15: Producto de alta calidad\n",
            "   N16: Novedad del producto\n",
            "   N17: El producto es especial y √∫nico\n",
            "   N18: El producto mejora la calidad de vida del consumidor\n",
            "   N19: Promueve el consumo reducido de az√∫car\n",
            "   N2: Producto apto para personas con diabetes\n",
            "   N20: Incentiva la compra del producto promocionado\n",
            "   N21: El producto es una forma m√°s sana de endulzar sin consecuencias negativas\n",
            "   N22: Invitaci√≥n a comprar Splenda para endulzar\n",
            "   N23: Comunicaci√≥n de los beneficios del producto\n",
            "   N24: Presentaci√≥n de Splenda como una forma saludable de endulzar los alimentos\n",
            "   N25: Comunicaci√≥n de los beneficios de consumir y comprar Splenda\n",
            "   N26: Permite consumir productos endulzados sin las calor√≠as del az√∫car real\n",
            "   N27: Splenda es la mejor opci√≥n de endulzante artificial para la salud y el sabor\n",
            "   N28: Producto m√°s sano por tener menos az√∫car\n",
            "   N29: Forma m√°s sana de endulzar los alimentos sustituyendo el az√∫car da√±ina\n",
            "   N3: Producto que no causa da√±o a la salud\n",
            "   N30: Producto sano\n",
            "   N31: Producto natural\n",
            "   N32: Sirve para endulzar alimentos y bebidas\n",
            "   N33: Permite disfrutar lo dulce sin los efectos negativos del az√∫car\n",
            "   N34: Permite endulzar cualquier alimento sin afectar la salud\n",
            "   N35: Percepci√≥n positiva del producto\n",
            "   N36: Sirve para endulzar postres\n",
            "   N37: Es un saborizante\n",
            "   N38: Relaci√≥n entre el producto y la salud\n",
            "   N39: Dificultad para comprender el mensaje\n",
            "   N4: Endulzante beneficioso para la salud\n",
            "   N40: Ingredientes de origen natural o m√°s saludables que el az√∫car\n",
            "   N41: Promoci√≥n de consumo de edulcorante saludable\n",
            "   N42: Asociaci√≥n del producto con bienestar\n",
            "   N43: Transmite optimismo y confianza\n",
            "   N44: Permite disfrutar de lo dulce sin culpa por la salud\n",
            "   N45: La idea es llamativa\n",
            "   N46: El producto es m√°s saludable\n",
            "   N47: Advertencia sobre los riesgos de consumir az√∫car procesada\n",
            "   N48: Promoci√≥n de disfrutar alimentos y bebidas cuidando la salud\n",
            "   N49: Presentaci√≥n de un endulzante saludable\n",
            "   N5: Producto rico en vitaminas\n",
            "   N50: Recomendaci√≥n de usar un endulzante m√°s sano y de mejor calidad para cuidar la salud\n",
            "   N51: Mejorar la salud mediante el consumo de una alternativa al az√∫car\n",
            "   N52: Cuidar la salud y reducir el consumo de az√∫cares nocivos\n",
            "   N53: Splenda endulza la vida\n",
            "   N54: Endulzar comidas de forma m√°s saludable\n",
            "   N55: Producto bueno para la salud y promueve una vida sana\n",
            "   N56: Permite cuidar la salud sin dejar de consumir endulzantes\n",
            "   N57: El endulzante es vers√°til y puede usarse en todo tipo de alimentos o bebidas\n",
            "   N58: Producto saludable que endulza\n",
            "   N59: El producto est√° disponible en distintas presentaciones o formatos\n",
            "   N6: Producto saludable para la salud\n",
            "   N60: Promueve el consumo de Splenda para cuidar la salud\n",
            "   N61: Presenta el producto como una opci√≥n m√°s saludable\n",
            "   N62: Promueve la alimentaci√≥n saludable\n",
            "   N63: Asocia el producto con el cuidado de la salud y la calidad\n",
            "   N64: Splenda es bueno para la salud y endulza sin calor√≠as\n",
            "   N65: Promueve el cuidado de la salud\n",
            "   N66: Sugiere que el edulcorante es mejor que el az√∫car para el estilo de vida actual\n",
            "   N67: Consumo del producto en diferentes ocasiones\n",
            "   N68: El producto es una buena alternativa al az√∫car\n",
            "   N69: Variedad de preparaciones posibles con el endulzante bajo en calor√≠as\n",
            "   N7: Endulzante sin calor√≠as\n",
            "   N70: El producto ayuda a cuidar la salud\n",
            "   N71: Invitaci√≥n a visitar el sitio web\n",
            "   N72: El producto ofrece beneficios y cuidados\n",
            "   N73: Se puede disfrutar de alimentos sabrosos de manera saludable\n",
            "   N74: Alternativa de az√∫car m√°s saludable\n",
            "   N75: Uso del producto para el autocuidado\n",
            "   N76: Comer saludablemente sin sacrificar sabor, figura y salud\n",
            "   N77: Cuidarse a trav√©s del producto\n",
            "   N78: Disfrutar del sabor dulce sin afectar la salud\n",
            "   N79: Falta de informaci√≥n sobre los motivos para elegir Splenda\n",
            "   N8: Publicidad de endulzante como alternativa m√°s sana al az√∫car\n",
            "   N80: Splenda es m√°s saludable que el az√∫car com√∫n\n",
            "   N81: Splenda permite dejar el az√∫car sin sacrificar el buen sabor\n",
            "   N82: Splenda cuida la salud\n",
            "   N83: Opci√≥n m√°s saludable en comparaci√≥n con otras alternativas\n",
            "   N84: Alternativa al az√∫car para cocinar y endulzar bebidas\n",
            "   N85: Beneficios de usar el producto\n",
            "   N86: Reducir consumo de az√∫car para mejorar la salud\n",
            "   N87: Producto que endulza sin muchas calor√≠as\n",
            "   N88: Llamar la atenci√≥n del consumidor\n",
            "   N89: Promoci√≥n de la salud\n",
            "   N9: Mejora el sabor de las comidas sin da√±ar la salud si se usa adecuadamente\n",
            "   N90: Splenda es una opci√≥n de edulcorante m√°s sana\n",
            "   N91: Splenda tiene mejor sabor\n",
            "   N92: Consumir sustituto de az√∫car en lugar de az√∫car\n",
            "   N93: Alternativa saludable para postres y bebidas dulces\n",
            "   N94: Consumir dulce sin culpa\n",
            "   N95: Mejorar la salud con un sustituto de az√∫car\n",
            "   N96: Preocupaci√≥n por la salud del consumidor\n",
            "   N97: Producto beneficioso para la salud de diferentes personas\n",
            "   N98: Opci√≥n saludable para endulzar\n",
            "   N99: Versatilidad del producto\n"
          ]
        }
      ],
      "source": [
        "# An√°lisis de decisiones\n",
        "decisiones_totales = {}\n",
        "for cod in resultado_final[\"codificaciones\"]:\n",
        "    dec = cod[\"decision\"]\n",
        "    decisiones_totales[dec] = decisiones_totales.get(dec, 0) + 1\n",
        "\n",
        "print(\"üìä RESUMEN DE DECISIONES\")\n",
        "print(\"=\"*60)\n",
        "for decision, cantidad in sorted(decisiones_totales.items(), key=lambda x: -x[1]):\n",
        "    porcentaje = (cantidad / len(resultado_final[\"codificaciones\"])) * 100\n",
        "    print(f\"   {decision.upper():12} : {cantidad:3} respuestas ({porcentaje:.1f}%)\")\n",
        "\n",
        "print(f\"\\nüÜï C√ìDIGOS NUEVOS GENERADOS: {len(resultado_final['codigos_nuevos_global'])}\")\n",
        "if resultado_final['codigos_nuevos_global']:\n",
        "    print(\"\\\\nüìã Lista de c√≥digos nuevos:\")\n",
        "    for desc, codigo in sorted(resultado_final['codigos_nuevos_global'].items(), key=lambda x: x[1]):\n",
        "        print(f\"   {codigo}: {desc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nüìù EJEMPLOS DE CODIFICACIONES:\n",
            "============================================================\n",
            "\\n1. Respuesta (fila 2):\n",
            "   \"-\"\n",
            "   Decisi√≥n: RECHAZAR\n",
            "   Justificaci√≥n: La respuesta est√° vac√≠a o no contiene informaci√≥n relevante.\n",
            "\\n2. Respuesta (fila 3):\n",
            "   \"que podemos ocuparla para cualquier alimento o bebida\"\n",
            "   Decisi√≥n: NUEVO\n",
            "   C√≥digos nuevos: Versatilidad de uso en alimentos y bebidas\n",
            "   Justificaci√≥n: La respuesta indica que el producto puede usarse en cualquier alimento o bebida, lo que apunta a su versatilidad.\n",
            "\\n3. Respuesta (fila 4):\n",
            "   \"-\"\n",
            "   Decisi√≥n: RECHAZAR\n",
            "   Justificaci√≥n: La respuesta est√° vac√≠a o no contiene informaci√≥n relevante.\n",
            "\\n4. Respuesta (fila 5):\n",
            "   \"ES AZUCAR PARA DIABETICOS\"\n",
            "   Decisi√≥n: NUEVO\n",
            "   C√≥digos nuevos: Producto apto para personas con diabetes\n",
            "   Justificaci√≥n: La respuesta se√±ala que el producto es az√∫car para diab√©ticos, lo que implica que es apto para personas con diabetes.\n",
            "\\n5. Respuesta (fila 6):\n",
            "   \"-\"\n",
            "   Decisi√≥n: RECHAZAR\n",
            "   Justificaci√≥n: La respuesta est√° vac√≠a o no contiene informaci√≥n relevante.\n"
          ]
        }
      ],
      "source": [
        "# Ver ejemplos de codificaciones\n",
        "print(\"\\\\nüìù EJEMPLOS DE CODIFICACIONES:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, cod in enumerate(resultado_final[\"codificaciones\"][:5], 1):\n",
        "    print(f\"\\\\n{i}. Respuesta (fila {cod['fila_excel']}):\")\n",
        "    texto_corto = cod['texto'][:80] + \"...\" if len(cod['texto']) > 80 else cod['texto']\n",
        "    print(f\"   \\\"{texto_corto}\\\"\")\n",
        "    print(f\"   Decisi√≥n: {cod['decision'].upper()}\")\n",
        "    \n",
        "    if cod['codigos_historicos']:\n",
        "        codigos_hist = \", \".join([str(c) for c in cod['codigos_historicos']])\n",
        "        print(f\"   C√≥digos hist√≥ricos: {codigos_hist}\")\n",
        "    \n",
        "    if cod['codigos_nuevos']:\n",
        "        print(f\"   C√≥digos nuevos: {', '.join(cod['codigos_nuevos'])}\")\n",
        "    \n",
        "    print(f\"   Justificaci√≥n: {cod['justificacion']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üíæ Paso 5: Exportar Resultados a Excel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä DataFrame de resultados:\n",
            "   Fila_Original                                          Respuesta  Decision  \\\n",
            "0              2                                                  -  rechazar   \n",
            "1              3  que podemos ocuparla para cualquier alimento o...     nuevo   \n",
            "2              4                                                  -  rechazar   \n",
            "3              5                          ES AZUCAR PARA DIABETICOS     nuevo   \n",
            "4              6                                                  -  rechazar   \n",
            "5              7                                                  -  rechazar   \n",
            "6              8        sobre un tipo de azucar que no te hace da√±o     nuevo   \n",
            "7              9                                                  -  rechazar   \n",
            "8             10                 endulzante muy bueno para la salud     nuevo   \n",
            "9             11                                                  -  rechazar   \n",
            "\n",
            "      Codigos                               Descripciones  \\\n",
            "0  SIN_CODIGO                                               \n",
            "1          N1  Versatilidad de uso en alimentos y bebidas   \n",
            "2  SIN_CODIGO                                               \n",
            "3          N2    Producto apto para personas con diabetes   \n",
            "4  SIN_CODIGO                                               \n",
            "5  SIN_CODIGO                                               \n",
            "6          N3       Producto que no causa da√±o a la salud   \n",
            "7  SIN_CODIGO                                               \n",
            "8          N4        Endulzante beneficioso para la salud   \n",
            "9  SIN_CODIGO                                               \n",
            "\n",
            "                                       Justificacion  \n",
            "0  La respuesta est√° vac√≠a o no contiene informac...  \n",
            "1  La respuesta indica que el producto puede usar...  \n",
            "2  La respuesta est√° vac√≠a o no contiene informac...  \n",
            "3  La respuesta se√±ala que el producto es az√∫car ...  \n",
            "4  La respuesta est√° vac√≠a o no contiene informac...  \n",
            "5  La respuesta est√° vac√≠a o no contiene informac...  \n",
            "6  La respuesta comunica que el az√∫car no hace da...  \n",
            "7  La respuesta est√° vac√≠a o no contiene informac...  \n",
            "8  La respuesta indica que el endulzante es muy b...  \n",
            "9  La respuesta est√° vac√≠a o no contiene informac...  \n",
            "\n",
            "üíæ Guardando resultados...\n",
            "   Archivo entrada: P5 - copia.xlsx\n",
            "   Modelo: gpt-4.1\n",
            "   Pregunta detectada: 5.Teniendo en cuenta la imagen que acaba de ver ¬øQu√© cree que le est√° tratando de comunicar? Profundice en su respuestaLe tratando comunicar\n",
            "\n",
            "‚úÖ Resultados guardados en:\n",
            "   üìÑ P5_copia_gpt_4.1_20251120_143250.xlsx\n",
            "   üìÇ c:\\Users\\ivan\\Documents\\cod-script\\notebooks\n"
          ]
        }
      ],
      "source": [
        "# Crear DataFrame con resultados\n",
        "filas_excel = []\n",
        "\n",
        "for cod in resultado_final[\"codificaciones\"]:\n",
        "    # Combinar todos los c√≥digos\n",
        "    codigos_finales = []\n",
        "    descripciones_finales = []\n",
        "    \n",
        "    # C√≥digos hist√≥ricos\n",
        "    if cod[\"codigos_historicos\"]:\n",
        "        for codigo_hist in cod[\"codigos_historicos\"]:\n",
        "            codigos_finales.append(str(codigo_hist))\n",
        "            # Buscar descripci√≥n en cat√°logo\n",
        "            desc = next((c[\"descripcion\"] for c in catalogo_historico if c[\"codigo\"] == codigo_hist), \"\")\n",
        "            if desc:\n",
        "                descripciones_finales.append(desc)\n",
        "    \n",
        "    # C√≥digos nuevos\n",
        "    if cod[\"codigos_nuevos\"]:\n",
        "        for desc_nueva in cod[\"codigos_nuevos\"]:\n",
        "            # Buscar el c√≥digo normalizado\n",
        "            codigo_nuevo = resultado_final[\"codigos_nuevos_global\"].get(desc_nueva, \"?\")\n",
        "            codigos_finales.append(codigo_nuevo)\n",
        "            descripciones_finales.append(desc_nueva)\n",
        "    \n",
        "    filas_excel.append({\n",
        "        \"Fila_Original\": cod[\"fila_excel\"],\n",
        "        \"Respuesta\": cod[\"texto\"],\n",
        "        \"Decision\": cod[\"decision\"],\n",
        "        \"Codigos\": \" | \".join(codigos_finales) if codigos_finales else \"SIN_CODIGO\",\n",
        "        \"Descripciones\": \" | \".join(descripciones_finales) if descripciones_finales else \"\",\n",
        "        \"Justificacion\": cod[\"justificacion\"]\n",
        "    })\n",
        "\n",
        "df_resultados = pd.DataFrame(filas_excel)\n",
        "\n",
        "# Mostrar primeras filas\n",
        "print(\"\\nüìä DataFrame de resultados:\")\n",
        "print(df_resultados.head(10))\n",
        "\n",
        "# Funci√≥n para sanitizar nombre de archivo\n",
        "import re\n",
        "\n",
        "def sanitizar_nombre_archivo(nombre: str, max_length: int = 50) -> str:\n",
        "    \"\"\"\n",
        "    Convierte un nombre en un nombre de archivo v√°lido\n",
        "    - Elimina caracteres inv√°lidos\n",
        "    - Reemplaza espacios y guiones por guiones bajos\n",
        "    \"\"\"\n",
        "    # Eliminar extensi√≥n si existe\n",
        "    nombre = nombre.replace('.xlsx', '').replace('.xls', '')\n",
        "    \n",
        "    # Eliminar caracteres inv√°lidos para Windows\n",
        "    nombre = re.sub(r'[<>:\"/\\\\|?*¬ø¬°]', '', nombre)\n",
        "    \n",
        "    # Reemplazar espacios, guiones y puntos por guiones bajos\n",
        "    nombre = nombre.replace(' ', '_').replace('-', '_').replace('.', '_')\n",
        "    \n",
        "    # Eliminar guiones bajos duplicados\n",
        "    nombre = re.sub(r'_+', '_', nombre)\n",
        "    \n",
        "    # Eliminar guiones bajos al inicio/final\n",
        "    nombre = nombre.strip('_')\n",
        "    \n",
        "    # Limitar longitud\n",
        "    if len(nombre) > max_length:\n",
        "        nombre = nombre[:max_length].rstrip('_')\n",
        "    \n",
        "    return nombre\n",
        "\n",
        "# Guardar a Excel\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Obtener nombre base del archivo de entrada (sin extensi√≥n)\n",
        "nombre_base = ARCHIVO_RESPUESTAS.stem  # \"P5 - copia\"\n",
        "nombre_base_safe = sanitizar_nombre_archivo(nombre_base)\n",
        "\n",
        "# Sanitizar modelo (gpt-4o-mini ‚Üí gpt_4o_mini)\n",
        "modelo_safe = MODELO_GPT.replace('-', '_')\n",
        "\n",
        "# Construir nombre: archivo_modelo_fecha.xlsx\n",
        "archivo_salida = project_root / \"notebooks\" / f\"{nombre_base_safe}_{modelo_safe}_{timestamp}.xlsx\"\n",
        "\n",
        "print(f\"\\nüíæ Guardando resultados...\")\n",
        "print(f\"   Archivo entrada: {ARCHIVO_RESPUESTAS.name}\")\n",
        "print(f\"   Modelo: {MODELO_GPT}\")\n",
        "print(f\"   Pregunta detectada: {nombre_pregunta}\")\n",
        "\n",
        "df_resultados.to_excel(archivo_salida, index=False)\n",
        "\n",
        "print(f\"\\n‚úÖ Resultados guardados en:\")\n",
        "print(f\"   üìÑ {archivo_salida.name}\")\n",
        "print(f\"   üìÇ {archivo_salida.parent}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üí° Ejecuta esta funci√≥n despu√©s de correr el notebook dos veces\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n para comparar dos ejecuciones (ejecuta esto despu√©s de correr ambas)\n",
        "def comparar_resultados(archivo1: str, archivo2: str):\n",
        "    \"\"\"\n",
        "    Compara resultados de dos ejecuciones\n",
        "    archivo1: con cat√°logo hist√≥rico\n",
        "    archivo2: sin cat√°logo hist√≥rico\n",
        "    \"\"\"\n",
        "    df1 = pd.read_excel(archivo1)\n",
        "    df2 = pd.read_excel(archivo2)\n",
        "    \n",
        "    print(\"üìä COMPARACI√ìN DE RESULTADOS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Decisiones\n",
        "    print(\"\\n1Ô∏è‚É£ Distribuci√≥n de Decisiones:\")\n",
        "    decisiones1 = df1[\"Decision\"].value_counts()\n",
        "    decisiones2 = df2[\"Decision\"].value_counts()\n",
        "    \n",
        "    print(f\"\\n   CON cat√°logo:\")\n",
        "    for dec, count in decisiones1.items():\n",
        "        print(f\"      {dec}: {count}\")\n",
        "    \n",
        "    print(f\"\\n   SIN cat√°logo:\")\n",
        "    for dec, count in decisiones2.items():\n",
        "        print(f\"      {dec}: {count}\")\n",
        "    \n",
        "    # C√≥digos generados\n",
        "    print(f\"\\n2Ô∏è‚É£ C√≥digos Nuevos Generados:\")\n",
        "    print(f\"   CON cat√°logo: {df1['Codigos'].str.contains('N').sum()} respuestas con c√≥digos nuevos\")\n",
        "    print(f\"   SIN cat√°logo: {df2['Codigos'].str.contains('N').sum()} respuestas con c√≥digos nuevos\")\n",
        "    \n",
        "    # C√≥digos √∫nicos\n",
        "    codigos1 = set()\n",
        "    codigos2 = set()\n",
        "    \n",
        "    for codigos_str in df1[\"Codigos\"]:\n",
        "        if isinstance(codigos_str, str):\n",
        "            codigos1.update(codigos_str.split(\" | \"))\n",
        "    \n",
        "    for codigos_str in df2[\"Codigos\"]:\n",
        "        if isinstance(codigos_str, str):\n",
        "            codigos2.update(codigos_str.split(\" | \"))\n",
        "    \n",
        "    print(f\"\\n3Ô∏è‚É£ Total C√≥digos √önicos:\")\n",
        "    print(f\"   CON cat√°logo: {len(codigos1)} c√≥digos\")\n",
        "    print(f\"   SIN cat√°logo: {len(codigos2)} c√≥digos\")\n",
        "\n",
        "# Ejemplo de uso (descomenta despu√©s de tener ambos archivos):\n",
        "\"\"\"\n",
        "comparar_resultados(\n",
        "    \"notebooks/resultados_P6_con_catalogo_20251120_120000.xlsx\",\n",
        "    \"notebooks/resultados_P6_sin_catalogo_20251120_123000.xlsx\"\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nüí° Ejecuta esta funci√≥n despu√©s de correr el notebook dos veces\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Gr√°fico de decisiones generado\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Gr√°fico de decisiones\n",
        "decisiones = df_resultados[\"Decision\"].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(decisiones.index, decisiones.values, color=['#2ecc71', '#3498db', '#e74c3c', '#95a5a6'])\n",
        "plt.title(f'Distribuci√≥n de Decisiones - {PREGUNTA_A_CODIFICAR}', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Tipo de Decisi√≥n', fontsize=12)\n",
        "plt.ylabel('Cantidad', fontsize=12)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Agregar valores encima de las barras\n",
        "for i, (idx, val) in enumerate(decisiones.items()):\n",
        "    plt.text(i, val + 0.5, str(val), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Gr√°fico de decisiones generado\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéØ Conclusiones y Observaciones\n",
        "\n",
        "Usa esta celda para anotar tus observaciones despu√©s de experimentar:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìù Mis Observaciones\n",
        "\n",
        "**Con Cat√°logo Hist√≥rico:**\n",
        "- ¬øReutiliz√≥ c√≥digos existentes efectivamente?\n",
        "- ¬øGener√≥ c√≥digos nuevos solo cuando era necesario?\n",
        "- ¬øLos c√≥digos hist√≥ricos fueron relevantes?\n",
        "\n",
        "**Sin Cat√°logo Hist√≥rico:**\n",
        "- ¬øLos c√≥digos nuevos son coherentes?\n",
        "- ¬øHay redundancia en las descripciones?\n",
        "- ¬øLa normalizaci√≥n funcion√≥ bien?\n",
        "\n",
        "**Calidad General:**\n",
        "- ¬øLas justificaciones tienen sentido?\n",
        "- ¬øHay respuestas que deber√≠an rechazarse pero no lo fueron?\n",
        "- ¬øHay multicodificaci√≥n apropiada?\n",
        "\n",
        "**Desempe√±o:**\n",
        "- Tiempo total: ___ segundos\n",
        "- Costo estimado: ~$___\n",
        "- ¬øVale la pena el costo vs. beneficio?\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Checklist de Evaluaci√≥n\n",
        "\n",
        "- [ ] Revisa manualmente 10-20 codificaciones\n",
        "- [ ] Verifica que no haya c√≥digos duplicados con descripciones diferentes\n",
        "- [ ] Confirma que las descripciones nuevas sean espec√≠ficas pero no redundantes\n",
        "- [ ] Compara resultados con tu soluci√≥n actual\n",
        "- [ ] Decide si LangGraph mejora tu workflow\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üöÄ Pr√≥ximos Pasos\n",
        "\n",
        "### **Si te gustaron los resultados:**\n",
        "\n",
        "1. **Experimenta con diferentes configuraciones:**\n",
        "   - Prueba con m√°s respuestas (50, 100, 200)\n",
        "   - Cambia el modelo (`gpt-4o` para m√°s precisi√≥n)\n",
        "   - Ajusta `BATCH_SIZE` para ver el impacto\n",
        "\n",
        "2. **Refina los prompts:**\n",
        "   - Modifica las instrucciones en `nodo_codificar_batch`\n",
        "   - Agrega ejemplos espec√≠ficos de tu dominio\n",
        "   - Ajusta el umbral de similitud (actualmente 0.6)\n",
        "\n",
        "3. **Migra a producci√≥n:**\n",
        "   - Integra este flujo en tu backend FastAPI\n",
        "   - Implementa streaming SSE para progreso en tiempo real\n",
        "   - Agrega checkpointing para recuperaci√≥n ante fallos\n",
        "\n",
        "### **Si quieres mejorar:**\n",
        "\n",
        "- Agrega un nodo de **validaci√≥n** antes de codificar\n",
        "- Implementa **retry logic** si GPT falla\n",
        "- Calcula **m√©tricas de costo** (tokens, $$$)\n",
        "- Agrega **human-in-the-loop** para casos ambiguos\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Recursos\n",
        "\n",
        "- [Notebook 01: Introducci√≥n a LangGraph](./01_langgraph_intro.ipynb)\n",
        "- [Notebook 02: Dise√±o del Sistema](./02_langgraph_codificacion.ipynb)\n",
        "- [Documentaci√≥n LangGraph](https://langchain-ai.github.io/langgraph/)\n",
        "\n",
        "---\n",
        "\n",
        "¬°Feliz experimentaci√≥n! üéâ\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "codificacion_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
