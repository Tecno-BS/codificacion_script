{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¯ IntroducciÃ³n a LangGraph - ExperimentaciÃ³n\n",
        "\n",
        "Este notebook te introduce a **LangGraph** con ejemplos simples antes de aplicarlo a tu sistema de codificaciÃ³n.\n",
        "\n",
        "## ðŸ“š Â¿QuÃ© es LangGraph?\n",
        "\n",
        "- **Framework** para construir aplicaciones con LLMs como grafos de estados\n",
        "- Cada **nodo** = una operaciÃ³n (llamar GPT, procesar datos, etc.)\n",
        "- Las **aristas** conectan nodos y pueden ser condicionales\n",
        "- El **estado** fluye entre nodos y se va enriqueciendo\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Setup Inicial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-1.0.8-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (1.1.1)\n",
            "Collecting langchain-core<2.0.0,>=1.0.6 (from langchain)\n",
            "  Downloading langchain_core-1.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain) (2.11.7)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting xxhash>=3.5.0 (from langgraph)\n",
            "  Using cached xxhash-3.6.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
            "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.6->langchain)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.6->langchain)\n",
            "  Downloading langsmith-0.4.44-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (4.15.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.6->langchain) (3.0.0)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Using cached ormsgpack-1.12.0-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph)\n",
            "  Using cached orjson-3.11.4-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: requests>=2.0.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (2.32.5)\n",
            "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain)\n",
            "  Using cached zstandard-0.25.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: anyio in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting openai<3.0.0,>=1.109.1 (from langchain-openai)\n",
            "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
            "  Using cached tiktoken-0.12.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.8.29)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (2.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\ivan\\documents\\cod-script\\codificacion_env\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
            "Downloading langchain-1.0.8-py3-none-any.whl (93 kB)\n",
            "Downloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
            "Downloading langchain_core-1.0.7-py3-none-any.whl (472 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl (34 kB)\n",
            "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "Downloading langsmith-0.4.44-py3-none-any.whl (410 kB)\n",
            "Downloading langchain_openai-1.0.3-py3-none-any.whl (82 kB)\n",
            "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
            "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.0/1.0 MB 4.9 MB/s  0:00:00\n",
            "Using cached tiktoken-0.12.0-cp312-cp312-win_amd64.whl (878 kB)\n",
            "Using cached orjson-3.11.4-cp312-cp312-win_amd64.whl (131 kB)\n",
            "Using cached ormsgpack-1.12.0-cp312-cp312-win_amd64.whl (112 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached xxhash-3.6.0-cp312-cp312-win_amd64.whl (31 kB)\n",
            "Using cached zstandard-0.25.0-cp312-cp312-win_amd64.whl (506 kB)\n",
            "Installing collected packages: zstandard, xxhash, ormsgpack, orjson, jsonpatch, tiktoken, requests-toolbelt, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain\n",
            "\n",
            "   ----------------------------------------  0/16 [zstandard]\n",
            "   ----- ----------------------------------  2/16 [ormsgpack]\n",
            "   ---------- -----------------------------  4/16 [jsonpatch]\n",
            "   ------------ ---------------------------  5/16 [tiktoken]\n",
            "   --------------- ------------------------  6/16 [requests-toolbelt]\n",
            "   --------------- ------------------------  6/16 [requests-toolbelt]\n",
            "   --------------- ------------------------  6/16 [requests-toolbelt]\n",
            "   --------------- ------------------------  6/16 [requests-toolbelt]\n",
            "   --------------- ------------------------  6/16 [requests-toolbelt]\n",
            "   --------------- ------------------------  6/16 [requests-toolbelt]\n",
            "  Attempting uninstall: openai\n",
            "   --------------- ------------------------  6/16 [requests-toolbelt]\n",
            "    Found existing installation: openai 1.102.0\n",
            "   --------------- ------------------------  6/16 [requests-toolbelt]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "    Uninstalling openai-1.102.0:\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "      Successfully uninstalled openai-1.102.0\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   ----------------- ----------------------  7/16 [openai]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   -------------------- -------------------  8/16 [langsmith]\n",
            "   ---------------------- -----------------  9/16 [langgraph-sdk]\n",
            "   ---------------------- -----------------  9/16 [langgraph-sdk]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   ------------------------- -------------- 10/16 [langchain-core]\n",
            "   --------------------------- ------------ 11/16 [langgraph-checkpoint]\n",
            "   --------------------------- ------------ 11/16 [langgraph-checkpoint]\n",
            "   --------------------------- ------------ 11/16 [langgraph-checkpoint]\n",
            "   ------------------------------ --------- 12/16 [langchain-openai]\n",
            "   ------------------------------ --------- 12/16 [langchain-openai]\n",
            "   ------------------------------ --------- 12/16 [langchain-openai]\n",
            "   ------------------------------ --------- 12/16 [langchain-openai]\n",
            "   -------------------------------- ------- 13/16 [langgraph-prebuilt]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ----------------------------------- ---- 14/16 [langgraph]\n",
            "   ------------------------------------- -- 15/16 [langchain]\n",
            "   ------------------------------------- -- 15/16 [langchain]\n",
            "   ------------------------------------- -- 15/16 [langchain]\n",
            "   ------------------------------------- -- 15/16 [langchain]\n",
            "   ------------------------------------- -- 15/16 [langchain]\n",
            "   ------------------------------------- -- 15/16 [langchain]\n",
            "   ---------------------------------------- 16/16 [langchain]\n",
            "\n",
            "Successfully installed jsonpatch-1.33 langchain-1.0.8 langchain-core-1.0.7 langchain-openai-1.0.3 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.4 langgraph-sdk-0.2.9 langsmith-0.4.44 openai-2.8.1 orjson-3.11.4 ormsgpack-1.12.0 requests-toolbelt-1.0.0 tiktoken-0.12.0 xxhash-3.6.0 zstandard-0.25.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Instalar dependencias\n",
        "!pip install langchain langchain-openai langgraph python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… API Key cargada\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Cargar variables de entorno\n",
        "load_dotenv()\n",
        "\n",
        "# Verificar API key\n",
        "assert os.getenv(\"OPENAI_API_KEY\"), \"âŒ Falta OPENAI_API_KEY en .env\"\n",
        "print(\"âœ… API Key cargada\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸŒŸ Ejemplo 1: Grafo Simple (Sin LLM)\n",
        "\n",
        "Empezamos con un grafo que solo procesa nÃºmeros, para entender la mecÃ¡nica.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# 1. Definir el ESTADO (datos que fluyen entre nodos)\n",
        "class EstadoSimple(TypedDict):\n",
        "    numero: int\n",
        "    mensaje: str\n",
        "\n",
        "# 2. Definir NODOS (funciones que procesan el estado)\n",
        "def nodo_duplicar(state: EstadoSimple) -> EstadoSimple:\n",
        "    \"\"\"Duplica el nÃºmero\"\"\"\n",
        "    nuevo_numero = state[\"numero\"] * 2\n",
        "    return {\n",
        "        \"numero\": nuevo_numero,\n",
        "        \"mensaje\": f\"Duplicado: {state['numero']} â†’ {nuevo_numero}\"\n",
        "    }\n",
        "\n",
        "def nodo_sumar_10(state: EstadoSimple) -> EstadoSimple:\n",
        "    \"\"\"Suma 10 al nÃºmero\"\"\"\n",
        "    nuevo_numero = state[\"numero\"] + 10\n",
        "    return {\n",
        "        \"numero\": nuevo_numero,\n",
        "        \"mensaje\": state[\"mensaje\"] + f\" | Suma: {state['numero']} â†’ {nuevo_numero}\"\n",
        "    }\n",
        "\n",
        "# 3. Construir el GRAFO\n",
        "workflow = StateGraph(EstadoSimple)\n",
        "\n",
        "# Agregar nodos\n",
        "workflow.add_node(\"duplicar\", nodo_duplicar)\n",
        "workflow.add_node(\"sumar\", nodo_sumar_10)\n",
        "\n",
        "# Definir flujo\n",
        "workflow.set_entry_point(\"duplicar\")  # Empieza aquÃ­\n",
        "workflow.add_edge(\"duplicar\", \"sumar\")  # DespuÃ©s va a sumar\n",
        "workflow.add_edge(\"sumar\", END)  # Y termina\n",
        "\n",
        "# 4. Compilar\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"âœ… Grafo simple creado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Ejecutar el grafo\n",
        "resultado = app.invoke({\n",
        "    \"numero\": 5,\n",
        "    \"mensaje\": \"Inicio\"\n",
        "})\n",
        "\n",
        "print(\"\\nðŸŽ¯ Resultado:\")\n",
        "print(f\"NÃºmero final: {resultado['numero']}\")\n",
        "print(f\"Trazabilidad: {resultado['mensaje']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“Š Visualizar el grafo (si tienes graphviz instalado)\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ No se pudo visualizar: {e}\")\n",
        "    print(\"\\nðŸ“ Ver estructura en formato texto:\")\n",
        "    print(app.get_graph())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ¤– Ejemplo 2: Grafo con GPT\n",
        "\n",
        "Ahora agregamos llamadas a OpenAI para analizar texto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Estado para anÃ¡lisis de texto\n",
        "class EstadoAnalisis(TypedDict):\n",
        "    texto_original: str\n",
        "    idioma: str\n",
        "    sentimiento: str\n",
        "    palabras_clave: list\n",
        "    resumen: str\n",
        "\n",
        "# Esquemas para respuestas estructuradas\n",
        "class ResultadoIdioma(BaseModel):\n",
        "    idioma: str = Field(description=\"Idioma detectado\")\n",
        "    confianza: float = Field(description=\"Confianza 0-1\")\n",
        "\n",
        "class ResultadoSentimiento(BaseModel):\n",
        "    sentimiento: str = Field(description=\"positivo, negativo o neutral\")\n",
        "    intensidad: float = Field(description=\"Intensidad 0-1\")\n",
        "\n",
        "# Inicializar LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "print(\"âœ… LLM inicializado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NODO 1: Detectar idioma\n",
        "def nodo_detectar_idioma(state: EstadoAnalisis) -> EstadoAnalisis:\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Detecta el idioma del texto.\"),\n",
        "        (\"user\", \"{texto}\")\n",
        "    ])\n",
        "    \n",
        "    chain = prompt | llm.with_structured_output(ResultadoIdioma)\n",
        "    resultado = chain.invoke({\"texto\": state[\"texto_original\"]})\n",
        "    \n",
        "    print(f\"  ðŸŒ Idioma: {resultado.idioma} (confianza: {resultado.confianza})\")\n",
        "    return {**state, \"idioma\": resultado.idioma}\n",
        "\n",
        "# NODO 2: Analizar sentimiento\n",
        "def nodo_analizar_sentimiento(state: EstadoAnalisis) -> EstadoAnalisis:\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Analiza el sentimiento del texto.\"),\n",
        "        (\"user\", \"{texto}\")\n",
        "    ])\n",
        "    \n",
        "    chain = prompt | llm.with_structured_output(ResultadoSentimiento)\n",
        "    resultado = chain.invoke({\"texto\": state[\"texto_original\"]})\n",
        "    \n",
        "    print(f\"  ðŸ˜Š Sentimiento: {resultado.sentimiento} (intensidad: {resultado.intensidad})\")\n",
        "    return {**state, \"sentimiento\": resultado.sentimiento}\n",
        "\n",
        "# NODO 3: Extraer palabras clave\n",
        "def nodo_palabras_clave(state: EstadoAnalisis) -> EstadoAnalisis:\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Extrae 3-5 palabras clave del texto. Responde solo con las palabras separadas por comas.\"),\n",
        "        (\"user\", \"{texto}\")\n",
        "    ])\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    resultado = chain.invoke({\"texto\": state[\"texto_original\"]})\n",
        "    \n",
        "    palabras = [p.strip() for p in resultado.content.split(\",\")]\n",
        "    \n",
        "    print(f\"  ðŸ”‘ Palabras clave: {palabras}\")\n",
        "    return {**state, \"palabras_clave\": palabras}\n",
        "\n",
        "# NODO 4: Generar resumen\n",
        "def nodo_resumen(state: EstadoAnalisis) -> EstadoAnalisis:\n",
        "    resumen = f\"Texto en {state['idioma']} con sentimiento {state['sentimiento']}. Palabras clave: {', '.join(state['palabras_clave'][:3])}\"\n",
        "    print(f\"  ðŸ“ Resumen: {resumen}\")\n",
        "    return {**state, \"resumen\": resumen}\n",
        "\n",
        "print(\"âœ… Nodos con GPT creados\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construir grafo de anÃ¡lisis\n",
        "workflow_analisis = StateGraph(EstadoAnalisis)\n",
        "\n",
        "workflow_analisis.add_node(\"idioma\", nodo_detectar_idioma)\n",
        "workflow_analisis.add_node(\"sentimiento\", nodo_analizar_sentimiento)\n",
        "workflow_analisis.add_node(\"palabras\", nodo_palabras_clave)\n",
        "workflow_analisis.add_node(\"resumen\", nodo_resumen)\n",
        "\n",
        "workflow_analisis.set_entry_point(\"idioma\")\n",
        "workflow_analisis.add_edge(\"idioma\", \"sentimiento\")\n",
        "workflow_analisis.add_edge(\"sentimiento\", \"palabras\")\n",
        "workflow_analisis.add_edge(\"palabras\", \"resumen\")\n",
        "workflow_analisis.add_edge(\"resumen\", END)\n",
        "\n",
        "app_analisis = workflow_analisis.compile()\n",
        "\n",
        "print(\"âœ… Grafo de anÃ¡lisis compilado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Probar con texto de ejemplo\n",
        "texto_prueba = \"Me encanta este producto, tiene muy buen sabor y es versÃ¡til para diferentes comidas. Lo recomiendo totalmente.\"\n",
        "\n",
        "print(f\"\\nðŸ“„ Analizando: '{texto_prueba}'\\n\")\n",
        "\n",
        "resultado = app_analisis.invoke({\n",
        "    \"texto_original\": texto_prueba,\n",
        "    \"idioma\": \"\",\n",
        "    \"sentimiento\": \"\",\n",
        "    \"palabras_clave\": [],\n",
        "    \"resumen\": \"\"\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š RESULTADO FINAL:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Idioma: {resultado['idioma']}\")\n",
        "print(f\"Sentimiento: {resultado['sentimiento']}\")\n",
        "print(f\"Palabras clave: {resultado['palabras_clave']}\")\n",
        "print(f\"Resumen: {resultado['resumen']}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ”€ Ejemplo 3: Transiciones Condicionales\n",
        "\n",
        "El grafo puede tomar diferentes caminos segÃºn el estado. Implementaremos la **Conjetura de Collatz**:\n",
        "\n",
        "- Si el nÃºmero es **par**: dividir por 2\n",
        "- Si es **impar**: multiplicar por 3 y sumar 1\n",
        "- Repetir hasta llegar a 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'TypedDict' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mEstadoCondicional\u001b[39;00m(\u001b[43mTypedDict\u001b[49m):\n\u001b[32m      2\u001b[39m     numero: \u001b[38;5;28mint\u001b[39m\n\u001b[32m      3\u001b[39m     resultado: \u001b[38;5;28mstr\u001b[39m\n",
            "\u001b[31mNameError\u001b[39m: name 'TypedDict' is not defined"
          ]
        }
      ],
      "source": [
        "  \n",
        "class EstadoCondicional(TypedDict):\n",
        "    numero: int\n",
        "    resultado: str\n",
        "    operaciones: list\n",
        "\n",
        "def nodo_inicio(state: EstadoCondicional) -> EstadoCondicional:\n",
        "    print(f\"ðŸŽ¬ Empezando con: {state['numero']}\")\n",
        "    return {**state, \"operaciones\": [f\"inicio: {state['numero']}\"]}\n",
        "\n",
        "def nodo_par(state: EstadoCondicional) -> EstadoCondicional:\n",
        "    nuevo_num = state[\"numero\"] // 2\n",
        "    print(f\"  âž— {state['numero']} es PAR â†’ dividir por 2 = {nuevo_num}\")\n",
        "    return {\n",
        "        **state,\n",
        "        \"numero\": nuevo_num,\n",
        "        \"operaciones\": state[\"operaciones\"] + [f\"par: {state['numero']} â†’ {nuevo_num}\"]\n",
        "    }\n",
        "\n",
        "def nodo_impar(state: EstadoCondicional) -> EstadoCondicional:\n",
        "    nuevo_num = state[\"numero\"] * 3 + 1\n",
        "    print(f\"  âœ–ï¸  {state['numero']} es IMPAR â†’ 3Ã—{state['numero']}+1 = {nuevo_num}\")\n",
        "    return {\n",
        "        **state,\n",
        "        \"numero\": nuevo_num,\n",
        "        \"operaciones\": state[\"operaciones\"] + [f\"impar: {state['numero']} â†’ {nuevo_num}\"]\n",
        "    }\n",
        "\n",
        "def nodo_fin(state: EstadoCondicional) -> EstadoCondicional:\n",
        "    print(f\"ðŸŽ‰ Â¡LlegÃ³ a 1 en {len(state['operaciones'])} pasos!\")\n",
        "    return {\n",
        "        **state,\n",
        "        \"resultado\": f\"LlegÃ³ a 1 en {len(state['operaciones'])} pasos\",\n",
        "        \"operaciones\": state[\"operaciones\"] + [\"fin\"]\n",
        "    }\n",
        "\n",
        "# FunciÃ³n que decide el camino\n",
        "def decidir_camino(state: EstadoCondicional) -> str:\n",
        "    if state[\"numero\"] == 1:\n",
        "        return \"fin\"\n",
        "    elif state[\"numero\"] % 2 == 0:\n",
        "        return \"par\"\n",
        "    else:\n",
        "        return \"impar\"\n",
        "\n",
        "print(\"âœ… Nodos condicionales creados\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construir grafo con bucles (Conjetura de Collatz)\n",
        "workflow_cond = StateGraph(EstadoCondicional)\n",
        "\n",
        "workflow_cond.add_node(\"inicio\", nodo_inicio)\n",
        "workflow_cond.add_node(\"par\", nodo_par)\n",
        "workflow_cond.add_node(\"impar\", nodo_impar)\n",
        "workflow_cond.add_node(\"fin\", nodo_fin)\n",
        "\n",
        "workflow_cond.set_entry_point(\"inicio\")\n",
        "\n",
        "# Desde inicio, decidir camino\n",
        "workflow_cond.add_conditional_edges(\n",
        "    \"inicio\",\n",
        "    decidir_camino,\n",
        "    {\"par\": \"par\", \"impar\": \"impar\", \"fin\": \"fin\"}\n",
        ")\n",
        "\n",
        "# DespuÃ©s de par/impar, volver a decidir (BUCLE)\n",
        "workflow_cond.add_conditional_edges(\n",
        "    \"par\",\n",
        "    decidir_camino,\n",
        "    {\"par\": \"par\", \"impar\": \"impar\", \"fin\": \"fin\"}\n",
        ")\n",
        "\n",
        "workflow_cond.add_conditional_edges(\n",
        "    \"impar\",\n",
        "    decidir_camino,\n",
        "    {\"par\": \"par\", \"impar\": \"impar\", \"fin\": \"fin\"}\n",
        ")\n",
        "\n",
        "workflow_cond.add_edge(\"fin\", END)\n",
        "\n",
        "app_cond = workflow_cond.compile()\n",
        "\n",
        "print(\"âœ… Grafo condicional compilado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Probar con diferentes nÃºmeros\n",
        "for num in [7, 12, 19]:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    resultado = app_cond.invoke({\n",
        "        \"numero\": num,\n",
        "        \"resultado\": \"\",\n",
        "        \"operaciones\": []\n",
        "    })\n",
        "    print(f\"{'='*60}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸŽ¯ Conceptos Clave Aprendidos\n",
        "\n",
        "âœ… **1. Estado (TypedDict)**: Estructura de datos que fluye entre nodos\n",
        "\n",
        "âœ… **2. Nodos**: Funciones que reciben estado y devuelven estado actualizado\n",
        "\n",
        "âœ… **3. Aristas**: Conexiones entre nodos (`add_edge`)\n",
        "\n",
        "âœ… **4. Aristas Condicionales**: Rutas dinÃ¡micas segÃºn el estado (`add_conditional_edges`)\n",
        "\n",
        "âœ… **5. CompilaciÃ³n**: Convierte el grafo en una aplicaciÃ³n ejecutable\n",
        "\n",
        "âœ… **6. Bucles**: Un nodo puede volver a sÃ­ mismo o a nodos anteriores\n",
        "\n",
        "---\n",
        "\n",
        "## âž¡ï¸ Siguiente Paso\n",
        "\n",
        "ContinÃºa con **`02_langgraph_codificacion.ipynb`** para ver cÃ³mo aplicar esto a tu sistema de codificaciÃ³n real.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "codificacion_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
